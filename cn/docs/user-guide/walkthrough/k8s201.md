---
approvers:
- janetkuo
- mikedanese
title: Kubernetes 201
---

## 标签，部署，服务，健康检查

<!--
## Labels, Deployments, Services and Health Checking
-->

<!--
If you went through [Kubernetes 101](/docs/user-guide/walkthrough/), you learned about kubectl, Pods, Volumes, and multiple containers.
For Kubernetes 201, we will pick up where 101 left off and cover some slightly more advanced topics in Kubernetes, related to application productionization, Deployment and
scaling.
-->

如果你已经学习过 [Kubernetes 101](/docs/user-guide/walkthrough/), 您应该已经了解了 kubectl、Pod、 Volume 和 multiple containers 的一些概念
在Kubernetes 201, 我们会加入一些 101 没有涉及到的和一些 Kubernetes 应用部署，弹性伸缩的话题。

{% include task-tutorial-prereqs.md %}

<!--
In order for the kubectl usage examples to work, make sure you have an examples directory locally, either from [a release](https://github.com/kubernetes/kubernetes/releases) or [the source](https://github.com/kubernetes/kubernetes).
-->

为了使文章中 kubectl 的案例正常工作， 请确保本地有一个 examples 目录，可以从 [release](https://github.com/kubernetes/kubernetes/releases) 或者 [source](https://github.com/kubernetes/kubernetes)下载.

* TOC
{:toc}

<!--
## Labels
-->

## 标签

<!--
Having already learned about Pods and how to create them, you may be struck by an urge to create many, many Pods.  Please do!  But eventually you will need a system to organize these Pods into groups.  The system for achieving this in Kubernetes is Labels.  Labels are key-value pairs that are attached to each object in Kubernetes.  Label selectors can be passed along with a RESTful `list` request to the apiserver to retrieve a list of objects which match that label selector.
-->

在你学习了什么是 Pod 和怎么创建后，你也许急切的想创建更多的 Pod, 没问题，你可以这么做，但是最终你需要将这些 Pod 分组。在 Kubernetes 中可以用标签来解决这个问题，标签就是 key-value 对，可以被附加在 Kubernetes 中所有的对象上。我们可以通过发送一个 `list` 的 RESTful 请求附加上一个标签选择器到 apiserver 来获取满足这个标签选择器的对象列表。

<!--
To add a label, add a labels section under metadata in the Pod definition:
-->

要添加一个标签，我们需要在 Pod 定义文件的 metadata 下添加 labels 部分：

```yaml
  labels:
    app: nginx
```

<!--
For example, here is the nginx Pod definition with labels ([pod-nginx-with-label.yaml](/docs/user-guide/walkthrough/pod-nginx-with-label.yaml)):

{% include code.html language="yaml" file="pod-nginx-with-label.yaml" ghlink="/docs/user-guide/walkthrough/pod-nginx-with-label.yaml" %}
Create the labeled Pod ([pod-nginx-with-label.yaml](/docs/user-guide/walkthrough/pod-nginx-with-label.yaml)):
-->

例如：这有一个包含 nginx Pod 的定义文件 ([pod-nginx-with-label.yaml](/docs/user-guide/walkthrough/pod-nginx-with-label.yaml))：

{% include code.html language="yaml" file="pod-nginx-with-label.yaml" ghlink="/docs/user-guide/walkthrough/pod-nginx-with-label.yaml" %}

创建这个 Pod:

```shell
kubectl create -f docs/user-guide/walkthrough/pod-nginx-with-label.yaml
```
<!--
List all Pods with the label `app=nginx`:
-->

列出所有的有 `app=nginx` 标签的 Pod:

```shell
kubectl get pods -l app=nginx
```
<!--
For more information, see [Labels](/docs/user-guide/labels/).
They are a core concept used by two additional Kubernetes building blocks: Deployments and Services.
-->

更多信息请看 [标签](/docs/user-guide/labels/).
这是 Kubernetes 中的另外两个构建块中用到的核心概念：Deployment 和 Service。

<!--
## Deployments
-->

## Deployment

<!--
Now that you know how to make awesome, multi-container, labeled Pods and you want to use them to build an application, you might be tempted to just start building a whole bunch of individual Pods, but if you do that, a whole host of operational concerns pop up.  For example: how will you scale the number of Pods up or down?  How will you roll out a new release?
-->

现在你已经知道怎么创建多容器的，带标签的 Pod 并且想用它们来部署一个应用程序，你也许会尝试创建一系列的单个的 Pod, 如果你这么做，问题就来了。比如说：你怎么对应用进行自动伸缩，怎么滚动升级到一个新的版本。

<!--
The answer to those questions and more is to use a [Deployment](/docs/concepts/workloads/controllers/deployment/) to manage maintaining and updating your running _Pods_.
-->

问题的答案就是使用 [Deployment]（/docs/concepts/workloads/controllers/deployment/) 来管理维护和更新你的应用。

<!--
A Deployment object defines a Pod creation template (a "cookie-cutter" if you will) and desired replica count.  The Deployment uses a label selector to identify the Pods it manages, and will create or delete Pods as needed to meet the replica count.  Deployments are also used to manage safely rolling out changes to your running Pods.
-->

<!--
Here is a Deployment that instantiates two nginx Pods:
-->

这里有一个 Deployment 创建了两个 Pod

{% include code.html language="yaml" file="deployment.yaml" ghlink="/docs/user-guide/walkthrough/deployment.yaml" %}


<!--
#### Deployment Management
-->

#### Deployment 管理

<!--
Create an nginx Deployment:

Download the `deployment.yaml` above by clicking on the file name and copy to your local directory.
-->

创建一个 nginx Deployment：

点击文件名，下载上面的 `deployment.yaml`, 复制到本地目录

```shell
kubectl create -f ./deployment.yaml
```
<!--
List all Deployments:
-->

查看所有的部署：

```shell
kubectl get deployment
```
<!--
List the Pods created by the Deployment:
-->

查看这个 Deployment 创建的 Pod

```shell
kubectl get pods -l app=nginx
```
<!--
Upgrade the nginx container from 1.7.9 to 1.8 by changing the Deployment and calling `apply`.  The following config
contains the desired changes:
-->

升级 nginx 容器从 1.7.9 到 1.8，修改 Deployment 然后执行 `apply` 操作。下面的配置文件包含所需的配置:

{% include code.html language="yaml" file="deployment-update.yaml" ghlink="/docs/user-guide/walkthrough/deployment-update.yaml" %}

<!--
Download ./deployment-update.yaml and copy to your local directory.
-->

下载 ./deployment-update.yaml 然后拷贝到你本地目录。

```shell
kubectl apply -f ./deployment-update.yaml
```
<!--
Watch the Deployment create Pods with new names and delete the old Pods:
-->

观察 Deployment 创建新的 Pod 并且删除老的 Pod：

```shell
kubectl get pods -l app=nginx
```

<!--
Delete the Deployment by name:
-->

通过名字删除 Deployment

```shell
kubectl delete deployment nginx-deployment
```
<!--
For more information, such as how to rollback Deployment changes to a previous version, see [_Deployments_](/docs/concepts/workloads/controllers/deployment/).
-->

更多信息比如说如何回滚到上一个版本，请查看 [_Deployments_](/docs/concepts/workloads/controllers/deployment/).

<!--
## Services
-->

## 服务

<!--
Once you have a replicated set of Pods, you need an abstraction that enables connectivity between the layers of your application.  For example, if you have a Deployment managing your backend jobs, you don't want to have to reconfigure your front-ends whenever you re-scale your backends.  Likewise, if the Pods in your backends are scheduled (or rescheduled) onto different machines, you can't be required to re-configure your front-ends.  In Kubernetes, the service abstraction achieves these goals.  A service provides a way to refer to a set of Pods (selected by labels) with a single static IP address. It may also provide load balancing, if supported by the provider.
-->

一旦你有了一组 Pod，你需要有一个抽象层来链接你的不同应用。 比如说，你有一个 Deployment 来管理你后端的应用，而当你对后端的应用进行伸缩的时候，你又不想改变你前端应用的配置。好比说你后端应用 Pod 被调度(或者重新调度)到其他的机器，你不需要重新修改你前端应用的配置。在 Kubernetes 中，服务抽象

<!--
For example, here is a service that balances across the Pods created in the previous nginx Deployment example ([service.yaml](/docs/user-guide/walkthrough/service.yaml)):
-->

例如：这里是上文 nginx 案例创建的 Pod 的一个服务([service.yaml](/docs/user-guide/walkthrough/service.yaml)):

{% include code.html language="yaml" file="service.yaml" ghlink="/docs/user-guide/walkthrough/service.yaml" %}


<!--
#### Service Management
-->

#### 管理 Service

<!--
Create an nginx service ([service.yaml](/docs/user-guide/walkthrough/service.yaml)):
-->

创建一个 nginx 服务 ([service.yaml](/docs/user-guide/walkthrough/service.yaml)):

```shell
kubectl create -f docs/user-guide/walkthrough/service.yaml
```

<!--
List all services:
-->

列出所有的服务:

```shell
kubectl get services
```
<!--
On most providers, the service IPs are not externally accessible. The easiest way to test that the service is working is to create a busybox Pod and exec commands on it remotely. See the [command execution documentation](/docs/user-guide/kubectl-overview/) for details.

Provided the service IP is accessible, you should be able to access its http endpoint with wget on the exposed port:
-->

大部分的K8S提供商，服务的 IP 是不能在外部网络访问的。测试这个服务最简单的方式就是创建一个 busybox 的 Pod 然后运行 exec 命令。 详细请看 [command execution documentation](/docs/user-guide/kubectl-overview/).

如果服务的 IP 可以访问， 你可以使用 wget 访问它的 http 服务暴露的端口：

```shell
{% raw %}
$ export SERVICE_IP=$(kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}')
$ export SERVICE_PORT=$(kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}')
$ echo "$SERVICE_IP:$SERVICE_PORT"
$ kubectl run busybox  --generator=run-pod/v1 --image=busybox --restart=Never --tty -i --env "SERVICE_IP=$SERVICE_IP,SERVICE_PORT=$SERVICE_PORT"
u@busybox$ wget -qO- http://$SERVICE_IP:$SERVICE_PORT # Run in the busybox container
u@busybox$ exit # Exit the busybox container
$ kubectl delete pod busybox # Clean up the pod we created with "kubectl run"
{% endraw %}
```

<!--
To delete the service by name:
-->

通过名称删除服务：

```shell
kubectl delete service nginx-service
```

<!--
When created, each service is assigned a unique IP address.  This address is tied to the lifespan of the Service, and will not change while the Service is alive.  Pods can be configured to talk to the service, and know that communication to the service will be automatically load-balanced out to some Pod that is a member of the set identified by the label selector in the Service.
-->

当服务创建的时候，每一个服务都会分配一个独立的 IP， 这个地址就绑定到了这个服务，只要服务在线这个地址就不会改变。 我们可以配置 Pod 和服务通信，并且当和服务通信的时候就会自动的被负载均衡到这个服务通过标签选择器选择的一个 Pod 上。

<!--
For more information, see [Services](/docs/concepts/services-networking/service/).
-->

更多信息请参考 [Services](/docs/concepts/services-networking/service/).

<!--
## Health Checking
-->

## 健康检查

<!--
When I write code it never crashes, right?  Sadly the [Kubernetes issues list](https://github.com/kubernetes/kubernetes/issues) indicates otherwise...
-->

我们写的代码永远不会崩溃，对吗？ [Kubernetes 问题列表](https://github.com/kubernetes/kubernetes/issues) 证明不是这样的。。。

<!--
Rather than trying to write bug-free code, a better approach is to use a management system to perform periodic health checking
and repair of your application.  That way a system outside of your application itself is responsible for monitoring the
application and taking action to fix it.  It's important that the system be outside of the application, since if
your application fails and the health checking agent is part of your application, it may fail as well and you'll never know.
In Kubernetes, the health check monitor is the Kubelet agent.
-->

比写没有 bug 的代码更好的是使用一个管理系统周期性的检查和修复你的应用。 一个你应用外的系统负责监控你的应用然后修复它。重要的是这个系统在你的应用外部，因为一旦你的应用出现了问题，而你的健康检查的代理是你的应用的一部分，那么它也会出现问题，而你根本不知道。在 Kubernetes 中健康检查是由 Kubelet做的。

<!--
#### Process Health Checking
-->

#### 进程健康检查

<!--
The simplest form of health-checking is just process level health checking.  The Kubelet constantly asks the Docker daemon
if the container process is still running, and if not, the container process is restarted.  In all of the Kubernetes examples
you have run so far, this health checking was actually already enabled.  It's on for every single container that runs in
Kubernetes.
-->

健康检查最简单的方式就是检查进程的状态。Kubelet 不断的询问 Docker daemon 这个容器进程是否还在运行，如果没有，这个容器就会被重启。目前在所有 Kubernetes 的案例中，这种健康检查是一直开启的。对与 Kubernetes 中所有运行的容器都是生效的。

<!--
#### Application Health Checking
-->

#### 应用健康检查

<!--
However, in many cases this low-level health checking is insufficient.  Consider, for example, the following code:
-->

然而，在很多场景中这个低级别的健康检查是没有作用的。例如下面的代码：

```go
lockOne := sync.Mutex{}
lockTwo := sync.Mutex{}

go func() {
  lockOne.Lock();
  lockTwo.Lock();
  ...
}()

lockTwo.Lock();
lockOne.Lock();
```

<!--
This is a classic example of a problem in computer science known as ["Deadlock"](https://en.wikipedia.org/wiki/Deadlock). From Docker's perspective your application is
still operating and the process is still running, but from your application's perspective your code is locked up and will never respond correctly.
-->

[死锁](https://en.wikipedia.org/wiki/Deadlock)是一个计算机科学很经典的例子. 从 Docker 的角度看你的应用一直在运行，进程也一直在运行，但是从应用的角度看，你的代码已经死锁，而且不会有正确的响应。

<!--
To address this problem, Kubernetes supports user implemented application health-checks.  These checks are performed by the
Kubelet to ensure that your application is operating correctly for a definition of "correctly" that _you_ provide.
-->

为了解决这个问题， Kubernetes 支持用户自己实现应用层的健康检查。 Kubelet 会执行这些检查来确保你的应用以你自己定义的条件是健康的。

<!--
Currently, there are three types of application health checks that you can choose from:
-->

目前，有三种类型的应用健康检查你可以选择：

<!--
   * HTTP Health Checks - The Kubelet will call a web hook.  If it returns between 200 and 399, it is considered success, failure otherwise. See health check examples [here](/docs/user-guide/liveness/).
   * Container Exec - The Kubelet will execute a command inside your container.  If it exits with status 0 it will be considered a success. See health check examples [here](/docs/user-guide/liveness/).
   * TCP Socket - The Kubelet will attempt to open a socket to your container.  If it can establish a connection, the container is considered healthy, if it can't it is considered a failure.
-->

  * HTTP 健康检查 - Kubelet 会调用你的 HTTP 接口。 如果返回代码在200和399之间，就认为是成功的，否则失败。[这里](/docs/user-guide/liveness/)有一个案例。
  * Container Exec - Kubelet 会执行你容器中的一个命令。如果返回值是0就认为是成功的，否则失败。[这里](/docs/user-guide/liveness/)有一个案例。
In all cases, if the Kubelet discovers a failure the container is restarted.
  * TCP Socket - Kubelet 会尝试在你的容器中打开一个 Socket 连接。 如果能打开就认为是成功的，否则失败。


<!--
The container health checks are configured in the `livenessProbe` section of your container config. There you can also specify an `initialDelaySeconds` that is a grace period from when the container is started to when health checks are performed, to enable your container to perform any necessary initialization.
-->

容器的健康检查是在容器的 `livenessProbe` 部分配置的。你可以设置 `initialDelaySeconds` 来指定容器启动后多长时间进行检查，这可以保证你的应用在健康检查之前执行初始化工作。

<!--
Here is an example config for a Pod with an HTTP health check ([pod-with-http-healthcheck.yaml](/docs/user-guide/walkthrough/pod-with-http-healthcheck.yaml)):
-->

这里是一个 Pod 使用 HTTP 健康检查的例子([pod-with-http-healthcheck.yaml](/docs/user-guide/walkthrough/pod-with-http-healthcheck.yaml)):

{% include code.html language="yaml" file="pod-with-http-healthcheck.yaml" ghlink="/docs/user-guide/walkthrough/pod-with-http-healthcheck.yaml" %}

<!--
And here is an example config for a Pod with a TCP Socket health check ([pod-with-tcp-socket-healthcheck.yaml](/docs/user-guide/walkthrough/pod-with-tcp-socket-healthcheck.yaml)):
-->

这里是一个使用 TCP Socket 健康检查的例子([pod-with-tcp-socket-healthcheck.yaml](/docs/user-guide/walkthrough/pod-with-tcp-socket-healthcheck.yaml)):

{% include code.html language="yaml" file="pod-with-tcp-socket-healthcheck.yaml" ghlink="/docs/user-guide/walkthrough/pod-with-tcp-socket-healthcheck.yaml" %}

<!--
For more information about health checking, see [Container Probes](/docs/user-guide/pod-states/#container-probes).
-->

更多健康检查的内容请查看 [Container Probes](/docs/user-guide/pod-states/#container-probes).


<!--
## What's Next?
-->

## 下一步呢？

<!--
For a complete application see the [guestbook example](https://github.com/kubernetes/examples/tree/{{page.githubbranch}}/guestbook/).
-->

这里有一个完整的应用 [guestbook example](https://github.com/kubernetes/examples/tree/{{page.githubbranch}}/guestbook/)。
