---
reviewers:
- moh0ps
title: سرویس
api_metadata:
- apiVersion: "v1"
  kind: "Service"
feature:
  title: کشف سرویس و متعادل‌سازی بار
  description: >
    No need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.
description: >-
  Expose an application running in your cluster behind a single outward-facing
  endpoint, even when the workload is split across multiple backends.
content_type: concept
weight: 10
---


<!-- overview -->

{{< glossary_definition term_id="service" length="short" prepend="In Kubernetes, a Service is" >}}

یکی از اهداف کلیدی سرویس‌ها در کوبرنتیز این است که نیازی به تغییر برنامه فعلی خود برای استفاده از یک سازوکار کشف سرویس ناآشنا نداشته باشید. می‌توانید کد را در پادها اجرا کنید، چه کدی باشد که برای دنیای ابری طراحی شده باشد و چه یک برنامه قدیمی‌تر که آن را کانتینر کرده‌اید. شما از یک سرویس برای در دسترس قرار دادن آن مجموعه از پادها در شبکه استفاده می‌کنید تا کلاینت‌ها بتوانند با آن تعامل داشته باشند.

اگر از {{< glossary_tooltip term_id="deployment" >}} برای اجرای برنامه خود استفاده می‌کنید، آن استقرار می‌تواند پادها را به صورت پویا ایجاد و از بین ببرد. از یک لحظه به لحظه دیگر، شما نمی‌دانید که چه تعداد از آن پادها کار می‌کنند و سالم هستند؛ حتی ممکن است ندانید که آن پادهای سالم چه نامی دارند. کوبرنتیز {{< glossary_tooltip term_id="pod" text="Pods" >}} ایجاد و از بین می‌روند تا با وضعیت مطلوب خوشه شما مطابقت داشته باشند. پادها منابع زودگذر هستند (نباید انتظار داشته باشید که یک پاد به تنهایی قابل اعتماد و بادوام باشد).

هر پاد نشانی IP مخصوص به خود را دریافت می‌کند (کوبرنتیز از افزونه‌های شبکه انتظار دارد که این امر را تضمین کنند). برای یک استقرار مشخص در خوشه شما، مجموعه پادهایی که در یک لحظه اجرا می‌شوند می‌توانند با مجموعه پادهایی که لحظه‌ای بعد همان برنامه را اجرا می‌کنند، متفاوت باشند.

این منجر به یک مشکل می‌شود: اگر مجموعه‌ای از پادها (که آنها را "backends" می‌نامیم) عملکردی را برای پادهای دیگر (که آنها را "frontends" می‌نامیم) درون خوشه شما فراهم کنند، ظاهرها چگونه نشانی IP مورد نظر را پیدا کرده و پیگیری می‌کنند تا ظاهر بتواند از بخش پس زمینه بار کاری استفاده کند؟

Enter _Services_.

<!-- body -->

## سرویس‌ها در کوبرنتیز

API سرویس، بخشی از کوبرنتیز، انتزاعی است که به شما کمک می‌کند گروه‌هایی از پادها را از طریق شبکه در معرض نمایش قرار دهید. هر شیء سرویس، مجموعه‌ای منطقی از نقاط پایانی (معمولاً این نقاط پایانی پادها هستند) را به همراه سیاستی در مورد نحوه دسترسی به آن پادها تعریف می‌کند.

برای مثال، یک پس زمینه پردازش تصویر بدون وضعیت را در نظر بگیرید که با ۳ رونوشت در حال اجرا است. این رونوشت ها قابل تعویض هستند و ظاهرها اهمیتی نمی‌دهند که از کدام پس زمینه استفاده می‌کنند. در حالی که پادهای واقعی که مجموعه پس زمینه را تشکیل می‌دهند ممکن است تغییر کنند، کلاینت‌های ظاهر نباید نیازی به آگاهی از این موضوع داشته باشند و همچنین نیازی به پیگیری مجموعه پس زمینه ها توسط خودشان ندارند.

انتزاع سرویس این جداسازی را امکان‌پذیر می‌کند.

مجموعه پادهای مورد هدف یک سرویس معمولاً توسط {{< glossary_tooltip text="selector" term_id="selector" >}} که شما تعریف می‌کنید، تعیین می‌شود.
برای آشنایی با روش‌های دیگر تعریف نقاط پایانی سرویس، به [سرویس‌های _بدون_انتخابگرها](#services-without-selectors) مراجعه کنید.

اگر حجم کاری شما از HTTP استفاده می‌کند، می‌توانید از یک [Ingress](/docs/concepts/services-networking/ingress/) برای کنترل نحوه‌ی رسیدن ترافیک وب به آن حجم کاری استفاده کنید.
Ingress یک نوع سرویس نیست، اما به عنوان نقطه ورود برای خوشه شما عمل می‌کند. Ingress به شما امکان می‌دهد قوانین مسیریابی خود را در یک منبع واحد تجمیع کنید، به طوری که بتوانید چندین مؤلفه از بار کاری خود را که به طور جداگانه در خوشه شما و پشت یک شنونده واحد اجرا می‌شوند، در معرض نمایش قرار دهید.

API [Gateway](https://gateway-api.sigs.k8s.io/#what-is-the-gateway-api) برای کوبرنتیز قابلیت‌های بیشتری فراتر از Ingress و سرویس ارائه می‌دهد. می‌توانید دروازه را به خوشه خود اضافه کنید - این خانواده‌ای از APIهای توسعه‌یافته است که با استفاده از {{< glossary_tooltip term_id="CustomResourceDefinition" text="CustomResourceDefinitions" >}} پیاده‌سازی شده‌اند - و سپس از آنها برای پیکربندی دسترسی به سرویس‌های شبکه‌ای که در خوشه شما در حال اجرا هستند استفاده کنید.

### کشف سرویس بومی ابری

اگر می‌توانید از APIهای کوبرنتیز برای کشف سرویس در برنامه خود استفاده کنید، می‌توانید برای تطبیق EndpointSliceها از {{< glossary_tooltip text="API server" term_id="kube-apiserver" >}} استفاده کنید. کوبرنیتز هر زمان که مجموعه پادها در یک سرویس تغییر کند، EndpointSliceهای یک سرویس را به‌روزرسانی می‌کند.

برای برنامه‌های غیربومی، کوبرنتیز روش‌هایی را برای قرار دادن یک پورت شبکه یا متعادل‌کننده بار بین برنامه شما و پادهای پس زمینه ارائه می‌دهد.

در هر صورت، بار کاری شما می‌تواند از این سازوکارهای [کشف سرویس](#discovering-services) برای یافتن هدفی که می‌خواهد به آن متصل شود، استفاده کند.

## تعریف یک سرویس

یک سرویس یک {{< glossary_tooltip text="object" term_id="object" >}} است (همانطور که یک پاد یا یک ConfigMap یک شیء هستند). شما می‌توانید تعاریف سرویس را با استفاده از API کوبرنتیز ایجاد، مشاهده یا اصلاح کنید. معمولاً از ابزاری مانند `kubectl` برای انجام این فراخوانی‌های API برای خود استفاده می‌کنید.

برای مثال، فرض کنید مجموعه‌ای از پادها دارید که هر کدام به درگاه TCP ۹۳۷۶ گوش می‌دهند و با عنوان `app.kubernetes.io/name=MyApp` برچسب‌گذاری شده‌اند. می‌توانید یک سرویس برای انتشار آن شنونده TCP تعریف کنید:

{{% code_sample file="service/simple-service.yaml" %}}

اعمال این تنظیمات، یک سرویس جدید با نام "my-service" با نوع سرویس پیش‌فرض نشانی خوشه (#publishing-services-service-types) ایجاد می‌کند. این سرویس درگاه TCP 9376 را در هر پاد با برچسب `app.kubernetes.io/name: MyApp` هدف قرار می‌دهد.

کوبرنتیز به این سرویس یک نشانی IP (IP_cluster) اختصاص می‌دهد که توسط سازوکار نشانی IP مجازی استفاده می‌شود. برای جزئیات بیشتر در مورد این سازوکار، [IPهای مجازی و پروکسی‌های سرویس](/docs/reference/networking/virtual-ips/) را مطالعه کنید.

کنترل‌کننده‌ی آن سرویس به‌طور مداوم پادهایی را که با انتخابگر آن مطابقت دارند، اسکن می‌کند و سپس هرگونه به‌روزرسانی لازم را در مجموعه‌ی EndpointSliceهای سرویس انجام می‌دهد.

نام یک شیء سرویس باید یک برچسب معتبر [نام برچسب RFC 1035](/docs/concepts/overview/working-with-objects/names#rfc-1035-label-names) باشد.


{{< note >}}
یک سرویس می‌تواند هر درگاه ورودی را به یک درگاه هدف نگاشت کند. به طور پیش‌فرض و برای راحتی، مقدار درگاه هدف با مقدار بخش درگاه یکسان است.
{{< /note >}}

### تعاریف درگاه {#field-spec-ports}

تعاریف درگاه در پادها نام دارند و شما می‌توانید این نام‌ها را در ویژگی `targetPort` یک سرویس ارجاع دهید. برای مثال، می‌توانیم `targetPort` سرویس را به درگاه پاد به روش زیر متصل کنیم:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app.kubernetes.io/name: proxy
spec:
  containers:
  - name: nginx
    image: nginx:stable
    ports:
      - containerPort: 80
        name: http-web-svc

---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app.kubernetes.io/name: proxy
  ports:
  - name: name-of-service-port
    protocol: TCP
    port: 80
    targetPort: http-web-svc
```

این حتی اگر ترکیبی از پادها در سرویس با یک نام پیکربندی شده واحد وجود داشته باشد، با همان پروتکل شبکه که از طریق شماره درگاه های مختلف در دسترس است، کار می‌کند. این انعطاف‌پذیری زیادی را برای استقرار و تکامل سرویس‌های شما ارائه می‌دهد. به عنوان مثال، می‌توانید شماره درگاه هایی را که پادها در نسخه بعدی نرم‌افزار پس زمینه شما نمایش می‌دهند، بدون ایجاد مشکل برای کلاینت‌ها تغییر دهید.

پروتکل پیش‌فرض برای سرویس‌ها ‎[TCP](/docs/reference/networking/service-protocols/#protocol-tcp)‎ است؛ شما همچنین می‌توانید از هر ‎[پروتکل پشتیبانی‌شده]‎ دیگری ‎(/docs/reference/networking/service-protocols/)‎ استفاده کنید.

از آنجا که بسیاری از سرویس‌ها نیاز به نمایش بیش از یک درگاه دارند، کوبرنتیز از [تعریف چندین درگاه](#multi-port-services) برای یک سرویس واحد پشتیبانی می‌کند. هر تعریف درگاه می‌تواند «پروتکل» یکسان یا متفاوتی داشته باشد.

### سرویس‌های بدون انتخابگر

سرویس‌ها معمولاً به لطف انتخابگر، دسترسی به پادهای کوبرنتیز را انتزاعی می‌کنند، اما وقتی با مجموعه‌ای از اشیاء مربوطه و بدون انتخابگر استفاده می‌شوند، سرویس می‌تواند انواع دیگری از پس زمینه ها، از جمله مواردی که خارج از خوشه اجرا می‌شوند را انتزاعی کند.

برای مثال:

* شما می‌خواهید در محیط عملیاتی یک خوشه پایگاه داده خارجی داشته باشید، اما در محیط تست خود از پایگاه‌های داده خودتان استفاده می‌کنید.
* شما می‌خواهید سرویس خود را به سرویسی در یک {{< glossary_tooltip term_id="namespace" >}} متفاوت یا در یک خوشه دیگر ارجاع دهید.
* شما در حال انتقال یک حجم کاری به کوبرنتیز هستید. هنگام ارزیابی این رویکرد، شما تنها بخشی از پس زمینه های خود را در کوبرنتیز اجرا می‌کنید.

در هر یک از این سناریوها می‌توانید یک سرویس را _بدون_ مشخص کردن یک انتخابگر برای مطابقت با پادها تعریف کنید. برای مثال:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
```

از آنجا که این سرویس هیچ انتخابگری ندارد، اشیاء EndpointSlice مربوطه به طور خودکار ایجاد نمی‌شوند. می‌توانید با اضافه کردن دستی یک شیء EndpointSlice، سرویس را به نشانی و درگاه شبکه‌ای که در آن اجرا می‌شود، نگاشت کنید. برای مثال:

```yaml
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  name: my-service-1 # طبق قرارداد، از نام سرویس استفاده کنید
                     # به عنوان پیشوندی برای نام EndpointSlice
  labels:
    # شما باید برچسب "kubernetes.io/service-name" را تنظیم کنید.
    # مقدار آن را طوری تنظیم کنید که با نام سرویس مطابقت داشته باشد.
    kubernetes.io/service-name: my-service
addressType: IPv4
ports:
  - name: http # باید با نام درگاه سرویس تعریف شده در بالا مطابقت داشته باشد
    appProtocol: http
    protocol: TCP
    port: 9376
endpoints:
  - addresses:
      - "10.4.5.6"
  - addresses:
      - "10.1.2.3"
```

#### Custom EndpointSlices

وقتی یک شیء [EndpointSlice](#endpointslices) برای یک سرویس ایجاد می‌کنید، می‌توانید از هر نامی برای EndpointSlice استفاده کنید. هر EndpointSlice در یک فضای نام باید یک نام منحصر به فرد داشته باشد. شما می‌توانید با تنظیم `kubernetes.io/service-name` {{< glossary_tooltip text="label" term_id="label" >}} روی آن EndpointSlice، یک EndpointSlice را به یک سرویس پیوند دهید.

{{< note >}}
IPهای نقاط پایانی _نباید_ به صورت loopback (127.0.0.0/8 برای IPv4، ::1/128 برای IPv6) یا پیوند-محلی (169.254.0.0/16 و 224.0.0.0/24 برای IPv4، fe80::/64 برای IPv6) باشند.

نشانی های IP نقطه پایانی نمی‌توانند IPهای خوشه‌ای سایر سرویس‌های کوبرنتیز باشند، زیرا {{< glossary_tooltip term_id="kube-proxy" >}} از IPهای مجازی به عنوان مقصد پشتیبانی نمی‌کند.
{{< /note >}}

برای یک EndpointSlice که خودتان یا در کد خودتان ایجاد می‌کنید، باید مقداری را برای برچسب [`endpointslice.kubernetes.io/managed-by`](/docs/reference/labels-annotations-taints/#endpointslicekubernetesiomanaged-by) انتخاب کنید. اگر کد کنترل کننده خودتان را برای مدیریت EndpointSlices ایجاد می‌کنید، استفاده از مقداری مشابه `"my-domain.example/name-of-controller"` را در نظر بگیرید. اگر از یک ابزار شخص ثالث استفاده می‌کنید، نام ابزار را تماماً با حروف کوچک بنویسید و فاصله‌ها و سایر علائم نگارشی را به خط تیره (`-`) تغییر دهید. اگر افراد مستقیماً از ابزاری مانند `kubectl` برای مدیریت EndpointSlices استفاده می‌کنند، از نامی استفاده کنید که این مدیریت دستی را توصیف کند، مانند `"staff"` یا `"cluster-admins"`. شما باید از استفاده از مقدار رزرو شده `"controller"` که EndpointSlices مدیریت شده توسط صفحه کنترل خود کوبرنتیز را مشخص می‌کند، خودداری کنید.

#### دسترسی به یک سرویس بدون انتخابگر {#service-no-selector-access}

دسترسی به یک سرویس بدون انتخابگر مانند زمانی است که یک انتخابگر داشته باشد. در [مثال](#services-without-selectors) برای یک سرویس بدون انتخابگر، ترافیک به یکی از دو نقطه پایانی تعریف شده در تنظیمات EndpointSlice هدایت می‌شود: یک اتصال TCP به 10.1.2.3 یا 10.4.5.6، روی درگاه 9376.

{{< note >}}
سرور کوبرنتیز API اجازه پروکسی کردن به نقاط انتهایی که به پادها نگاشت نشده‌اند را نمی‌دهد. اقداماتی مانند `kubectl port-forward service/<service-name> forwardedPort:servicePort` که در آن سرویس هیچ انتخابگری ندارد، به دلیل این محدودیت با شکست مواجه خواهد شد. این امر مانع از استفاده سرور کوبرنتیز API به عنوان پروکسی برای نقاط انتهایی می‌شود که ممکن است تماس‌گیرنده مجاز به دسترسی به آنها نباشد.
{{< /note >}}

سرویس `ExternalName` نوع خاصی از سرویس است که انتخابگر ندارد و به جای آن از نام‌های DNS استفاده می‌کند. برای اطلاعات بیشتر، به بخش [نام خارجی](#externalname) مراجعه کنید.

### EndpointSlices

{{< feature-state for_k8s_version="v1.21" state="stable" >}}

[EndpointSlices](/docs/concepts/services-networking/endpoint-slices/) اشیایی هستند که زیرمجموعه‌ای (یک _slice_) از نقاط پایانی شبکه پشتیبان برای یک سرویس را نشان می‌دهند.

خوشه کوبرنتیز شما تعداد نقاط پایانی هر EndpointSlice را ردیابی می‌کند. اگر تعداد نقاط پایانی برای یک سرویس آنقدر زیاد باشد که به یک آستانه برسد، کوبرنتیز یک EndpointSlice خالی دیگر اضافه می‌کند و اطلاعات نقاط پایانی جدید را در آنجا ذخیره می‌کند.
به طور پیش‌فرض، کوبرنتیز زمانی یک EndpointSlice جدید ایجاد می‌کند که EndpointSliceهای موجود حداقل شامل ۱۰۰ نقطه پایانی باشند. کوبرنتیز تا زمانی که نیاز به اضافه کردن یک نقطه پایانی اضافی نباشد، EndpointSlice جدید را ایجاد نمی‌کند.

برای اطلاعات بیشتر در مورد این API به [EndpointSlices](/docs/concepts/services-networking/endpoint-slices/) مراجعه کنید.

### نقاط پایانی (منسوخ شده) {#endpoints}

{{< feature-state for_k8s_version="v1.33" state="deprecated" >}}

API EndpointSlice تکامل یافته‌ی API قدیمی‌تر [نقاط پایانی](/docs/reference/kubernetes-api/service-resources/endpoints-v1/) است. API منسوخ شده‌ی نقاط پایانی چندین مشکل نسبت به EndpointSlice دارد:

  - از خوشه‌های دو پشته‌ای پشتیبانی نمی‌کند.
  - این شامل اطلاعات مورد نیاز برای پشتیبانی از ویژگی‌های جدیدتر، مانند [توزیع ترافیک](/docs/concepts/services-networking/service/#traffic-distribution) نیست.
  - اگر لیست نقاط پایانی خیلی طولانی باشد که در یک شیء واحد جا نشود، آن را کوتاه می‌کند.

به همین دلیل، توصیه می‌شود که همه کلاینت‌ها به جای نقاط پایانی از EndpointSlice API استفاده کنند.

#### نقاط پایانی بیش از ظرفیت

کوبرنتیز تعداد نقاط پایانی که می‌توانند در یک شیء نقاط پایانی جای بگیرند را محدود می‌کند. وقتی بیش از ۱۰۰۰ نقطه پایانی پشتیبان برای یک سرویس وجود داشته باشد، کوبرنتیز داده‌های موجود در شیء نقاط پایانی را کوتاه می‌کند. از آنجا که یک سرویس می‌تواند با بیش از یک EndpointSlice مرتبط شود، محدودیت ۱۰۰۰ نقطه پایانی پشتیبان فقط بر API قدیمی نقاط پایانی تأثیر می‌گذارد.

در این حالت، کوبرنتیز حداکثر ۱۰۰۰ نقطه پایانی پس زمینه ممکن را برای ذخیره در شیء نقاط پایانی انتخاب می‌کند و یک {{< glossary_tooltip text="annotation" term_id="annotation" >}} روی نقاط پایانی تنظیم می‌کند:
[`endpoints.kubernetes.io/over-capacity: truncated`](/docs/reference/labels-annotations-taints/#endpoints-kubernetes-io-over-capacity). صفحه کنترل همچنین اگر تعداد پادهای پس زمینه به کمتر از ۱۰۰۰ برسد، آن حاشیه‌نویسی را حذف می‌کند.

ترافیک همچنان به سرورهای پس زمینه ارسال می‌شود، اما هر سازوکار متعادل‌سازی بار که به API قدیمی نقاط پایانی متکی باشد، ترافیک را فقط به حداکثر ۱۰۰۰ تا از نقاط پایانی پس زمینه موجود ارسال می‌کند.

همین محدودیت API به این معنی است که شما نمی‌توانید به صورت دستی یک نقاط پایانی را برای داشتن بیش از ۱۰۰۰ نقطه پایانی به‌روزرسانی کنید.

### پروتکل برنامه

{{< feature-state for_k8s_version="v1.20" state="stable" >}}

بخش `appProtocol` راهی برای مشخص کردن یک پروتکل برنامه برای هر درگاه سرویس ارائه می‌دهد. این به عنوان راهنمایی برای پیاده‌سازی‌ها استفاده می‌شود تا رفتار غنی‌تری را برای پروتکل‌هایی که درک می‌کنند ارائه دهند. مقدار این بخش توسط اشیاء `Endpoints` و `EndpointSlice` مربوطه منعکس می‌شود.

این بخش از دستور زبان استاندارد برچسب کوبرنتیز پیروی می‌کند. مقادیر معتبر یکی از موارد زیر هستند:

* [نام‌های سرویس استاندارد IANA](https://www.iana.org/assignments/service-names).

* نام‌های پیشوندی تعریف‌شده در پیاده‌سازی مانند `mycompany.com/my-custom-protocol`.

* نام‌های پیشوندی تعریف‌شده توسط کوبرنتیز:

| پروتکل | توضیحات |
|----------|-------------|
| `kubernetes.io/h2c` | HTTP/2 روی متن ساده همانطور که در [RFC 7540](https://www.rfc-editor.org/rfc/rfc7540) توضیح داده شده است |
| `kubernetes.io/ws`  | WebSocket روی متن ساده همانطور که در [RFC 6455](https://www.rfc-editor.org/rfc/rfc6455) توضیح داده شده است |
| `kubernetes.io/wss` | WebSocket روی TLS همانطور که در [RFC 6455](https://www.rfc-editor.org/rfc/rfc6455) توضیح داده شده است |

### سرویس های چند-درگاهی

برای برخی از سرویس‌ها، باید بیش از یک درگاه را در معرض نمایش قرار دهید. کوبرنتیز به شما امکان می‌دهد چندین تعریف درگاه را روی یک شیء سرویس پیکربندی کنید. هنگام استفاده از چندین درگاه برای یک سرویس، باید نام همه درگاه های خود را ارائه دهید تا مبهم نباشند. به عنوان مثال:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9377
```

{{< note >}}
همانند کوبرنتیز {{< glossary_tooltip term_id="name" text="names">}} به طور کلی، نام درگاه ها فقط باید شامل کاراکترهای حروف کوچک و عدد و `-` باشد. نام درگاه ها نیز باید با یک کاراکتر حروف و عدد شروع و پایان یابد.

برای مثال، نام‌های `123-abc` و `web` معتبر هستند، اما `123_abc` و `-web` معتبر نیستند.
{{< /note >}}

## نوع سرویس {#publishing-services-service-types}

برای برخی از بخش‌های برنامه‌تان (مثلاً ظاهرها) ممکن است بخواهید یک سرویس را روی یک نشانی IP خارجی قرار دهید، نشانی که از خارج از خوشه شما قابل دسترسی باشد.

انواع سرویس‌های کوبرنتیز به شما این امکان را می‌دهند که نوع سرویس مورد نظر خود را مشخص کنید.

مقادیر `type` موجود و رفتارهای آنها عبارتند از:

[`ClusterIP`](#type-clusterip)
: سرویس را روی یک IP داخلی خوشه نمایش می‌دهد. انتخاب این مقدار باعث می‌شود سرویس فقط از داخل خوشه قابل دسترسی باشد. این مقدار پیش‌فرضی است که در صورت عدم تعیین صریح نوع سرویس استفاده می‌شود. می‌توانید سرویس را با استفاده از [Ingress](/docs/concepts/services-networking/ingress/) یا [Gateway](https://gateway-api.sigs.k8s.io/) در معرض اینترنت عمومی قرار دهید.

[`NodePort`](#type-nodeport)
: سرویس را روی هر IP گره در یک درگاه ایستا ("NodePort") قرار می‌دهد. برای در دسترس قرار دادن درگاه گره، کوبرنتیز یک نشانی IP خوشه تنظیم می‌کند، درست مانند زمانی که شما یک سرویس از نوع "ClusterIP" درخواست کرده‌اید.

[`LoadBalancer`](#loadbalancer)
: سرویس را با استفاده از یک متعادل‌کننده بار خارجی، به صورت خارجی در معرض نمایش قرار می‌دهد. کوبرنتیز مستقیماً یک جزء متعادل‌کننده بار ارائه نمی‌دهد؛ شما باید یکی از آنها را تهیه کنید، یا می‌توانید خوشه کوبرنتیز خود را با یک ارائه‌دهنده ابری ادغام کنید.

[`ExternalName`](#externalname)
: سرویس را به محتویات بخش `externalName` (برای مثال، به نام میزبان `api.foo.bar.example`) نگاشت می‌کند. این نگاشت، سرور DNS خوشه شما را طوری پیکربندی می‌کند که یک ثبت `CNAME` با آن مقدار نام میزبان خارجی برگرداند. هیچ نوع پروکسی تنظیم نشده است.

بخش `type` در API سرویس به صورت تودرتو طراحی شده است - هر سطح به سطح قبلی اضافه می‌شود. با این حال، یک استثنا در این طراحی تودرتو وجود دارد. شما می‌توانید یک سرویس `LoadBalancer` را با غیرفعال کردن تخصیص `NodePort` برای متعادل‌کننده بار تعریف کنید. (/docs/concepts/services-networking/service/#load-balancer-nodeport-allocation).

### `type: ClusterIP` {#type-clusterip}

این نوع سرویس پیش‌فرض، یک نشانی IP را از مجموعه‌ای از نشانی های IP که خوشه شما برای این منظور رزرو کرده است، اختصاص می‌دهد.

چندین نوع دیگر برای سرویس، بر اساس نوع `ClusterIP` به عنوان پایه ساخته می‌شوند.

اگر سرویسی تعریف کنید که `.spec.clusterIP` آن روی `None` تنظیم شده باشد، کوبرنتیز نشانی IP اختصاص نمی‌دهد. برای اطلاعات بیشتر به [سرویس های بدون سر](#headless-services) مراجعه کنید.

#### انتخاب نشانی IP خودتان

شما می‌توانید نشانی IP خوشه خود را به عنوان بخشی از درخواست ایجاد `Service` مشخص کنید. برای انجام این کار، بخش `.spec.clusterIP` را تنظیم کنید. به عنوان مثال، اگر از قبل یک ورودی DNS موجود دارید که می‌خواهید دوباره از آن استفاده کنید، یا سیستم‌های قدیمی که برای یک نشانی IP خاص پیکربندی شده‌اند و پیکربندی مجدد آنها دشوار است.

نشانی IP که انتخاب می‌کنید باید یک نشانی IPv4 یا IPv6 معتبر از محدوده CIDR `service-cluster-ip-range` باشد که برای سرور API پیکربندی شده است. اگر سعی کنید سرویسی با مقدار نشانی `clusterIP` نامعتبر ایجاد کنید، سرور API یک کد وضعیت HTTP 422 را برای نشان دادن وجود مشکل برمی‌گرداند.

برای آشنایی با نحوه‌ی کمک کوبرنتیز به کاهش ریسک و تأثیر دو سرویس مختلف که هر دو سعی در استفاده از یک نشانی IP دارند، [اجتناب از برخورد](/docs/reference/networking/virtual-ips/#avoiding-collisions) را مطالعه کنید.

### `type: NodePort` {#type-nodeport}

اگر بخش `type` را روی `NodePort` تنظیم کنید، صفحه کنترل کوبرنتیز یک درگاه از محدوده مشخص شده توسط پرچم `--service-node-port-range` (پیش‌فرض: 30000-32767) اختصاص می‌دهد. هر گره آن پورت (شماره درگاه یکسان در هر گره) را به سرویس شما پروکسی می‌کند. سرویس شما درگاه اختصاص داده شده را در بخش `.spec.ports[*].nodePort` خود گزارش می‌دهد.

استفاده از درگاه گره به شما این آزادی را می‌دهد که راهکار متعادل‌سازی بار خودتان را راه‌اندازی کنید، محیط‌هایی را که به طور کامل توسط کوبرنتیز پشتیبانی نمی‌شوند پیکربندی کنید، یا حتی نشانی های IP یک یا چند گره را مستقیماً در معرض نمایش قرار دهید.

برای یک سرویس درگاه گره، کوبرنتیز علاوه بر این، یک درگاه (TCP، UDP یا SCTP برای مطابقت با پروتکل سرویس) اختصاص می‌دهد. هر گره در خوشه خود را طوری پیکربندی می‌کند که به آن درگاه اختصاص داده شده گوش دهد و ترافیک را به یکی از نقاط پایانی آماده مرتبط با آن سرویس ارسال کند. شما می‌توانید با اتصال به هر گره با استفاده از پروتکل مناسب (به عنوان مثال: TCP) و درگاه مناسب (همانطور که به آن سرویس اختصاص داده شده است) از خارج از خوشه با سرویس `type: NodePort` تماس بگیرید.

#### انتخاب درگاه دلخواه {#nodeport-custom-port}

اگر شماره درگاه خاصی می‌خواهید، می‌توانید مقداری را در بخش `nodePort` مشخص کنید. صفحه کنترل یا آن درگاه را به شما اختصاص می‌دهد یا گزارش می‌دهد که تراکنش API ناموفق بوده است. این بدان معناست که شما باید خودتان مراقب تداخل‌های احتمالی درگاه باشید. همچنین باید از یک شماره درگاه معتبر استفاده کنید، شماره درگاهی که در محدوده پیکربندی شده برای استفاده از درگاه گره باشد.

در اینجا یک مثال برای تنظیمات سرویسی با نوع درگاه گره که مقدار درگاه گره (در این مثال 30007) را مشخص می‌کند، آورده شده است:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - port: 80
      # به طور پیش‌فرض و برای راحتی، مقدار `targetPort` با
      # مقدار بخش `port` یکسان است.
      targetPort: 80
      # بخش اختیاری
      # به طور پیش‌فرض و برای راحتی، صفحه کنترل کوبرنتیز
      # یک پورت از یک محدوده (پیش‌فرض: 30000-32767) اختصاص می‌دهد.
      nodePort: 30007
```

#### رزرو محدوده های درگاه گره برای جلوگیری از تصادم {#avoid-nodeport-collisions}

سیاست اختصاص درگاه ها به سرویس‌های درگاه گره هم برای سناریوهای اختصاص خودکار و هم برای سناریوهای اختصاص دستی اعمال می‌شود. وقتی کاربری می‌خواهد یک سرویس درگاه گره ایجاد کند که از یک درگاه خاص استفاده کند، درگاه هدف ممکن است با درگاه دیگری که قبلاً اختصاص داده شده است، تداخل داشته باشد.

برای جلوگیری از این مشکل، محدوده درگاه برای سرویس‌های درگاه گره به دو باند تقسیم می‌شود. تخصیص درگاه پویا به طور پیش‌فرض از باند بالایی استفاده می‌کند و ممکن است پس از اتمام باند بالایی، از باند پایینی استفاده کند. سپس کاربران می‌توانند با ریسک کمتر تصادم درگاه، از باند پایینی تخصیص دهند.

#### پیکربندی نشانی IP سفارشی برای سرویس‌های `type: NodePort` {#service-nodeport-custom-listen-address}

شما می‌توانید گره‌ها را در خوشه خود طوری تنظیم کنید که از یک نشانی IP خاص برای ارائه خدمات درگاه گره استفاده کنند. اگر هر گره به چندین شبکه متصل است (برای مثال: یک شبکه برای ترافیک برنامه و شبکه دیگر برای ترافیک بین گره‌ها و صفحه کنترل)، ممکن است بخواهید این کار را انجام دهید.

اگر می‌خواهید نشانی های IP خاصی را برای پروکسی درگاه مشخص کنید، می‌توانید پرچم `--nodeport-addresses` را برای kube-proxy یا بخش معادل `nodePortAddresses` از [پرونده پیکربندی kube-proxy](/docs/reference/config-api/kube-proxy-config.v1alpha1/) را روی بلوک(های) IP خاص تنظیم کنید.

این پرچم، فهرستی از بلوک‌های IP را که با کاما از هم جدا شده‌اند (مثلاً `10.0.0.0/8`، `192.0.2.0/25`) دریافت می‌کند تا محدوده نشانی های IP را که kube-proxy باید به عنوان نشانی های محلی این گره در نظر بگیرد، مشخص کند.

برای مثال، اگر kube-proxy را با پرچم `--nodeport-addresses=127.0.0.0/8` شروع کنید، kube-proxy فقط رابط loopback را برای سرویس‌های درگاه گره انتخاب می‌کند. پیش‌فرض برای `--nodeport-addresses` یک لیست خالی است. این بدان معناست که kube-proxy باید تمام رابط‌های شبکه موجود برای درگاه گره را در نظر بگیرد. (این با نسخه‌های قبلی کوبرنتیز نیز سازگار است.)
{{< note >}}
این سرویس با نام‌های `<NodeIP>:spec.ports[*].nodePort` و `.spec.clusterIP:spec.ports[*].port` قابل مشاهده است. اگر علامت `--nodeport-addresses` برای kube-proxy یا بخش معادل آن در پرونده پیکربندی kube-proxy تنظیم شده باشد، `<NodeIP>` یک نشانی IP گره (یا احتمالاً نشانی های IP) فیلتر شده خواهد بود.
{{< /note >}}

### `type: LoadBalancer` {#loadbalancer}

در ارائه‌دهندگان ابری که از متعادل‌کننده‌های بار خارجی پشتیبانی می‌کنند، تنظیم بخش `type` روی `LoadBalancer`، یک متعادل‌کننده بار برای سرویس شما فراهم می‌کند. ایجاد متعادل‌کننده بار به صورت ناهمزمان اتفاق می‌افتد و اطلاعات مربوط به متعادل‌کننده ارائه شده در بخش `.status.loadBalancer` سرویس منتشر می‌شود.
برای مثال:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  clusterIP: 10.0.171.239
  type: LoadBalancer
status:
  loadBalancer:
    ingress:
    - ip: 192.0.2.127
```

ترافیک از متعادل‌کننده بار خارجی به سمت پادهای پس زمینه هدایت می‌شود. ارائه‌دهنده ابر تصمیم می‌گیرد که چگونه متعادل‌کننده بار شود.

برای پیاده‌سازی سرویسی با `type: LoadBalancer`، کوبرنتیز معمولاً با ایجاد تغییراتی معادل درخواست شما برای سرویسی با `type: NodePort` شروع می‌کند. سپس مؤلفه‌ی cloud-controller-manager، متعادل‌کننده‌ی بار خارجی را طوری پیکربندی می‌کند که ترافیک را به درگاه گره‌ی اختصاص داده شده هدایت کند.

شما می‌توانید یک سرویس متعادل‌سازی بار را طوری پیکربندی کنید که یک درگاه گره را اختصاص دهد، مشروط بر اینکه پیاده‌سازی ارائه‌دهنده ابری از این پشتیبانی کند.

برخی از ارائه‌دهندگان ابری به شما اجازه می‌دهند `loadBalancerIP` را مشخص کنید. در این موارد، متعادل‌کننده بار با `loadBalancerIP` مشخص‌شده توسط کاربر ایجاد می‌شود. اگر بخش `loadBalancerIP` مشخص نشده باشد، متعادل‌کننده بار با یک نشانی IP موقت تنظیم می‌شود. اگر `loadBalancerIP` را مشخص کنید اما ارائه‌دهنده ابری شما از این ویژگی پشتیبانی نکند، بخش `loadbalancerIP` که تنظیم کرده‌اید نادیده گرفته می‌شود.


{{< note >}}
بخش `.spec.loadBalancerIP` برای یک سرویس در کوبرنتیز نسخه ۱.۲۴ منسوخ شده است.

این بخش به طور کامل مشخص نشده بود و معنی آن در پیاده‌سازی‌های مختلف متفاوت است. همچنین نمی‌تواند از شبکه‌های دو پشته‌ای پشتیبانی کند. این بخش ممکن است در نسخه‌های بعدی API حذف شود.

اگر با ارائه‌دهنده‌ای ادغام می‌شوید که از مشخص کردن نشانی های IP متعادل‌کننده بار برای یک سرویس از طریق حاشیه‌نویسی (مخصوص ارائه‌دهنده) پشتیبانی می‌کند، باید به انجام آن تغییر دهید.

اگر در حال نوشتن کد برای ادغام متعادل‌کننده بار با کوبرنتیز هستید، از استفاده از این بخش خودداری کنید. می‌توانید به جای Service، با [دروازه](https://gateway-api.sigs.k8s.io/) ادغام شوید، یا می‌توانید حاشیه‌نویسی‌های (مختص ارائه‌دهنده) خودتان را روی Service تعریف کنید که جزئیات معادل را مشخص می‌کنند.
{{< /note >}}

#### تأثیر زنده بودن گره بر ترافیک متعادل‌کننده بار

بررسی‌های سلامت متعادل‌کننده بار برای برنامه‌های مدرن بسیار مهم هستند. از آنها برای تعیین اینکه متعادل‌کننده بار باید ترافیک را به کدام سرور (ماشین مجازی یا نشانی IP) ارسال کند، استفاده می‌شود. APIهای کوبرنتیز نحوه پیاده‌سازی بررسی‌های سلامت را برای متعادل‌کننده‌های بار مدیریت‌شده کوبرنتیز تعریف نمی‌کنند، در عوض، ارائه‌دهندگان ابر (و افرادی که کد ادغام را پیاده‌سازی می‌کنند) هستند که در مورد رفتار تصمیم می‌گیرند. بررسی‌های سلامت متعادل‌کننده بار به طور گسترده در زمینه پشتیبانی از بخش «سیاست ترافیک خارجی» برای سرویس‌ها استفاده می‌شوند.

#### متعادل‌کننده‌های بار با انواع پروتکل‌های مختلط

{{< feature-state feature_gate_name="MixedProtocolLBService" >}}

به طور پیش‌فرض، برای سرویس‌های نوع متعادل کننده بار، وقتی بیش از یک درگاه تعریف شده باشد، همه درگاه ها باید پروتکل یکسانی داشته باشند و این پروتکل باید توسط ارائه‌دهنده ابری پشتیبانی شود.

قابلیت «سرویس ترکیبی پروتکل‌های LB» (که به طور پیش‌فرض برای kube-apiser از نسخه ۱.۲۴ فعال شده است) امکان استفاده از پروتکل‌های مختلف برای سرویس‌های نوع متعادل کننده بار را فراهم می‌کند، زمانی که بیش از یک درگاه تعریف شده باشد.

{{< note >}}
مجموعه پروتکل‌هایی که می‌توانند برای سرویس‌های متعادل‌سازی بار استفاده شوند، توسط ارائه‌دهنده ابری شما تعریف می‌شوند؛ آن‌ها ممکن است محدودیت‌هایی فراتر از آنچه API کوبرنتیز اعمال می‌کند، اعمال کنند.
{{< /note >}}

#### غیرفعال کردن تخصیص درگاه گره در متعادل‌کننده بار {#load-balancer-nodeport-allocation}

{{< feature-state for_k8s_version="v1.24" state="stable" >}}

شما می‌توانید به صورت اختیاری تخصیص درگاه گره را برای سرویسی از نوع `LoadBalancer` غیرفعال کنید، برای این کار بخش `spec.allocateLoadBalancerNodePorts` را روی `false` تنظیم کنید. این فقط باید برای پیاده‌سازی‌های متعادل‌کننده بار استفاده شود که ترافیک را مستقیماً به پادها هدایت می‌کنند، نه اینکه از درگاه های گره استفاده کنند. به طور پیش‌فرض، `spec.allocateLoadBalancerNodePorts` روی `true` تنظیم شده است و سرویس‌های نوع متعادل کننده بار به تخصیص درگاه های گره ادامه خواهند داد. اگر `spec.allocateLoadBalancerNodePorts` در یک سرویس موجود با درگاه های گره اختصاص داده شده روی `false` تنظیم شود، آن درگاه‌های گره به طور خودکار از تخصیص خارج نمی‌شوند. برای از تخصیص خارج کردن آن درگاه‌های گره، باید ورودی `nodePorts` را در هر درگاه سرویس به صراحت حذف کنید.

#### مشخص کردن کلاس پیاده‌سازی متعادل‌کننده بار {#load-balancer-class}

{{< feature-state for_k8s_version="v1.24" state="stable" >}}

برای سرویسی که `type` آن روی `LoadBalancer` تنظیم شده باشد، بخش `.spec.loadBalancerClass` به شما این امکان را می‌دهد که از پیاده‌سازی متعادل‌کننده بار دیگری غیر از پیش‌فرض ارائه‌دهنده ابری استفاده کنید.

به طور پیش‌فرض، `.spec.loadBalancerClass` تنظیم نشده است و نوع سرویس `LoadBalancer` از پیاده‌سازی متعادل‌کننده بار پیش‌فرض ارائه‌دهنده ابر استفاده می‌کند اگر خوشه با یک ارائه‌دهنده ابر با استفاده از پرچم مؤلفه `--cloud-provider` پیکربندی شده باشد.

اگر `.spec.loadBalancerClass` را مشخص کنید، فرض بر این است که یک پیاده‌سازی متعادل‌کننده بار که با کلاس مشخص‌شده مطابقت دارد، سرویس‌ها را زیر نظر دارد. هر پیاده‌سازی متعادل‌کننده بار پیش‌فرض (به عنوان مثال، پیاده‌سازی ارائه‌شده توسط ارائه‌دهنده ابر) سرویس‌هایی را که این بخش را دارند، نادیده می‌گیرد. `spec.loadBalancerClass` را می‌توان فقط روی سرویسی از نوع `LoadBalancer` تنظیم کرد. پس از تنظیم، نمی‌توان آن را تغییر داد. مقدار `spec.loadBalancerClass` باید یک شناسه به سبک برچسب باشد، با یک پیشوند اختیاری مانند "`internal-vip`" یا "`example.com/internal-vip`". نام‌های بدون پیشوند برای کاربران نهایی رزرو شده‌اند.

#### حالت نشانی IP متعادل کننده بار {#load-balancer-ip-mode}

{{< feature-state feature_gate_name="LoadBalancerIPMode" >}}

برای سرویسی با نوع `type: LoadBalancer`، یک کنترل کننده می‌تواند `.status.loadBalancer.ingress.ipMode` را تنظیم کند. `.status.loadBalancer.ingress.ipMode` نحوه رفتار IP متعادل‌کننده بار را مشخص می‌کند. این مقدار فقط زمانی می‌تواند تعیین شود که بخش `.status.loadBalancer.ingress.ip` نیز مشخص شده باشد.

دو مقدار برای `.status.loadBalancer.ingress.ipMode` وجود دارد: "VIP" و "Proxy". مقدار پیش‌فرض "VIP" است، به این معنی که ترافیک به گره تحویل داده می‌شود و مقصد آن IP و درگاه متعادل‌کننده بار تنظیم شده است. بسته به نحوه تحویل ترافیک توسط متعادل‌کننده بار از ارائه‌دهنده ابری، دو حالت برای تنظیم این مقدار روی "Proxy" وجود دارد:

- اگر ترافیک به گره تحویل داده شود و سپس به پاد منتقل شود، مقصد روی IP و درگاه گره تنظیم می‌شود؛
- اگر ترافیک مستقیماً به پاد تحویل داده شود، مقصد روی IP و درگاه پاد تنظیم می‌شود.

پیاده‌سازی‌های سرویس ممکن است از این اطلاعات برای تنظیم مسیریابی ترافیک استفاده کنند.

#### متعادل کننده بار داخلی

در یک محیط ترکیبی، گاهی اوقات لازم است که ترافیک از سرویس‌ها درون یک بلوک نشانی شبکه (مجازی) یکسان مسیریابی شود.

در یک محیط DNS با قابلیت Split-Horizon، برای اینکه بتوانید ترافیک خارجی و داخلی را به سمت نقاط پایانی خود هدایت کنید، به دو سرویس نیاز خواهید داشت.

برای تنظیم یک متعادل‌کننده بار داخلی، بسته به ارائه‌دهنده خدمات ابری که استفاده می‌کنید، یکی از حاشیه‌نویسی‌های زیر را به سرویس خود اضافه کنید:

{{< tabs name="service_tabs" >}}
{{% tab name="Default" %}}
Select one of the tabs.
{{% /tab %}}

{{% tab name="GCP" %}}

```yaml
metadata:
  name: my-service
  annotations:
    networking.gke.io/load-balancer-type: "Internal"
```
{{% /tab %}}
{{% tab name="AWS" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
```

{{% /tab %}}
{{% tab name="Azure" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/azure-load-balancer-internal: "true"
```

{{% /tab %}}
{{% tab name="IBM Cloud" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.kubernetes.io/ibm-load-balancer-cloud-provider-ip-type: "private"
```

{{% /tab %}}
{{% tab name="OpenStack" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/openstack-internal-load-balancer: "true"
```

{{% /tab %}}
{{% tab name="Baidu Cloud" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/cce-load-balancer-internal-vpc: "true"
```

{{% /tab %}}
{{% tab name="Tencent Cloud" %}}

```yaml
metadata:
  annotations:
    service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-xxxxx
```

{{% /tab %}}
{{% tab name="Alibaba Cloud" %}}

```yaml
metadata:
  annotations:
    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-address-type: "intranet"
```

{{% /tab %}}
{{% tab name="OCI" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/oci-load-balancer-internal: true
```
{{% /tab %}}
{{< /tabs >}}

### `type: ExternalName` {#externalname}

سرویس‌هایی از نوع نام خارجی، یک سرویس را به یک نام DNS نگاشت می‌کنند، نه به یک انتخابگر معمولی مانند `my-service` یا `cassandra`. شما این سرویس‌ها را با پارامتر `spec.externalName` مشخص می‌کنید.

برای مثال، این تعریف سرویس، سرویس `my-service` را در فضای نام `prod` به `my.database.example.com` نگاشت می‌کند:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com
```

{{< note >}}
سرویسی با نوع «نام خارجی» یک رشته نشانی IPv4 را می‌پذیرد، اما آن رشته را به عنوان یک نام DNS متشکل از اعداد در نظر می‌گیرد، نه به عنوان یک نشانی IP (با این حال، اینترنت چنین نام‌هایی را در DNS مجاز نمی‌داند). سرویس‌هایی با نام‌های خارجی که شبیه نشانی های IPv4 هستند، توسط سرورهای DNS شناسایی نمی‌شوند.

اگر می‌خواهید یک سرویس را مستقیماً به یک نشانی IP خاص نگاشت کنید، استفاده از [سرویس‌های بدون سر](#headless-services) را در نظر بگیرید.
{{< /note >}}

هنگام جستجوی میزبان `my-service.prod.svc.cluster.local`، سرویس DNS خوشه یک ثبت `CNAME` با مقدار `my.database.example.com` برمی‌گرداند. دسترسی به `my-service` مانند سایر سرویس‌ها عمل می‌کند، اما با این تفاوت اساسی که تغییر مسیر در سطح DNS اتفاق می‌افتد، نه از طریق پروکسی یا بازارسال. اگر بعداً تصمیم به انتقال پایگاه داده خود به خوشه خود گرفتید، می‌توانید پادهای آن را راه‌اندازی کنید، انتخابگرها یا نقاط انتهایی مناسب را اضافه کنید و `type` سرویس را تغییر دهید.

{{< caution >}}
ممکن است در استفاده از نام خارجی برای برخی از پروتکل‌های رایج، از جمله HTTP و HTTPS، با مشکل مواجه شوید. اگر از نام خارجی استفاده می‌کنید، نام میزبان مورد استفاده توسط کلاینت‌های درون خوشه شما با نامی که نام خارجی به آن ارجاع می‌دهد، متفاوت است.

برای پروتکل‌هایی که از نام‌های میزبان استفاده می‌کنند، این تفاوت ممکن است منجر به خطا یا پاسخ‌های غیرمنتظره شود. درخواست‌های HTTP دارای سرآیند `Host:` خواهند بود که سرور مبدا آن را تشخیص نمی‌دهد؛ سرورهای TLS قادر به ارائه گواهی‌نامه‌ای مطابق با نام میزبانی که کلاینت به آن متصل شده است، نخواهند بود.
{{< /caution >}}

## سرویس های بدون سر

گاهی اوقات به متعادل‌سازی بار و یک سرویس IP واحد نیاز ندارید. در این حالت، می‌توانید با مشخص کردن صریح `"None"` برای نشانی IP خوشه (`.spec.clusterIP`)، سرویس‌هایی را ایجاد کنید که به آنها سرویس‌های بدون سر گفته می‌شود.

شما می‌توانید از یک سرویس بدون سر برای ارتباط با سایر سازوکارهای کشف سرویس استفاده کنید، بدون اینکه به پیاده‌سازی کوبرنتیز وابسته باشید.

برای سرویس‌های بدون سر، IP خوشه اختصاص داده نمی‌شود، kube-proxy این سرویس‌ها را مدیریت نمی‌کند و هیچ متعادل‌سازی بار یا پروکسی برای آنها توسط بستر انجام نمی‌شود.

یک سرویس بدون سر به کلاینت اجازه می‌دهد تا مستقیماً به هر پادی که ترجیح می‌دهد متصل شود. سرویس‌هایی که بدون سر هستند، مسیرها و ارسال بسته را با استفاده از [نشانی های IP مجازی و پروکسی‌ها](/docs/reference/networking/virtual-ips/) پیکربندی نمی‌کنند. در عوض، سرویس‌های بدون سر، نشانی های IP نقطه انتهایی پادهای منفرد را از طریق ثبت های DNS داخلی گزارش می‌دهند که از طریق [سرویس DNS](/docs/concepts/services-networking/dns-pod-service/) خوشه ارائه می‌شوند. برای تعریف یک سرویس بدون سر، شما یک سرویس با `.spec.type` تنظیم شده روی IP خوشه (که همچنین پیش‌فرض برای `type` است) ایجاد می‌کنید، و علاوه بر آن `.spec.clusterIP` را روی None تنظیم می‌کنید.

مقدار رشته‌ای None یک مورد خاص است و با تنظیم نکردن بخش `.spec.clusterIP` یکسان نیست.

نحوه پیکربندی خودکار DNS بستگی به این دارد که آیا سرویس دارای انتخابگرهای تعریف شده است یا خیر:

### با انتخابگرها

برای سرویس‌های بدون سر که انتخابگرها را تعریف می‌کنند، کنترل‌کننده نقاط پایانی، EndpointSliceها را در کوبرنتیز API ایجاد می‌کند و پیکربندی DNS را برای بازگرداندن ثبت های A یا AAAA (نشانی های IPv4 یا IPv6) که مستقیماً به پادهای پشتیبان سرویس اشاره می‌کنند، تغییر می‌دهد.

### بدون انتخابگرها

برای سرویس‌های بدون سر که انتخابگرها را تعریف نمی‌کنند، صفحه کنترل اشیاء EndpointSlice را ایجاد نمی‌کند. با این حال، سیستم DNS به دنبال موارد زیر می‌گردد و آنها را پیکربندی می‌کند:

* ثبت های DNS CNAME برای سرویس‌های [`type: ExternalName`](#externalname)
* ثبت های DNS A / AAAA برای تمام نشانی های IP نقاط پایانی آماده سرویس،
برای همه انواع سرویس به غیر از `ExternalName`.
  * برای نقاط پایانی IPv4، سیستم DNS ثبت های A ایجاد می‌کند.
  * برای نقاط پایانی IPv6، سیستم DNS ثبت های AAAA ایجاد می‌کند.

وقتی یک سرویس بدون سر را بدون انتخابگر تعریف می‌کنید، `port` باید با `targetPort` مطابقت داشته باشد.

## کشف سرویس‌ها

برای کلاینت‌هایی که درون خوشه شما اجرا می‌شوند، کوبرنتیز از دو حالت اصلی برای یافتن یک سرویس پشتیبانی می‌کند: متغیرهای محیطی و DNS.
### متغیرهای محیطی

وقتی یک پاد روی یک گره اجرا می‌شود، kubelet مجموعه‌ای از متغیرهای محیطی را برای هر سرویس فعال اضافه می‌کند. این برنامه متغیرهای `{SVCNAME}_SERVICE_HOST` و `{SVCNAME}_SERVICE_PORT` را اضافه می‌کند، که در آن نام سرویس با حروف بزرگ نوشته می‌شود و خط تیره به زیرخط تبدیل می‌شود.


برای مثال، سرویس «redis-primary» که درگاه TCP 6379 را در معرض نمایش قرار می‌دهد و نشانی IP خوشه 10.0.0.11 به آن اختصاص داده شده است، متغیرهای محیطی زیر را تولید می‌کند:

```shell
REDIS_PRIMARY_SERVICE_HOST=10.0.0.11
REDIS_PRIMARY_SERVICE_PORT=6379
REDIS_PRIMARY_PORT=tcp://10.0.0.11:6379
REDIS_PRIMARY_PORT_6379_TCP=tcp://10.0.0.11:6379
REDIS_PRIMARY_PORT_6379_TCP_PROTO=tcp
REDIS_PRIMARY_PORT_6379_TCP_PORT=6379
REDIS_PRIMARY_PORT_6379_TCP_ADDR=10.0.0.11
```

{{< note >}}
وقتی یک پاد دارید که نیاز به دسترسی به یک سرویس دارد و از متد متغیر محیطی برای انتشار درگاه و IP خوشه به پادهای کلاینت استفاده می‌کنید، باید سرویس را *قبل* از اینکه پادهای کلاینت به وجود بیایند، ایجاد کنید. در غیر این صورت، آن پادهای کلاینت متغیرهای محیطی خود را نخواهند داشت.

اگر فقط از DNS برای کشف IP خوشه یک سرویس استفاده می‌کنید، لازم نیست نگران این مشکل ترتیب باشید.
{{< /note >}}

کوبرنتیز همچنین از متغیرهایی پشتیبانی و ارائه می‌دهد که با ویژگی "_[legacy container links](https://docs.docker.com/network/links/)_" موتور داکر سازگار هستند. می‌توانید [`makeLinkVariables`](https://github.com/kubernetes/kubernetes/blob/dd2d12f6dc0e654c15d5db57a5f9f6ba61192726/pkg/kubelet/envvars/envvars.go#L72) را مطالعه کنید تا ببینید چگونه این ویژگی در کوبرنتیز پیاده‌سازی شده است.

### DNS

شما می‌توانید (و تقریباً همیشه باید) با استفاده از [افزونه](/docs/concepts/cluster-administration/addons/) یک سرویس DNS برای خوشه کوبرنتیز خود راه‌اندازی کنید.

یک سرور DNS آگاه از خوشه، مانند CoreDNS، API کوبرنتیز را برای سرویس‌های جدید زیر نظر می‌گیرد و مجموعه‌ای از ثبت های DNS را برای هر یک ایجاد می‌کند. اگر DNS در سراسر خوشه شما فعال شده باشد، تمام پادها باید به طور خودکار بتوانند سرویس‌ها را با نام DNS خود شناسایی کنند.

برای مثال، اگر سرویسی به نام `my-service` در فضای نام کوبرنتیز `my-ns` دارید، صفحه کنترل و سرویس DNS با همکاری یکدیگر یک ثبت DNS برای `my-service.my-ns` ایجاد می‌کنند. پادهای موجود در فضای نام `my-ns` باید بتوانند با جستجوی نام `my-service`، سرویس را پیدا کنند (`my-service.my-ns` نیز کار می‌کند).

پادها در سایر فضاهای نام باید نام را به صورت `my-service.my-ns` تعریف کنند. این نام‌ها به IP خوشه اختصاص داده شده برای سرویس تبدیل می‌شوند.

کوبرنتیز همچنین از ثبت های DNS SRV (سرویس) برای درگاه های نامگذاری شده پشتیبانی می‌کند. اگر سرویس `my-service.my-ns` دارای درگاهی به نام `http` با پروتکل تنظیم شده روی `TCP` باشد، می‌توانید یک پرس و جوی DNS SRV برای `_http._tcp.my-service.my-ns` انجام دهید تا شماره درگاه `http` و همچنین نشانی IP را پیدا کنید.

سرور DNS کوبرنتیز تنها راه دسترسی به سرویس‌های `ExternalName` است. می‌توانید اطلاعات بیشتر در مورد وضوح `ExternalName` را در [DNS برای سرویس‌ها و پادها](/docs/concepts/services-networking/dns-pod-service/) بیابید.

<!-- preserve existing hyperlinks -->
<a id="shortcomings" />
<a id="the-gory-details-of-virtual-ips" />
<a id="proxy-modes" />
<a id="proxy-mode-userspace" />
<a id="proxy-mode-iptables" />
<a id="proxy-mode-ipvs" />
<a id="ips-and-vips" />

## سازوکار نشانی دهی IP مجازی

بخش [IPهای مجازی و پروکسی‌های سرویس](/docs/reference/networking/virtual-ips/) را مطالعه کنید تا سازوکاری که کوبرنتیز برای نمایش یک سرویس با یک نشانی IP مجازی ارائه می‌دهد را توضیح دهد.

### سیاست‌های ترافیک

شما می‌توانید بخش های `.spec.internalTrafficPolicy` و `.spec.externalTrafficPolicy` را تنظیم کنید تا نحوه هدایت ترافیک توسط کوبرنتیز به سمت پس زمینه های سالم ("ready") را کنترل کنید.

برای جزئیات بیشتر به [سیاست‌های ترافیک](/docs/reference/networking/virtual-ips/#traffic-policies) مراجعه کنید.

### توزیع ترافیک

{{< feature-state feature_gate_name="ServiceTrafficDistribution" >}}

بخش `.spec.trafficDistribution` راه دیگری برای تأثیرگذاری بر مسیریابی ترافیک در یک سرویس کوبرنتیز فراهم می‌کند. در حالی که سیاست‌های ترافیک بر تضمین‌های معنایی دقیق تمرکز دارند، توزیع ترافیک به شما امکان می‌دهد تنظیمات دلخواه خود را بیان کنید (مانند مسیریابی به نقاط انتهایی از نظر توپولوژیکی نزدیک‌تر). این می‌تواند به بهینه‌سازی عملکرد، هزینه یا قابلیت اطمینان کمک کند. در کوبرنتیز {{< skew currentVersion >}}، مقدار بخش زیر پشتیبانی می‌شود:

`PreferClose`
: نشان‌دهنده‌ی ترجیح مسیریابی ترافیک به نقاط پایانی است که در همان منطقه‌ی کلاینت قرار دارند.

{{< feature-state feature_gate_name="PreferSameTrafficDistribution" >}}

دو مقدار اضافی زمانی که `PreferSameTrafficDistribution`
[دروازه ویژگی](/docs/reference/command-line-tools-reference/feature-gates/) فعال باشد، در دسترس هستند:

`PreferSameZone`
: این یک نام مستعار برای `PreferClose` است که معنای مورد نظر را واضح‌تر بیان می‌کند.

`PreferSameNode`
: نشان‌دهنده‌ی ترجیح مسیریابی ترافیک به نقاط پایانی است که در همان گره کلاینت قرار دارند.

اگر بخش تنظیم نشده باشد، پیاده‌سازی، راهبرد مسیریابی پیش‌فرض خود را اعمال خواهد کرد.

برای جزئیات بیشتر به [توزیع ترافیک](/docs/reference/networking/virtual-ips/#traffic-distribution) مراجعه کنید.

### چسبندگی جلسه

اگر می‌خواهید مطمئن شوید که اتصالات از یک کلاینت خاص هر بار به یک پاد منتقل می‌شوند، می‌توانید وابستگی نشست را بر اساس نشانی IP کلاینت پیکربندی کنید. برای کسب اطلاعات بیشتر [ وابستگی نشست ](/docs/reference/networking/virtual-ips/#session-affinity) را مطالعه کنید.

## IP های خارجی

اگر IP های خارجی وجود داشته باشند که به یک یا چند گره خوشه مسیر یابی کنند، سرویس‌های کوبرنتیز می‌توانند در آن «IP های خارجی» نمایش داده شوند. هنگامی که ترافیک شبکه به خوشه می‌رسد، با IP خارجی (به عنوان IP مقصد) و درگاهی که با آن سرویس مطابقت دارد، قوانین و مسیرهایی که کوبرنتیز پیکربندی کرده است، اطمینان حاصل می‌کنند که ترافیک به یکی از نقاط پایانی آن سرویس مسیر یابی می‌شود.

وقتی یک سرویس تعریف می‌کنید، می‌توانید برای هر نوع سرویسی (#publishing-services-service-types) `externalIP` تعیین کنید. در مثال زیر، سرویسی با نام `my-service` می‌تواند توسط کلاینت‌هایی که از TCP استفاده می‌کنند، روی `"198.51.100.32:80"` (محاسبه شده از `.spec.externalIPs[]` و `.spec.ports[].port`) استفاده شود.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 49152
  externalIPs:
    - 198.51.100.32
```

{{< note >}}
کوبرنتیز تخصیص «آدرس‌های خارجی» را مدیریت نمی‌کند؛ این موارد مسئولیت مدیر خوشه است.
{{< /note >}}

## شیء API

سرویس یک منبع سطح بالا در کوبرنتیز REST API است. می‌توانید جزئیات بیشتری در مورد [شیء API سرویس](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#service-v1-core) پیدا کنید.

## {{% heading "whatsnext" %}}

درباره سرویس‌ها و نحوه قرارگیری آنها در کوبرنتیز بیشتر بدانید:

* آموزش [اتصال برنامه‌ها با سرویس‌ها](/docs/tutorials/services/connect-applications-service/) را دنبال کنید.
* درباره [Ingress](/docs/concepts/services-networking/ingress/) بخوانید، که مسیرهای HTTP و HTTPS را از خارج از خوشه به سرویس‌های درون خوشه شما ارائه می‌دهد.
* درباره [Gateway](/docs/concepts/services-networking/gateway/) که افزونه‌ای برای کوبرنتیز است و انعطاف‌پذیری بیشتری نسبت به Ingress ارائه می‌دهد، مطالعه کنید.

برای مطالعه بیشتر در این زمینه، مطالب زیر را بخوانید:

* [Virtual IPs and Service Proxies](/docs/reference/networking/virtual-ips/)
* [EndpointSlices](/docs/concepts/services-networking/endpoint-slices/)
* [Service API reference](/docs/reference/kubernetes-api/service-resources/service-v1/)
* [EndpointSlice API reference](/docs/reference/kubernetes-api/service-resources/endpoint-slice-v1/)
* [Endpoint API reference (legacy)](/docs/reference/kubernetes-api/service-resources/endpoints-v1/)
