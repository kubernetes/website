---
title: Service
api_metadata:
- apiVersion: "v1"
  kind: "Service"
feature:
  title: Виявлення Service та балансування навантаження
  description: >
    Не потрібно змінювати свій застосунок, щоб використовувати незнайомий механізм виявлення Service. Kubernetes надає Podʼам власні IP-адреси та єдине DNS-імʼя для набору Podʼів, а також може балансувати навантаження між ними.
description: >-
  Надайте доступ до застосунку, що працює в кластері, за допомогою однієї точки доступу, навіть якщо робота розподілена між декількома бекендами.
content_type: concept
weight: 10
---

<!-- overview -->

{{< glossary_definition term_id="service" length="short" prepend="В Kubernetes, Service — це" >}}

Ключова мета Service в Kubernetes — це те, що вам не потрібно модифікувати ваш поточний застосунок для використання незнайомого механізму виявлення Service. Ви можете виконувати код в Podʼах, чи це буде код, призначений для світу, орієнтованого на хмари, або старий застосунок, який ви контейнеризували. Ви використовуєте Service, щоб зробити цей набір Podʼів доступним в мережі, так щоб клієнти могли взаємодіяти з ним.

Якщо ви використовуєте {{< glossary_tooltip term_id="deployment" >}} для запуску вашого застосунку, цей Deployment може динамічно створювати та знищувати Podʼи. З одного моменту і до наступного, ви не знаєте, скільки з цих Podʼів працюють і є справними; ви навіть не можете знати,
як називаються ці справні Podʼи. {{< glossary_tooltip term_id="pod" text="Podʼи" >}} Kubernetes створюються та знищуються щоб відповідати бажаному стану вашого кластера. Podʼи є ефемерними ресурсами (ви не повинні очікувати, що індивідуальний Pod є надійним та довговічним).

Кожен Pod отримує свою власну IP-адресу (Kubernetes очікує, що мережеві втулки гарантують це). Для даного Deployment у вашому кластері набір Podʼів, який працює в один момент часу, може відрізнятися від набору Podʼів, який працює для цього застосунку наступний момент часу.

Це призводить до проблеми: якщо певний набір Podʼів (назвемо їх "backend") надає функціонал іншим Podʼам (назвемо їх "frontend") всередині вашого кластера, як фронтенд дізнається та відстежує, яку IP-адресу підключати, щоб він міг використовувати частину робочого навантаження?

Познайомтесь з _Service_.

<!-- body -->

## Service в Kubernetes {#servics-in-kubernetes}

API Service, що є частиною Kubernetes, є абстракцією, яка допомагає вам давати групі Podʼів доступ в мережі. Кожен обʼєкт Service визначає логічний набір endpoint (зазвичай endpoint — Pod) разом із політикою того, як робити ці Podʼи доступними.

Наприклад, розгляньте stateless бекенд для обробки зображень, який працює з 3 репліками. Ці репліки замінюються одна одною — фронтендам не важливо, який бекенд вони використовують. Хоча конкретні Podʼи, що складають бекенд, можуть змінюватися,
клієнти фронтенду не мають на це звертати уваги, і вони не повинні вести облік набору елементів бекендів самі.

Абстракція Service дозволяє таке відокремлення.

Набір Podʼів, яким призначається Service, зазвичай визначається
{{< glossary_tooltip text="селектором" term_id="selector" >}}, який ви визначаєте. Щоб дізнатися про інші способи визначення endpointʼів сервісу, дивіться [Сервіси _без_ селекторів](#services-without-selectors).

Якщо ваше навантаження використовує HTTP, ви можете  викорисовувати [Ingress](/docs/concepts/services-networking/ingress/) для контролю над тим, як вебтрафік досягає цього навантаження. Ingress не є типом сервісу, але він діє як точка входу до вашого кластера. Ingress дозволяє обʼєднати ваші правила маршрутизації в один ресурс, щоб ви могли
експонувати кілька компонентів вашого навантаження, що працюють окремо в вашому кластері, під одним зовнішнім URL.

API [Gateway](https://gateway-api.sigs.k8s.io/#what-is-the-gateway-api) для Kubernetes надає додаткові можливості, які виходять за межі Ingress і Service. Ви можете додати Gateway до вашого кластера, це родина розширених API, реалізованих за допомогою {{< glossary_tooltip term_id="CustomResourceDefinition" text="CustomResourceDefinitions" >}}, і потім використовувати їх для налаштування доступу до мережевих сервісів, що працюють у вашому кластері.

### Хмарно-нативне виявлення сервісів {#cloud-native-service-discovery}

Якщо ви можете використовувати API Kubernetes для виявлення сервісів у вашому застосунку, ви можете звертатись до {{< glossary_tooltip text="сервера API" term_id="kube-apiserver" >}}
по відповідні EndpointSlices. Kubernetes оновлює EndpointSlices для сервісу кожного разу, коли набір Podʼів у сервісі змінюється.

Для не-нативних застосунків Kubernetes пропонує способи розміщення мережевого порту чи балансувальника між вашим застосунком та Podʼами бекенду.

В будь-якому випадку ваше навантаження може використовувати ці [засоби виявлення сервісів](#discovering-services) для пошуку цільового сервісу, до якого воно хоче підʼєднатися.

## Визначення Сервісу {#defining-a-service}

Service — це {{< glossary_tooltip text="обʼєкт" term_id="object" >}} (так само як Pod чи ConfigMap є обʼєктами). Ви можете створювати, переглядати або змінювати визначення Service, використовуючи API Kubernetes. Зазвичай для цього ви використовуєте інструмент, такий як `kubectl`, який звертається до API.

Наприклад, припустимо, у вас є набір Podʼів, які слухають TCP-порт 9376 і мають мітку `app.kubernetes.io/name=MyApp`. Ви можете визначити Сервіс, щоб
опублікувати цього TCP-слухача:

{{% code_sample file="service/simple-service.yaml" %}}

Застосування цього маніфесту створює новий Сервіс з назвою "my-service" зі стандартним [типом служби](#publishing-services-service-types) ClusterIP. Сервіс обслуговує TCP-порт 9376 на будь-якому Podʼі з міткою `app.kubernetes.io/name: MyApp`.

Kubernetes призначає цьому Сервісу IP-адресу (так званий _кластерний IP_), що використовується механізмом віртуалізації IP-адрес. Для отримання докладнішої інформації про цей механізм, читайте [Віртуальні IP та Проксі-сервіси](/docs/reference/networking/virtual-ips/).

Контролер для цього Сервісу постійно сканує Podʼи, які відповідають його селектору, а потім вносить будь-які необхідні оновлення до набору EndpointSlices для Сервісу.

Назва обʼєкта Сервісу повинна бути дійсним [іменем мітки за стандартом RFC 1035](/docs/concepts/overview/working-with-objects/names#rfc-1035-label-names).

{{< note >}}
Сервіс може повʼязувати _будь-який_ вхідний `port` з `targetPort`. Типово та для зручності, `targetPort` встановлено на те ж саме значення, що й поле `port`.
{{< /note >}}

### Послаблені вимоги до іменування обʼєктів Service {#relaxed-naming-requirements-for-service-objects}

{{< feature-state feature_gate_name="RelaxedServiceNameValidation" >}}

The `RelaxedServiceNameValidation` feature gate allows Service object names to start with a digit. When this feature gate is enabled, Service object names must be valid [RFC 1123 label names](/docs/concepts/overview/working-with-objects/names/#dns-label-names).

### Визначення портів {#field-spec-ports}

Визначення портів в Podʼах мають назви, і ви можете посилатися на ці назви в атрибуті `targetPort` Сервісу. Наприклад, ми можемо привʼязати `targetPort` Сервісу до порту Podʼа таким чином:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app.kubernetes.io/name: proxy
  ports:
  - name: name-of-service-port
    protocol: TCP
    port: 80
    targetPort: http-web-svc

---
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    app.kubernetes.io/name: proxy
spec:
  containers:
  - name: nginx
    image: nginx:stable
    ports:
      - containerPort: 80
        name: http-web-svc

```

Це працює навіть у випадку, якщо у Сервісу є суміш Podʼів з використанням одного налаштованого імені, з однаковим мережевим протоколом, доступним через різні номери портів. Це надає багато гнучкості для розгортання та розвитку вашого Сервісу. Наприклад, ви можете змінити номери портів, які Podʼи прослуховують в наступній версії вашого програмного забезпечення бекенду, без руйнівних наслідків для клієнтів.

Станадртним протоколом для Service є [TCP](/docs/reference/networking/service-protocols/#protocol-tcp); ви також можете використовувати будь-який інший [підтримуваний протокол](/docs/reference/networking/service-protocols/).

Оскільки багато Сервісів повинні працювати більше ніж з одним портом, Kubernetes підтримує [визначення кількох портів](#multi-port-services) для одного Сервісу. Кожне визначення порту може мати той же `protocol` або різні.

### Сервіси без селекторів {#services-without-selectors}

Сервіси найчастіше абстрагують доступ до Podʼів Kubernetes завдяки селектору, але коли вони використовуються разом із відповідним набором {{<glossary_tooltip term_id="endpoint-slice" text="EndpointSlices">}} обʼєктів та без селектора, Сервіс може абстрагувати інші типи бекендів, включаючи ті, які працюють поза кластером.

Наприклад:

* Ви хочете мати зовнішній кластер баз даних у вашому промисловому середовищі, але у своєму тестовому середовищі ви використовуєте свої власні бази даних.
* Ви хочете спрямувати ваш Сервіс на Сервіс в іншому {{< glossary_tooltip term_id="namespace" >}} чи в іншому кластері.
* Ви мігруєте робоче навантаження в Kubernetes. Під час оцінки цього підходу, ви запускаєте лише частину своїх бекендів в Kubernetes.

У будь-якому з цих сценаріїв ви можете визначити Сервіс _без_ вказівки селектора для відповідності Podʼам. Наприклад:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
```

Оскільки у цього Сервісу немає селектора, відповідні обʼєкти EndpointSlice не створюються автоматично. Ви можете повʼязувати Сервіс з мережевою адресою та портом, де він працює, додавши обʼєкт EndpointSlice вручну. Наприклад:

```yaml
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  name: my-service-1 # за звичай, використовуйте назву Сервісу
                     # як префікс для назви EndpointSlice
  labels:
    # Ви повинні встановити мітку "kubernetes.io/service-name".
    # Встановіть її значення, щоб відповідати назві Сервісу
    kubernetes.io/service-name: my-service
addressType: IPv4
ports:
  - name: http # Має збігатись з іменем порту у визначенні Service
               # визначеному вище
    appProtocol: http
    protocol: TCP
    port: 9376
endpoints:
  - addresses:
      - "10.4.5.6"
  - addresses:
      - "10.1.2.3"
```

#### Власні EndpointSlices {#custom-endpointslices}

Коли ви створюєте обʼєкт [EndpointSlice](#endpointslices) для Сервісу, ви можете
використовувати будь-яку назву для EndpointSlice. Кожен EndpointSlice в просторі імен повинен мати унікальну назву. Ви поєднуєте EndpointSlice із Сервісом, встановлюючи {{< glossary_tooltip text="label" term_id="label" >}} `kubernetes.io/service-name` на цьому EndpointSlice.

{{< note >}}
IP-адреси endpoint _не повинні бути_: локальними (127.0.0.0/8 для IPv4, ::1/128 для IPv6), або (169.254.0.0/16 та 224.0.0.0/24 для IPv4, fe80::/64 для IPv6).

IP-адреси endpoint не можуть бути кластерними IP-адресами інших Сервісів Kubernetes, оскільки {{< glossary_tooltip term_id="kube-proxy" >}} не підтримує віртуальні IP-адреси як призначення.
{{< /note >}}

Для EndpointSlice, який ви створюєте самостійно або у своєму власному коді,
вам також слід вибрати значення для мітки [`endpointslice.kubernetes.io/managed-by`](/docs/reference/labels-annotations-taints/#endpointslicekubernetesiomanaged-by). Якщо ви створюєте свій власний код контролера для управління EndpointSlice, розгляньте можливість використання значення, схожого на `"my-domain.example/name-of-controller"`. Якщо ви використовуєте інструмент від стороннього постачальника, використовуйте назву інструменту в нижньому регістрі та замініть пробіли та інші знаки пунктуації на дефіси (`-`). Якщо ви безпосередньо використовуєте інструмент, такий як `kubectl`, для управління EndpointSlice, використовуйте назву, яка описує це ручне управління, таку як `"staff"` або `"cluster-admins"`. Ви повинні уникати використання захищеного значення `"controller"`, яке ідентифікує EndpointSlices, які керуються власною панеллю управління Kubernetes.

#### Доступ до Сервісу без селектора {#service-no-selector-access}

Доступ до Сервісу без селектора працює так само, якби він мав селектор. У [прикладі](#services-without-selectors) Сервісу без селектора, трафік маршрутизується до одного з двох endpoint, визначених у маніфесті EndpointSlice: TCP-зʼєднання до 10.1.2.3 або 10.4.5.6, на порт 9376.

{{< note >}}
Сервер API Kubernetes не дозволяє проксіювання до endpoint, які не повʼязані з Podʼами. Дії, такі як `kubectl port-forward service/<service-name> forwardedPort:servicePort`, де сервіс не має селектора, зазнають збою через це обмеження. Це запобігає використанню сервера API Kubernetes як проксі до endpoint, до яких викликач може не мати авторизації на доступ.
{{< /note >}}

`ExternalName` Сервіс — це особливий випадок Сервісу, який не має селекторів і використовує DNS-імена замість них. Для отримання доклдадної інформації, див. розділ
[ExternalName](#externalname).

### EndpointSlices

{{< feature-state for_k8s_version="v1.21" state="stable" >}}

[EndpointSlices](/docs/concepts/services-networking/endpoint-slices/) — це обʼєкти, які представляють підмножину (зріз) мережевих endpoint, які підтримують Сервіс.

Ваш кластер Kubernetes відстежує кількість endpointʼів, які представляє кожен EndpointSlice. Якщо для Сервісу є настільки багато endpointʼів, що досягається порогове значення, тоді Kubernetes додає ще один порожній EndpointSlice і зберігає там нову інформацію про endpoint. Типово Kubernetes створює новий EndpointSlice, як тільки наявні EndpointSlice всі містять принаймні 100 endpoint. Kubernetes не створює новий EndpointSlice, поки не буде потрібно додати додатковий endpoint.

Див. [EndpointSlices](/docs/concepts/services-networking/endpoint-slices/) для отримання додаткової інформації про цей API.

### Endpoint (deprecated) {#endpoints}

{{< feature-state for_k8s_version="v1.33" state="deprecated" >}}

API EndpointSlice є розвитком старого API [Endpoints](/docs/reference/kubernetes-api/service-resources/endpoints-v1/). Застарілий API Endpoints має кілька проблем порівняно з EndpointSlice:

* Він не підтримує двостекові кластери.
* Не містить інформації, необхідної для підтримки нових функцій, таких як [trafficDistribution](/docs/concepts/services-networking/service/#traffic-distribution).
* Якщо список точок доступу буде надто довгим, щоб вміститися в одному обʼєкті, він буде скорочений.

Через це рекомендується, щоб усі клієнти використовували API EndpointSlice, а не Endpoints.

#### Endpoints з перевищеним обсягом {#over-capacity-endpoints}

Kubernetes обмежує кількість endpointʼів, які можуть поміститися в один обʼєкт Endpoints. Коли є понад 1000 endpointʼів, які підтримують Сервіс, Kubernetes розмішує дані в обʼєкті Endpoints. Оскільки Сервіс може бути повʼязаним
з більше ніж одним EndpointSlice, обмеження в 1000 endpointʼів впливає лише
на застарілий API Endpoints.

У цьому випадку Kubernetes вибирає не більше 1000 можливих endpointʼів, які слід зберегти в обʼєкті Endpoints, і встановлює {{< glossary_tooltip text="анотацію" term_id="annotation" >}} на Endpoints: [`endpoints.kubernetes.io/over-capacity: truncated`](/docs/reference/labels-annotations-taints/#endpoints-kubernetes-io-over-capacity). Панель управління також видаляє цю анотацію, якщо кількість бекенд-Podʼів впадає нижче 1000.

Трафік все ще відсилається на бекенди, але будь-який механізм балансування навантаження, який покладається на застарілий API Endpoints, відсилає трафік не більше, ніж до 1000 доступних бекенд-endpointʼів.

Той самий ліміт API означає, що ви не можете вручну оновлювати Endpoints так, щоб у них було понад 1000 endpointʼів.

### Протокол застосунку {#application-protocol}

{{< feature-state for_k8s_version="v1.20" state="stable" >}}

Поле `appProtocol` надає можливість вказати протокол застосунку для кожного порту Сервісу. Це використовується як підказка для реалізацій для надання розширеної поведінки для протоколів, які вони розуміють. Значення цього поля відображається відповідними обʼєктами Endpoints та EndpointSlice.

Це поле відповідає стандартному синтаксису міток Kubernetes. Дійсні значення — це одне з:

* [стандартні назви служб IANA](https://www.iana.org/assignments/service-names).

* Імплементаційно-визначені префіксовані імена, такі як `mycompany.com/my-custom-protocol`.

* Імена з префіксом, визначені Kubernetes:

| Протокол | Опис        |
|----------|-------------|
| `kubernetes.io/h2c` | HTTP/2 через відкритий текст, як описано в [RFC 7540](https://www.rfc-editor.org/rfc/rfc7540) |
| `kubernetes.io/ws`  | WebSocket через відкритий текст, як описано у [RFC 6455](https://www.rfc-editor.org/rfc/rfc6455) |
| `kubernetes.io/wss` | WebSocket через TLS, як описано у [RFC 6455](https://www.rfc-editor.org/rfc/rfc6455) |

### Сервіси з кількома портами {#multi-port-services}

Для деяких Сервісів вам може знадобитися використовувати більше одного порту. Kubernetes дозволяє конфігурувати кілька визначень портів в обʼєкті Service. При використанні кількох портів для Сервісу, вам слід надавати всім портам імена,
щоб вони були однозначними. Наприклад:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9377
```

{{< note >}}
Так само як і з {{< glossary_tooltip term_id="name" text="іменами" >}} в Kubernetes взагалі, імена портів мають містити лише буквено-цифрові символи в нижньому регістрі та `-`. Імена портів також повинні починатися та закінчуватися буквено-цифровим символом.

Наприклад, імена `123-abc` та `web` є допустимими, але `123_abc` та `-web` - ні.
{{< /note >}}

## Тип Сервісу {#publishing-services-service-types}

Для деяких частин вашого застосунку (наприклад, фронтенду) ви можете знадобитись звʼязати Сервіс з зовнішньою IP-адресою, доступну з-поза вашого кластера.

Типи Сервісів Kubernetes дозволяють вам вказати, який тип Сервісу вам потрібен.

Доступні значення `type` та їхні поведінка:

[`ClusterIP`](#type-clusterip)
: Повʼязує Сервіс з внутрішньою IP-адресою кластера. Вибір цього значення робить Сервіс доступним лише зсередини кластера. Це значення використовується стандартно, якщо ви не вказали явно `type` для Сервісу. Ви можете дати Сервісу доступ в Інтернет за допомогою [Ingress](/docs/concepts/services-networking/ingress/) або [Gateway](https://gateway-api.sigs.k8s.io/).

[`NodePort`](#type-nodeport)
: Повʼязує Сервіс на кожній IP-адресі вузла зі статичним портом (`NodePort`). Щоб зробити порт вузла доступним, Kubernetes налаштовує IP-адресу кластера, так само якби ви запросили Сервіс з `type: ClusterIP`.

[`LoadBalancer`](#loadbalancer)
: Повʼязує Сервіс із зовнішніми споживачами за допомогою зовнішнього балансувальника навантаження. Kubernetes не надає безпосередньо компонент балансування навантаження; вам слід надати його, або ви можете інтегрувати свій кластер Kubernetes з постачальником хмарних послуг.

[`ExternalName`](#externalname)
: Повʼязує Сервіс зі змістом поля `externalName` (наприклад, з іменем хосту `api.foo.bar.example`). Це конфігурує сервер DNS вашого кластера повертати запис `CNAME` з вказаною зовнішньою назвою хосту. Ніякого проксінгу не налаштовується.

Поле `type` в API Сервісу розроблене як вкладена функціональність — кожен рівень додається до попереднього. Однак існує виняток з цього вкладеного дизайну. Ви можете визначити Сервіс `LoadBalancer`, відключивши [використання порту вузла для балансування навантаження](/docs/concepts/services-networking/service/#load-balancer-nodeport-allocation).

### `type: ClusterIP` {#type-clusterip}

Цей тип Сервісу типово призначає IP-адресу з пулу IP-адрес, який ваш кластер зарезервував для цієї мети.

Кілька інших типів Сервісу базуються на типі `ClusterIP`.

Якщо ви визначаєте Сервіс, у якому `.spec.clusterIP` встановлено в `"None"`, тоді Kubernetes не призначає IP-адресу. Див. [Сервіси headless](#headless-services) для отримання додаткової інформації.

#### Вибір власної IP-адреси {#choosing-your-own-ip-address}

Ви можете вказати власну IP-адресу кластера як частину запиту на створення `Service`. Для цього встановіть поле `.spec.clusterIP`. Наприклад, якщо у вас вже є наявний запис DNS, який ви хочете повторно використовувати, або старі системи, які налаштовані на певну IP-адресу і важко переналаштовуються.

IP-адреса, яку ви вибираєте, повинна бути дійсною IPv4 або IPv6 адресою з діапазону CIDR, який налаштований для сервера API за допомогою `service-cluster-ip-range`. Якщо ви намагаєтеся створити Сервіс із недійсною IP-адресою `clusterIP`, сервер API поверне HTTP-відповідь зі статус-кодом 422 для позначення проблеми.

Читайте [уникнення конфліктів](/docs/reference/networking/virtual-ips/#avoiding-collisions), щоб дізнатися, як Kubernetes допомагає зменшити ризик та вплив двох різних Сервісів, що намагаються використовувати однакову IP-адресу.

### `type: NodePort` {#type-nodeport}

Якщо ви встановлюєте поле `type` в `NodePort`, панель управління Kubernetes виділяє порт з діапазону, вказаного прапорцем `--service-node-port-range` (типово: 30000-32767). Кожен вузол проксіює цей порт (той самий номер порту на кожному вузлі) у ваш Сервіс. Ваш Сервіс повідомляє виділений порт у полі `.spec.ports[*].nodePort`.

Використання NodePort дає вам свободу налаштувати власне рішення з балансування навантаження, конфігурувати середовища, які не повністю підтримуються Kubernetes, або навіть експонувати один або кілька IP-адрес вузлів безпосередньо.

Для Сервісу з портом вузла Kubernetes додатково виділяє порт (TCP, UDP або SCTP для відповідності протоколу Сервісу). Кожен вузол у кластері конфігурується на прослуховування цього призначеного порту і пересилання трафіку на одну з готових точок доступу, повʼязаних із цим Сервісом. Ви зможете звертатися до Сервісу з `type: NodePort`, ззовні кластера, підключаючись до будь-якого вузла за відповідним протоколом (наприклад: TCP) та відповідним портом (який призначено цьому Сервісу).

#### Вибір власного порту {#nodeport-custom-port}

Якщо вам потрібен певний номер порту, ви можете вказати значення у полі `nodePort`.Панель управління вибере для вас цей порт або повідомить, що транзакція API не вдалася. Це означає, що вам потрібно самостійно дбати про можливі конфлікти портів. Вам також слід використовувати дійсний номер порту, який знаходиться в межах налаштованого діапазону для використання NodePort.

Ось приклад маніфесту для Сервісу з `type: NodePort`, який вказує значення `NodePort` (30007 у цьому прикладі):

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - port: 80
      # Стандартно та для зручності, `targetPort` встановлено
      # в те ж значення, що й поле `port`.
      targetPort: 80
      # Необовʼязкове поле
      # Стандартно та для зручності, панель управління Kubernetes
      # виділить порт з діапазону (станадртно: 30000-32767)
      nodePort: 30007
```

#### Резервування діапазонів NodePort для уникнення конфліктів {#avoid-nodeport-collisions}

Політика виділення портів для NodePort-сервісів застосовується як до автоматичного, так і до ручного виділення. Коли користувач хоче створити NodePort-сервіс, який використовує певний порт, цей цільовий порт може конфліктувати з іншим портом, який вже виділено.

Щоб уникнути цієї проблеми, діапазон портів для NodePort-сервісів розбито на дві частини. Типово для динамічного виділення портів використовується верхній діапазон, і він може використовувати нижній діапазон, якщо верхній діапазон вичерпано. Користувачі можуть виділяти порти з нижнього діапазону з меншим ризиком конфлікту портів.

При використанні стандартного діапазону NodePort 30000-32767 смуги розподіляються наступним чином:

* Статична смуга: 30000-30085
* Динамічна смуга: 30086-32767

Докладнішу інформацію про те, як обчислюються статичні та динамічні діапазони, див. у статті [Уникнення конфліктів при призначенні портів сервісам NodePort](/blog/2023/05/11/nodeport-dynamic-and-static-allocation/).

#### Налаштування власної IP-адреси для Сервісів `type: NodePort` {#service-nodeport-custom-listen-address}

Ви можете налаштувати вузли у своєму кластері використовувати певну IP-адресу для обслуговування сервісів з портом вузла. Ви можете це зробити, якщо кожен вузол підключений до декількох мереж (наприклад: одна мережа для трафіку застосунків, а інша мережа для трафіку між вузлами та панеллю управління).

Якщо ви хочете вказати певні IP-адреси для проксі-порта, ви можете встановити прапорець `--nodeport-addresses` для kube-proxy або еквівалентне поле `nodePortAddresses` у [файлі конфігурації kube-proxy](/docs/reference/config-api/kube-proxy-config.v1alpha1/) на конкретні блоки IP.

Цей прапорець приймає список IP-блоків через кому (наприклад, `10.0.0.0/8`, `192.0.2.0/25`) для вказівки діапазонів IP-адрес, які kube-proxy повинен вважати локальними для цього вузла.

Наприклад, якщо ви запускаєте kube-proxy з прапорцем `--nodeport-addresses=127.0.0.0/8`, kube-proxy вибирає лише інтерфейс loopback для NodePort-сервісів. Типово для `--nodeport-addresses` є порожній список. Це означає, що kube-proxy повинен вважати всі доступні мережеві інтерфейси локальними для NodePort. (Це також сумісно з раніше випущеними версіями Kubernetes.)

{{< note >}}
Цей Сервіс видно як `<NodeIP>:spec.ports[*].nodePort` та `.spec.clusterIP:spec.ports[*].port`. Якщо встановлено прапорець `--nodeport-addresses` для kube-proxy або еквівалентне поле у файлі конфігурації kube-proxy, `<NodeIP>` буде IP-адресою вузла (або можливо IP-адресами) для фільтрування.
{{< /note >}}

### `type: LoadBalancer` {#loadbalancer}

У хмарних постачальників, які підтримують зовнішні балансувальники навантаження, встановлення поля `type` в `LoadBalancer` надає балансувальник навантаження для вашого Сервісу. Створення балансувальника навантаження відбувається асинхронно, і інформація про створений балансувальник публікується у полі `.status.loadBalancer` Сервісу. Наприклад:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  clusterIP: 10.0.171.239
  type: LoadBalancer
status:
  loadBalancer:
    ingress:
    - ip: 192.0.2.127
```

Трафік від зовнішнього балансувальника навантаження направляється на бекенд-Podʼи. Хмарний постачальник вирішує, як він балансує навантаження.

Для реалізації Сервісу з `type: LoadBalancer`, Kubernetes зазвичай починає з того, що вносить зміни, які еквівалентні вашим запитам на Сервіс `type: NodePort`. Компонент cloud-controller-manager потім налаштовує зовнішній балансувальник для пересилання трафіку на цей призначений порт вузла.

Ви можете налаштувати балансований за навантаженням Сервіс для [виключення](#load-balancer-nodeport-allocation) призначення порта вузла, за умови, що реалізація постачальника хмари це підтримує.

Деякі постачальники хмар дозволяють вам вказати `loadBalancerIP`. У цих випадках балансувальник створюється з вказаною користувачем `loadBalancerIP`. Якщо поле `loadBalancerIP` не вказано, то балансувальник налаштовується з ефемерною IP-адресою. Якщо ви вказали `loadBalancerIP`, але ваш постачальник хмари не підтримує цю функцію, то вказане вами поле `loadbalancerIP` ігнорується.

{{< note >}}
Поле `.spec.loadBalancerIP` для Сервісу було визнане застарілим в Kubernetes v1.24.

Це поле було недостатньо визначеним, і його значення різниться в різних реалізаціях. Воно також не підтримує мережі з подвійним стеком. Це поле може бути вилучено в майбутніх версіях API.

Якщо ви інтегруєтеся з постачальником, який підтримує вказання IP-адреси(в) балансувальника навантаження для Сервісу через анотацію (специфічну для постачальника), вам слід перейти на цей метод.

Якщо ви пишете код для інтеграції балансувальника з Kubernetes, уникайте використання цього поля. Ви можете інтегрувати його з [Gateway](https://gateway-api.sigs.k8s.io/) замість Service, або ви можете визначити власні анотації (специфічні для постачальника) для Сервісу, які визначають еквівалентну деталь.
{{< /note >}}

#### Вплив життєздатності вузла на трафік балансувальника навантаження {#node-liveness-impact-on-load-balancer-traffic}

Перевірки стану балансувальника навантаження є критичними для сучасних застосунків. Вони використовуються для визначення того, на який сервер (віртуальна машина або IP-адреса) повинен бути направлений трафік балансувальника навантаження. API Kubernetes не визначає, як мають бути реалізовані перевірки стану для керованих Kubernetes балансувальників навантаження; замість цього це роблять хмарні постачальники (і люди, які створюють код інтеграції), які визначають поведінку. Перевірки стану балансувальника навантаження широко використовуються в контексті підтримки поля `externalTrafficPolicy` для Service.

#### Балансувальники з мішаними типами протоколів {#load-balancer-with-mixed-protocol-types}

{{< feature-state feature_gate_name="MixedProtocolLBService" >}}

Типово для Сервісів типу LoadBalancer, коли визначено більше одного порту, всі порти повинні мати один і той же протокол, і цей протокол повинен бути підтримуваний
постачальником хмари.

Функціональна можливість `MixedProtocolLBService` (стандартно увімкнена для kube-apiserver з версії v1.24) дозволяє використовувати різні протоколи для Сервісів типу LoadBalancer, коли визначено більше одного порту.

{{< note >}}
Набір протоколів, які можна використовувати для балансованих навантажень Сервісів, визначається вашим постачальником хмари; вони можуть накладати обмеження поза тим, що накладає API Kubernetes.
{{< /note >}}

#### Вимкнення виділення порту вузла для балансувальника навантаження {#load-balancer-nodeport-allocation}

{{< feature-state for_k8s_version="v1.24" state="stable" >}}

Ви можете вимкнути виділення порту вузла для Сервісу з `type: LoadBalancer`, встановивши поле `spec.allocateLoadBalancerNodePorts` в `false`. Це слід використовувати тільки для реалізацій балансувальників, які маршрутизують трафік безпосередньо до Podʼів, а не використовують порти вузла. Стандартно `spec.allocateLoadBalancerNodePorts` дорівнює `true`, і Сервіси типу LoadBalancer будуть продовжувати виділяти порти вузла. Якщо `spec.allocateLoadBalancerNodePorts` встановлено в `false` для існуючого Сервісу з виділеними портами вузла, ці порти вузла **не** будуть автоматично видалятися. Вам слід явно видалити запис `nodePorts` в кожному порту Сервісу для деалокації цих портів вузла.

#### Вказання класу реалізації балансувальника {#load-balancer-class}

{{< feature-state for_k8s_version="v1.24" state="stable" >}}

Для Сервісу з `type` встановленим на `LoadBalancer`, поле `.spec.loadBalancerClass`
дозволяє вам використовувати реалізацію балансувальника, відмінну від тієї, яку типово встановлено постачальником хмари.

Типово `.spec.loadBalancerClass` не встановлено, і Сервіс з `LoadBalancer`  використовує реалізацію балансувальника що постачається в хмарі, якщо кластер налаштовано постачальником хмари за допомогою прапорця компоненту `--cloud-provider`. Якщо ви вказуєте `.spec.loadBalancerClass`, вважається, що реалізація балансувальника, яка відповідає вказаному класу, відстежує Сервіси. Будь-яка стандартна реалізація балансувальника (наприклад, та, яку надає постачальник хмари), ігнорує Сервіси, у яких встановлено це поле. `spec.loadBalancerClass` може бути встановлено тільки для Сервісу типу `LoadBalancer`. Після встановлення його не можна змінити. Значення `spec.loadBalancerClass` повинно бути ідентифікатором у формі мітки, з необовʼязковим префіксом, таким як "`internal-vip`" або "`example.com/internal-vip`". Безпрефіксні імена зарезервовані для кінцевих користувачів.

#### Режим IP-адреси балансувальника навантаження {#load-balancer-ip-mode}

Для Service з типом `type: LoadBalancer`, контролер може встановити `.status.loadBalancer.ingress.ipMode`. `.status.loadBalancer.ingress.ipMode` вказує, як веде себе IP-адреса балансувальника. Воно може бути вказано лише тоді, коли вказано поле `.status.loadBalancer.ingress.ip`.

Є два можливі значення для `.status.loadBalancer.ingress.ipMode`: "VIP" та "Proxy".Типово встановлене значення "VIP", що означає, що трафік подається на вузол з призначенням, встановленим на IP та порт балансувальника. Є два випадки, коли встановлено значення "Proxy", залежно від того, як постачальник хмари балансує трафік:

* Якщо трафік подається на вузол, а потім перенаправляється до Podʼа, призначення буде встановлено на IP та порт вузла;
* Якщо трафік подається безпосередньо до Podʼа, призначення буде встановлено на IP та порт Podʼа.

Реалізації Сервісів можуть використовувати цю інформацію для налаштування маршрутизації трафіку.

#### Внутрішній балансувальник {#internal-load-balancer}

У змішаному середовищі іноді необхідно направляти трафік від Сервісів всередині того ж (віртуального) мережевого блоку.

У середовищі DNS з розділеним горизонтом вам знадобляться два Сервіси, щоб мати можливість маршрутизувати як зовнішній, так і
і внутрішній трафік до ваших точок доступу.

Щоб встановити внутрішній балансувальник, додайте одну з наступних анотацій до Сервісу в залежності від постачальника хмари, який ви використовуєте:

{{< tabs name="service_tabs" >}}
{{% tab name="Типово" %}}
Виберіть одну з вкладок.
{{% /tab %}}

{{% tab name="GCP" %}}

```yaml
metadata:
  name: my-service
  annotations:
    networking.gke.io/load-balancer-type: "Internal"
```

{{% /tab %}}
{{% tab name="AWS" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"
```

{{% /tab %}}
{{% tab name="Azure" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/azure-load-balancer-internal: "true"
```

{{% /tab %}}
{{% tab name="IBM Cloud" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.kubernetes.io/ibm-load-balancer-cloud-provider-ip-type: "private"
```

{{% /tab %}}
{{% tab name="OpenStack" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/openstack-internal-load-balancer: "true"
```

{{% /tab %}}
{{% tab name="Baidu Cloud" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/cce-load-balancer-internal-vpc: "true"
```

{{% /tab %}}
{{% tab name="Tencent Cloud" %}}

```yaml
metadata:
  annotations:
    service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-xxxxx
```

{{% /tab %}}
{{% tab name="Alibaba Cloud" %}}

```yaml
metadata:
  annotations:
    service.beta.kubernetes.io/alibaba-cloud-loadbalancer-address-type: "intranet"
```

{{% /tab %}}
{{% tab name="OCI" %}}

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/oci-load-balancer-internal: true
```

{{% /tab %}}
{{< /tabs >}}

### `type: ExternalName` {#externalname}

Сервіси типу ExternalName звʼязують Сервіс з DNS-іменем, а не з типовим селектором, таким як `my-service` або `cassandra`. Ви вказуєте ці Сервіси параметром `spec.externalName`.

Наприклад, це визначення Сервісу звʼязує Сервіс `my-service` в просторі імен `prod` з `my.database.example.com`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com
```

{{< note >}}
Сервіс типу `ExternalName` приймає рядок IPv4 адреси, але трактує цей рядок як імʼя DNS, що складається з цифр, а не як IP-адресу (інтернет, однак, не дозволяє такі імена в DNS). Сервіси зовнішніх імен, які нагадують IPv4 адреси, не розвʼязуються DNS-серверами.

Якщо ви хочете звʼязати Сервіс безпосередньо з конкретною IP-адресою, розгляньте можливість використання [headless Services](#headless-services).
{{< /note >}}

При пошуку хоста `my-service.prod.svc.cluster.local`, DNS-сервіс кластера повертає запис `CNAME` із значенням `my.database.example.com`. Доступ до `my-service` працює так само, як і для інших Сервісів, але з важливою різницею в тому, що перенаправлення відбувається на рівні DNS, а не через проксі або переадресацію. Якщо ви пізніше вирішите перемістити свою базу даних в кластер, ви можете запустити його Podʼи, додати відповідні селектори чи endpointʼи та змінити тип Сервісу.

{{< caution >}}
Можливі проблеми з використанням ExternalName для деяких загальних протоколів, таких як HTTP та HTTPS. Якщо ви використовуєте ExternalName, імʼя хоста, яке використовують клієнти всередині вашого кластера, відрізняється від
імені, на яке посилається ExternalName.

Для протоколів, які використовують імена хостів, ця різниця може призвести до помилок або непередбачуваних відповідей. HTTP-запити матимуть заголовок `Host:`, який сервер-джерело не визнає; сервери TLS не зможуть надати сертифікат, що відповідає імені хоста, до якого приєдно клієнта.
{{< /caution >}}

## Headless Services {#headless-services}

Іноді вам не потрібен балансувальник навантаження та одна IP-адреса Сервісу. У цьому випадку ви можете створити так звані _headless Services_, якщо явно вказати `"None"` для IP-адреси кластера (`.spec.clusterIP`).

Ви можете використовувати headless Сервіс для взаємодії з іншими механізмами виявлення сервісів, не будучи привʼязаним до реалізації Kubernetes.

Для headless Сервісів кластерна IP-адреса не видається, kube-proxy не обслуговує ці Сервіси, і для них платформа не виконує балансування навантаження чи проксіюваня.

Headless Сервіси дозволяють клієнту приєднуватись до будь-якого Pod безпосередньо. Ці Сервіси не встановлюють маршрути та перенаправлення пакетів з використанням [віртуальних IP-адрес та проксі](/docs/reference/networking/virtual-ips/); натомість вони повідомляють про IP-адреси точок доступу окремих Podʼів через внутрішні записи DNS, які обслуговуються [службою DNS](/docs/concepts/services-networking/dns-pod-service/) кластера. Для визначення headless Сервіса вам потрібно створити Service з `.spec.type` встановленим на `ClusterIP` (що також є типовим значенням) та `.spec.clusterIP` встановленим у `None`.

Рядкове значення None є особливим випадком і не тотожне відсутності значення в полі `.spec.clusterIP`.

Те, як автоматично налаштовано DNS, залежить від того, чи визначені селектори Сервісу:

### З селекторами {#with-selectors}

Для headless Сервісів, які визначають селектори, контролер endpointʼів створює обʼєкти EndpointSlice в Kubernetes API та змінює конфігурацію DNS так, щоб повертати записи A або AAAA (IPv4 або IPv6 адреси), які напрямую вказують на Podʼи, які підтримують Сервіс.

### Без селекторів {#without-selectors}

Для headless Сервісів, які не визначають селектори, панель управління не створює обʼєкти EndpointSlice. Проте система DNS шукає та налаштовує або:

* DNS-записи CNAME для Сервісів з [`type: ExternalName`](#externalname).
* DNS-записи A / AAAA для всіх IP-адрес Сервісу з готовими endpointʼами, для всіх типів Сервісів, крім `ExternalName`.
  * Для IPv4 endpointʼів система DNS створює A-записи.
  * Для IPv6 endpointʼів система DNS створює AAAA-записи.

Коли ви визначаєте headless Сервіс без селектора, поле `port` повинно відповідати полю `targetPort`.

## Виявлення сервісів {#discovering-services}

Для клієнтів, що працюють всередині вашого кластера, Kubernetes підтримує два основних способи виявлення Сервісу: змінні середовища та DNS.

### Змінні середовища {#environment-variables}

Коли Pod запускається на вузлі, kubelet додає набір змінних середовища для кожного активного Сервісу. Додаються змінні середовища `{SVCNAME}_SERVICE_HOST` та `{SVCNAME}_SERVICE_PORT`, де імʼя Сервісу перетворюється у верхній регістр, а тире конвертуються у підкреслення.

Наприклад, Сервіс `redis-primary`, який використовує TCP-порт 6379 та має присвоєну IP-адресу кластера 10.0.0.11, створює наступні змінні середовища:

```shell
REDIS_PRIMARY_SERVICE_HOST=10.0.0.11
REDIS_PRIMARY_SERVICE_PORT=6379
REDIS_PRIMARY_PORT=tcp://10.0.0.11:6379
REDIS_PRIMARY_PORT_6379_TCP=tcp://10.0.0.11:6379
REDIS_PRIMARY_PORT_6379_TCP_PROTO=tcp
REDIS_PRIMARY_PORT_6379_TCP_PORT=6379
REDIS_PRIMARY_PORT_6379_TCP_ADDR=10.0.0.11
```

{{< note >}}
Коли у вас є Pod, який потребує доступу до Сервісу, і ви використовуєте метод змінної середовища для публікації порту та кластерного IP для Podʼів клієнта, ви повинні створити Сервіс _перед_ створенням Podʼів клієнта. В іншому випадку ці Podʼи клієнта не матимуть заповнених змінних середовища.

Якщо ви використовуєте лише DNS для визначення кластерного IP для Сервісу, вам не потрібно турбуватися про цю проблему порядку.
{{< /note >}}

Kubernetes також підтримує та надає змінні, які сумісні з "_[legacy container links](https://docs.docker.com/network/links/)_" Docker Engine. Ви можете переглянути [`makeLinkVariables`](https://github.com/kubernetes/kubernetes/blob/dd2d12f6dc0e654c15d5db57a5f9f6ba61192726/pkg/kubelet/envvars/envvars.go#L72) щоб побачити, як це реалізовано в Kubernetes.

### DNS

Ви можете (і майже завжди повинні) налаштувати службу DNS для вашого кластера Kubernetes, використовуючи [надбудову](/docs/concepts/cluster-administration/addons/).

Сервер DNS, що знається на кластерах, такий як CoreDNS, стежить за Kubernetes API для виявлення нових Сервісів і створює набір DNS-записів для кожного з них. Якщо DNS увімкнено в усьому кластері, то всі Podʼи повинні автоматично мати можливість знаходити Сервіси за їхнім DNS-імʼям.

Наприклад, якщо у вас є Сервіс з назвою `my-service` в просторі імен Kubernetes `my-ns`, то разом панель управління та служба DNS створюють DNS-запис для `my-service.my-ns`. Podʼи в просторі імен `my-ns` повинні мати можливість знаходити Сервіс, роблячи запит за іменем `my-service` (`my-service.my-ns` також працюватиме).

Podʼи в інших просторах імен повинні вказати імʼя як `my-service.my-ns`. Ці імена будуть розповсюджуватись на призначений кластером IP для Сервісу.

Kubernetes також підтримує DNS SRV (Service) записи для іменованих портів. Якщо Сервіс `my-service.my-ns` має порт з іменем `http` і протоколом, встановленим в `TCP`, ви можете виконати DNS SRV-запит для `_http._tcp.my-service.my-ns`, щоб дізнатися номер порту для `http`, а також IP-адресу.

Сервер DNS Kubernetes — єдиний спосіб доступу до Сервісів `ExternalName`. Ви можете знайти більше інформації про вирішення `ExternalName` в [DNS для Сервісів та Podʼів](/docs/concepts/services-networking/dns-pod-service/).

<!-- Збережіть існуючі гіперпосилання -->
<a id="shortcomings" />
<a id="the-gory-details-of-virtual-ips" />
<a id="proxy-modes" />
<a id="proxy-mode-userspace" />
<a id="proxy-mode-iptables" />
<a id="proxy-mode-ipvs" />
<a id="ips-and-vips" />

## Механізм віртуальних IP-адрес {#virtual-ip-addressing-mechanism}

Прочитайте [Віртуальні IP-адреси та сервісні проксі](/docs/reference/networking/virtual-ips/), що пояснює механізм, який Kubernetes надає для експозиції Сервісу з віртуальною IP-адресою.

### Політики трафіку {#traffic-policies}

Ви можете встановити поля `.spec.internalTrafficPolicy` та `.spec.externalTrafficPolicy`, щоб контролювати, як Kubernetes маршрутизує трафік до справних ("готових") бекендів.

Дивіться [Політики трафіку](/docs/reference/networking/virtual-ips/#traffic-policies) для отримання докладнішої інформації.

### Контроль розподілу трафіку {#traffic-distribution}

Поле `.spec.trafficDistribution` надає ще один спосіб впливу на маршрутизацію трафіку в межах Сервісу Kubernetes. Хоча політика трафіку зосереджується на строгих семантичних гарантіях, розподіл трафіку дозволяє виражати _уподобання_ (наприклад, маршрутизацію до топологічно ближчих точок доступу). Це може допомогти оптимізувати продуктивність, вартість або надійність. У Kubernetes {{< skew currentVersion >}}, підтримуються такі значення поля:

`PreferSameZone`
: Вказує на перевагу маршрутизації трафіку до точок доступу, які знаходяться в тій самій зоні, що й клієнт.

`PreferSameNode`
: Вказує на перевагу маршрутизації трафіку до точок доступу, які знаходяться на тому ж вузлі, що і клієнт.

`PreferClose` (застаріло)
: Це старіший псевдонім для `PreferSameZone`, який є менш зрозумілим з точки зору семантики.

Якщо поле не встановлено, реалізація застосує свою стандартну стратегію маршрутизації.

Дивіться [Розподіл трафіку](/docs/reference/networking/virtual-ips/#traffic-distribution) для отримання додаткової інформації.

### Збереження сесії {#session-stickiness}

Якщо ви хочете переконатися, що зʼєднання з певного клієнта щоразу передаються до одного і того ж Pod, ви можете налаштувати спорідненість сеансу на основі IP-адреси клієнта. Читайте [Сесійна спорідненість](/docs/reference/networking/virtual-ips/#session-affinity) щоб дізнатися більше.

## Зовнішні IP {#external-ips}

Якщо існують зовнішні IP-адреси, які маршрутизують до одного чи декількох вузлів кластера, Сервіси Kubernetes можна використовувати на цих `externalIPs`. Коли мережевий трафік потрапляє в кластер із зовнішнім IP (як IP призначення) та портом, який відповідає цьому Сервісу, правила та маршрути, які Kubernetes налаштовує, забезпечують маршрутизацію трафіку до однієї з точок доступу цього Сервісу.

При визначенні Сервісу ви можете вказати `externalIPs` для будь-якого [типу сервісу](#publishing-services-service-types). У наведеному нижче прикладі Сервіс з іменем `"my-service"` може отримати доступ від клієнтів за допомогою TCP за адресою `"198.51.100.32:80"` (розраховано із `.spec.externalIPs[]` та `.spec.ports[].port`).

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 49152
  externalIPs:
    - 198.51.100.32
```

{{< note >}}
Kubernetes не керує виділенням `externalIPs`; це відповідальність адміністратора кластера.
{{< /note >}}

## API Обʼєкт {#api-object}

Сервіс — це ресурс верхнього рівня в Kubernetes REST API. Ви можете знайти більше деталей про [обʼєкт API Service](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#service-v1-core).

## {{% heading "whatsnext" %}}

Дізнайтеся більше про Сервіси та те, як вони вписуються в Kubernetes:

* Дізнайтесь про [Підключення застосунків за допомогою Service](/docs/tutorials/services/connect-applications-service/).
* Прочитайте про [Ingress](/docs/concepts/services-networking/ingress/), який експонує маршрути HTTP та HTTPS ззовні кластера до Сервісів всередині вашого кластера.
* Прочитайте про [Gateway](/docs/concepts/services-networking/gateway/), розширення для Kubernetes, яке надає більше гнучкості, ніж Ingress.

Для отримання додаткового контексту прочитайте наступне:

* [Віртуальні IP та Сервісні проксі](/docs/reference/networking/virtual-ips/)
* [EndpointSlices](/docs/concepts/services-networking/endpoint-slices/)
* [Довідка API Service](/docs/reference/kubernetes-api/service-resources/service-v1/)
* [Довідка API EndpointSlice](/docs/reference/kubernetes-api/service-resources/endpoint-slice-v1/)
* [Довідка API Endpoint (застаріла)](/docs/reference/kubernetes-api/service-resources/endpoints-v1/)
