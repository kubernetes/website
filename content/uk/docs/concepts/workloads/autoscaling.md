---
title: Автомасштабування робочих навантажень
description: >-
  З автомасштабуванням ви можете автоматично оновлювати ваші робочі навантаження різними способами. Це дозволяє вашому кластеру еластичніше та ефективніше реагувати на зміни витрат ресурсів.
content_type: concept
weight: 40
---

<!-- overview -->

У Kubernetes ви можете _масштабувати_ робоче навантаження залежно від поточного попиту на ресурси. Це дозволяє вашому кластеру більш еластично та ефективно реагувати на зміни витрат ресурсів.

При масштабуванні робочого навантаження ви можете збільшувати або зменшувати кількість реплік, які керуються робочим навантаженням, або налаштовувати ресурси, доступні для реплік на місці.

Перший підхід називається _горизонтальним масштабуванням_, тоді як другий — _вертикальним масштабуванням_.

Є ручні та автоматичні способи масштабування робочих навантажень, залежно від вашого випадку використання.

<!-- body -->

## Ручне масштабування робочих навантажень {#scaling-workloads-manually}

Kubernetes підтримує _ручне масштабування_ робочих навантажень. Горизонтальне масштабування можна виконати за допомогою інтерфейсу командного рядка `kubectl`. Для вертикального масштабування вам потрібно _змінити_ визначення ресурсів вашого робочого навантаження.

Дивіться нижче приклади обох стратегій.

- **Горизонтальне масштабування**: [Запуск кількох екземплярів вашого застосунку](/docs/tutorials/kubernetes-basics/scale/scale-intro/)
- **Вертикальне масштабування**: [Зміна обсягів ресурсів CPU та памʼяті, призначених для контейнерів](/docs/tasks/configure-pod-container/resize-container-resources/)

## Автоматичне масштабування робочих навантажень {#scaling-workloads-automatically}

Kubernetes також підтримує _автоматичне масштабування_ робочих навантажень, що є основною темою цієї сторінки.

Концепція _Автомасштабування_ в Kubernetes стосується можливості автоматичного оновлення обʼєкта, який керує набором Podʼів (наприклад, {{< glossary_tooltip text="Deployment" term_id="deployment" >}}).

### Горизонтальне масштабування робочих навантажень {#scaling-workloads-horizontally}

У Kubernetes ви можете автоматично масштабувати робоче навантаження горизонтально за допомогою _HorizontalPodAutoscaler_ (HPA).

Він реалізований як ресурс Kubernetes API та {{< glossary_tooltip text="controller" term_id="controller" >}} і періодично налаштовує кількість {{< glossary_tooltip text="реплік" term_id="replica" >}} в робочому навантаженні, щоб відповідати спостереженню за використанням ресурсів, такими як використання CPU чи памʼяті.

Є [посібник з інструкціями](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough) з налаштування HorizontalPodAutoscaler для Deployment.

### Вертикальне масштабування робочих навантажень {#scaling-workloads-vertically}

{{< feature-state for_k8s_version="v1.25" state="stable" >}}

Ви можете автоматично масштабувати робоче навантаження вертикально за допомогою _VerticalPodAutoscaler_ (VPA). На відміну від HPA, VPA не поставляється стандартно в Kubernetes, але є окремим проєктом, який можна знайти [на GitHub](https://github.com/kubernetes/autoscaler/tree/9f87b78df0f1d6e142234bb32e8acbd71295585a/vertical-pod-autoscaler).

Після встановлення він дозволяє створювати {{< glossary_tooltip text="CustomResourceDefinitions" term_id="customresourcedefinition" >}} (CRDs) для ваших робочих навантажень, які визначають _як_ і _коли_ масштабувати ресурси керованих реплік.

{{< note >}}
Вам потрібно мати встановлений [Metrics Server](https://github.com/kubernetes-sigs/metrics-server) в вашому кластері для роботи VPA.
{{< /note >}}

На цей час VPA може працювати в чотирьох різних режимах:

{{< table caption="Різні режими VPA" >}}
Режим | Опис
:----|:-----------
`Auto` | Наразі `Recreate`. Це може змінитися на оновлення на місці у майбутньому.
`Recreate` | VPA встановлює ресурсні запити при створенні підпорядкованих контейнерів і оновлює їх на наявних контейнерах, витісняючи їх, коли запитані ресурси відрізняються від нової рекомендації.
`Initial` | VPA встановлює ресурсні запити лише при створенні підпорядкованих контейнерів і ніколи не змінює їх пізніше.
`Off` | VPA автоматично не змінює вимоги до ресурсів підпорядкованих контейнерів. Рекомендації обчислюються і можуть бути перевірені в обʼєкті VPA.
{{< /table >}}

#### Вертикальне масштабування Podʼів на місці {#in-place-pod-vertical-scaling}

{{< feature-state feature_gate_name="InPlacePodVerticalScaling" >}}

Починаючи з Kubernetes {{< skew currentVersion >}}, VPA не підтримує зміну розміру podʼів на місці, але над цією інтеграцією працюють. Щоб вручну змінити розмір podʼів на місці, див. [Зміна розмір ресурсів контейнера на місці](/docs/tasks/configure-pod-container/resize-container-resources/).

### Автомасштабування на основі розміру кластера {#autoscaling-based-on-cluster-size}

Для робочих навантажень, які потрібно масштабувати залежно від розміру кластера (наприклад, `cluster-dns` чи інші системні компоненти), ви можете використовувати [_Cluster Proportional Autoscaler_](https://github.com/kubernetes-sigs/cluster-proportional-autoscaler). Так само як і VPA, він не є частиною основного функціонала Kubernetes, але розміщений як окремий проєкт на GitHub.

Cluster Proportional Autoscaler відстежує кількість {{< glossary_tooltip text="вузлів" term_id="node" >}} які готові приймати Podʼи та ядра та масштабує кількість реплік цільового робочого навантаження відповідно.

Якщо кількість реплік має залишитися незмінною, ви можете масштабувати свої робочі навантаження вертикально залежно від розміру кластера, використовуючи [_Cluster Proportional Vertical Autoscaler_](https://github.com/kubernetes-sigs/cluster-proportional-vertical-autoscaler). Проєкт знаходиться **наразі у бета-версії** та доступний на GitHub.

В той час як Cluster Proportional Autoscaler масштабує кількість реплік робочого навантаження, Cluster Proportional Vertical Autoscaler налаштовує вимоги до ресурсів для робочого навантаження (наприклад, Deployment або DaemonSet) залежно від кількості вузлів та/або ядер у кластері.

### Автомасштабування, на підставі подій {#event-driven-autoscaling}

Також існує можливість масштабування робочих навантажень на основі подій, наприклад, використовуючи [_Kubernetes Event Driven Autoscaler_ (**KEDA**)](https://keda.sh/).

KEDA є проєктом, створеним під егідою CNCF, що дозволяє масштабувати ваші робочі навантаження залежно від кількості подій, які потрібно обробити, наприклад, кількість повідомлень в черзі. Існує широкий спектр адаптерів для різних джерел подій на вибір.

### Автомасштабування на основі розкладу {#autoscaling-based-on-schedule}

Ще одна стратегія для масштабування вашого робочого навантаження — це **запланувати** операції масштабування, наприклад, для зменшення використання ресурсів під час годин неактивності.

Схоже на автомасштабування, спровоковане подіями, таку поведінку можна досягти за допомогою KEDA спільно з його [`Cron` scaler](https://keda.sh/docs/latest/scalers/cron/). Scaler `Cron` дозволяє вам визначати розклади (і часові пояси) для масштабування ваших робочих навантажень вгору чи вниз.

## Масштабування інфраструктури кластера {#scaling-cluster-infrastructure}

Якщо масштабування робочих навантажень не вистачає для задоволення ваших потреб, ви також можете масштабувати інфраструктуру вашого кластера.

Масштабування інфраструктури кластера, зазвичай, передбачає додавання або видалення {{< glossary_tooltip text="вузлів" term_id="node" >}}. Дивіться [автомасштабування Вузлів](/docs/concepts/cluster-administration/node-autoscaling/) для отримання додаткової інформації.

## {{% heading "whatsnext" %}}

- Дізнайтеся більше про горизонтальне масштабування
  - [Масштабування StatefulSet](/docs/tasks/run-application/scale-stateful-set/)
  - [Посібник по HorizontalPodAutoscaler](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)
- [Зміна розміру ресурсів контейнера на місці](/docs/tasks/configure-pod-container/resize-container-resources/)
- [Автомасштабування служби DNS в кластері](/docs/tasks/administer-cluster/dns-horizontal-autoscaling/)
- [Автомасштабування Вузлів](/docs/concepts/cluster-administration/node-autoscaling/)
