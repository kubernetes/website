---
title: Podʼи
api_metadata:
- apiVersion: "v1"
  kind: "Pod"
content_type: concept
weight: 10
no_list: true
---

<!-- overview -->

_Podʼи_ — найменші обчислювальні одиниці, які ви можете створити та керувати ними в Kubernetes.

_Pod_ (як у випадку з групою китів або гороховим стручком) — це група з одного або кількох {{< glossary_tooltip text="контейнерів" term_id="container" >}}, які мають спільні ресурси зберігання та мережі, а також специфікацію щодо того, як запускати контейнери. Вміст Podʼа завжди розташований та запускається разом, та працює в спільному контексті. Pod моделює "логічний хост" для вашого застосунку: він містить один або кілька контейнерів застосунку, які мають відносно тісний звʼязок один з одним. По за контекстом хмар, застосунки, що виконуються на одному фізичному або віртуальному компʼютері, аналогічні застосункам, що виконуються на одному логічному хості.

Так само як і контейнери застосунків, Podʼи можуть містити {{< glossary_tooltip text="контейнери ініціалізації" term_id="init-container" >}}, які запускаються під час старту Podʼа. Ви також можете впровадити {{< glossary_tooltip text="тимчасові контейнери" term_id="ephemeral-container" >}} для налагодження, якщо ваш кластер це підтримує.

<!-- body -->

## Що таке Pod? {#what-is-a-pod}

{{< note >}}
Вам потрібно встановити [середовище виконання контейнерів](/docs/setup/production-environment/container-runtimes/) на кожному вузлі кластера, щоб контейнери могли працювати там.
{{< /note >}}

Спільний контекст Podʼа — це набір Linux-просторів імен, cgroups та, можливо, інших аспектів ізоляції — ті самі речі, які ізолюють {{< glossary_tooltip text="контейнер" term_id="container" >}}. В межах контексту Podʼа окремі застосунки можуть мати додаткові підізоляції.

Pod схожий на набір контейнерів із спільними просторами імен та спільними ресурсами файлових систем.

Podʼи в кластері Kubernetes використовуються двома основними способами:

* **Podʼи, що керують одним контейнером**. Модель "один контейнер на Pod" є найпоширенішим використанням в Kubernetes. У цьому випадку Pod можна розглядати як обгортку навколо одного контейнера; Kubernetes керує Podʼами, а не контейнерами безпосередньо.
* **Podʼи, що керують кількома контейнерами, які мають працювати разом**. Pod може інкапсулювати застосунок, який складається з кількох [розміщених разом контейнерів](#how-pods-manage-multiple-containers), які тісно повʼязані та мають спільні ресурси. Такі контейнери утворюють єдиний обʼєкт.

Група кількох контейнерів, розміщених разом в одному Podʼі є відносно складним прикладом. Ви повинні використовувати цей шаблон тільки в конкретних випадках, коли ваші контейнери тісно повʼязані.

Вам не треба запускати кілька контейнерів для забезпечення реплікації (для підтримання стійкості чи місткості); якщо вам потрібно кілька реплік, дивіться [ресурси робочих навантажень](/docs/concepts/workloads/controllers/).

## Використання Podʼів {#using-pods}

Нижче наведено приклад Pod, який складається з контейнера, який запускає образ `nginx:1.14.2`.

{{% code_sample file="pods/simple-pod.yaml" %}}

Для створення Podʼа, показаного вище, виконайте наступну команду:

```shell
kubectl apply -f https://k8s.io/examples/pods/simple-pod.yaml
```

Як правило Podʼи не створюються напряму, навіть одиничні Podʼи. Замість цього, створюйте їх за допомогою ресурсів робочих навантажень. Дивіться [Робота з Podʼами](#working-with-pods) для отримання додаткової інформації про те, як Podʼи використовуються разом з ресурсами робочих навантажень.

### Ресурси навантаження для керування Podʼами {#workload-resources-for-managing-pods}

Зазвичай у вас немає потреби у створенні окремих Pod напряму в Kubernetes, навіть одиничних Podʼів. Натомість створюйте їх за допомогою ресурсів робочих навантажень, таких як {{< glossary_tooltip text="Deployment" term_id="deployment" >}} або {{< glossary_tooltip text="Job" term_id="job" >}}. Якщо ваші Podʼи потребують відстеження стану, розгляньте використання ресурсу {{< glossary_tooltip text="StatefulSet" term_id="statefulset" >}}.

Кожен Pod призначений для запуску одного екземпляра застосунку. Якщо ви хочете масштабувати свій застосунок горизонтально (щоб надати більше ресурсів, запустивши більше екземплярів), вам слід використовувати кілька Podʼів, по одному для кожного екземпляра. У Kubernetes це зазвичай називається _реплікацією_. Репліковані Podʼи створюються та керуються як група ресурсів робочих навантажень разом з їх {{< glossary_tooltip text="контролером" term_id="controller" >}}.

Ознайомтесь з [Podʼи та контролери](#pods-and-controllers) для отримання додаткової інформації про те, як Kubernetes використовує ресурси робочих навантажень та їх контролери для реалізації масштабування та автоматичного відновлення роботи застосунку.

Podʼи можуть надавати два види спільних ресурсів для своїх підпорядкованих контейнерів: [мережу](#pod-networking) та [зберігання](#pod-storage).

## Робота з Podʼами {#working-with-pods}

Ви навряд чи створюватимете окремі Pod напряму в Kubernetes, навіть одиничні Podʼи. Це тому, що Podʼи спроєктовано бути відносно ефемерними, одноразовими обʼєктами, які можуть бути втрачені в будь-який момент. Коли Pod створено (чи це зроблено вами, чи це зроблено автоматично за допомогою {{< glossary_tooltip text="контролера" term_id="controller" >}}), новий Pod планується на виконання на {{< glossary_tooltip text="вузлі" term_id="node" >}} вашого кластера. Pod залишається на цьому вузлі до тих пір, поки він не завершить роботу, обʼєкт Pod видалено, Pod _виселено_ за відсутності ресурсів, або вузол зазнав збою.

{{< note >}}
Перезапуск контейнера в Pod не слід плутати з перезапуском Podʼа. Pod — це не процес, а середовище для запуску контейнера(ів). Pod існує до тих пір, поки його не видалено.
{{< /note >}}

Назва Podʼа має бути дійсним [DNS-піддоменом](/docs/concepts/overview/working-with-objects/names#dns-subdomain-names), але це може призвести до неочікуваних результатів для імені хоста Podʼа. Для найкращої сумісності, імʼя має відповідати більш обмеженим правилам для [DNS-мітки](/docs/concepts/overview/working-with-objects/names#dns-label-names).

### Операційна система Podʼа {#pod-os}

{{< feature-state state="stable" for_k8s_version="v1.25" >}}

Ви маєте вказати значення поля `.spec.os.name` як `linux` або `windows`, щоб вказати ОС, на якій ви хочете запустити Pod. Ці дві ОС підтримуються Kubernetes. У майбутньому цей список може бути розширений.

У Kubernetes v{{< skew currentVersion >}}, значення `.spec.os.name` не впливає на те, як {{< glossary_tooltip text="kube-scheduler" term_id="kube-scheduler" >}} вибирає вузол для запуску Podʼа. У будь-якому кластері, де існує більше однієї операційної системи для запуску вузлів, ви повинні правильно встановити мітку [kubernetes.io/os](/docs/reference/labels-annotations-taints/#kubernetes-io-os) на кожному вузлі та визначити Podʼи з використанням `nodeSelector` на основі мітки операційної системи. Kube-scheduler призначає вашому Podʼа вузол на основі інших критеріїв і може або не може вдало вибрати відповідне розміщення вузлів, де операційна система вузла відповідає контейнерам в такому Podʼі. [Стандарти безпеки Pod](/docs/concepts/security/pod-security-standards/) також використовують це поле, щоб уникнути застосування політик, які не є відповідними для цієї операційної системи.

### Podʼи та контролери {#pods-and-controllers}

Ви можете використовувати ресурси робочих навантажень для створення та керування Podʼами. Контролери ресурсів опікуються реплікацією та розгортанням Podʼів, а також автоматичним відновленням роботи застосунку в разі відмови. Наприклад, якщо Node впав, контролер помітить, що Pod на цьому вузлі перестав працювати, він створить заміну Podʼа. Планувальник поміщає Pod заміну до нового працездатного вузла.

Ось кілька прикладів ресурсів робочих навантажень, які керують одним чи більше Podʼами:

* {{< glossary_tooltip text="Deployment" term_id="deployment" >}}
* {{< glossary_tooltip text="StatefulSet" term_id="statefulset" >}}
* {{< glossary_tooltip text="DaemonSet" term_id="daemonset" >}}

### Визначення посилання на робоче навантаження {#specifying-a-workload-reference}

{{< feature-state feature_gate_name="GenericWorkload" >}}

Стандартно Kubernets планує кожний Pod окремо. Однак деякі тісно повʼязані застосунки потребують одночасного планування групи Podʼів для коректної роботи.

Ви можете повʼязати Pod з обʼєктом [робочого навантаження](/docs/concepts/workloads/workload-api/) за допомогою [посилання на робоче навантаження](/docs/concepts/workloads/pods/workload-reference/). Таким чином ви повідомляєте `kube-scheduler`, що Pod є частиною певної групи, що дозволяє йому приймати скоординовані рішення щодо розміщення для всієї групи одночасно.

### Pod templates {#pod-templates}

Контролери ресурсів {{< glossary_tooltip text="робочих навантажень" term_id="workload" >}} створюють Pod з _pod template_ та керують цими Podʼом від вашого імені.

PodTemplate — це специфікація для створення Pod, і вона включена в ресурси робочих навантажень, такі як [Deployment](/docs/concepts/workloads/controllers/deployment/), [Job](/docs/concepts/workloads/controllers/job/) та [DaemonSet](/docs/concepts/workloads/controllers/daemonset/).

Кожен контролер ресурсів робочих навантажень використовує `PodTemplate` всередині обʼєкта робочого навантаження для створення фактичних Podʼів. `PodTemplate` є частиною бажаного стану будь-якого ресурсу робочого навантаження, який ви використовуєте для запуску вашого застосунку.

Коли ви створюєте Pod, ви можете додати [змінні оточення](/docs/tasks/inject-data-application/define-environment-variable-container/) в шаблон Podʼа для контейнерів, які запускаються в Podʼі.

Приклад нижче — це маніфест простого Job з `template`, який запускає один контейнер. Контейнер в цьому Podʼі виводить повідомлення, а потім призупиняється.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    # Це шаблон Podʼа
    spec:
      containers:
      - name: hello
        image: busybox:1.28
        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
      restartPolicy: OnFailure
    # Кінець щаблону Podʼа
```

Зміна template або перемикання на новий template не має прямого впливу на Podʼи, які вже існують. Якщо ви змінюєте template Podʼа для ресурсу робочого навантаження, цей ресурс має створити Pod заміну, який використовує оновлений template.

Наприклад, контролер StatefulSet переконується, що запущені Pod відповідають поточному template для кожного обʼєкта StatefulSet. Якщо ви редагуєте StatefulSet, щоб змінити його template, StatefulSet починає створювати нові Pod на основі оновленого template. З часом всі старі Pod замінюються новими і оновлення завершується.

Кожен ресурс робочого навантаження реалізує власні правила для обробки змін у template Podʼа. Якщо ви хочете дізнатися більше про StatefulSet, прочитайте [Стратегія оновлення](/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets) в посібнику StatefulSet Basics.

На вузлах {{< glossary_tooltip term_id="kubelet" text="kubelet" >}} безпосередньо не спостерігає або керує жодними деталями щодо template Podʼа та оновлень; ці деталі абстраговані. Ця абстракція та розділення відповідальностей спрощує семантику системи та робить можливим розширення поведінки кластера без зміни наявного коду.

## Оновлення та заміна Podʼів {#pod-update-and-replacement}

Як зазначено в попередньому розділі, коли template Podʼа для ресурсу робочого навантаження змінюється, контролер створює нові Podʼи на основі оновленого template замість оновлення або латання наявних Podʼів.

Kubernetes не забороняє вам керувати Pod напряму. Ви можете оновлювати деякі поля запущеного Pod, на місці. Однак операції оновлення Pod, такі як [`patch`](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#patch-pod-v1-core) та [`replace`](/docs/reference/generated/kubernetes-api/{{< param "version" >}}/#replace-pod-v1-core), мають деякі обмеження:

* Більшість метаданих Podʼа є незмінними. Наприклад, ви не можете змінити поля `namespace`, `name`, `uid` або `creationTimestamp`.
* Якщо `metadata.deletionTimestamp` встановлено, новий запис не може бути доданий до списку `metadata.finalizers`.
* Оновлення Pod може не змінювати поля, крім `spec.containers[*].image`, `spec.initContainers[*].image`, `spec.activeDeadlineSeconds`, `spec.terminationGracePeriodSeconds`, `spec.tolerations` or `spec.schedulingGates`. Для `spec.tolerations` ви можете додавати лише нові записи.
* Коли ви оновлюєте `spec.activeDeadlineSeconds`, дозволені два типи оновлень:
  1. встановлення непризначеному полю позитивного числа;
  2. оновлення поля з позитивного числа на менше, невідʼємне число.

### Субресурси Podʼів {#pod-subresources}

Наведені вище правила оновлення застосовуються до регулярних оновлень podʼів, але інші поля podʼа можуть бути оновлені за допомогою _subresources_.

* **Resize:** Субресурс `resize` дозволяє оновлювати ресурси контейнерів (`spec.containers[*].resources`). Дивіться [Зміна розміру ресурсів контейнера](/docs/tasks/configure-pod-container/resize-container-resources/) для більш детальної інформації.
* **Ефемерні контейнери:** Субресурс `ephemeralContainers` дозволяє додавати {{< glossary_tooltip text="ephemeral containers" term_id="ephemeral-container" >}} до Podʼа. Дивіться [Ефемерні контейнери](/docs/concepts/workloads/pods/ephemeral-containers/) для більш детальної інформації.
* **Status:** Субресурс `status` дозволяє оновити статус контейнера. Зазвичай він використовується лише Kubelet та іншими системними контролерами.
* **Binding:** Субресурс `binding` дозволяє встановити `spec.nodeName` podʼів за допомогою запиту `Binding`. Зазвичай це використовується лише {{< glossary_tooltip text="scheduler" term_id="kube-scheduler" >}}.

### Генерація (покоління) Podʼів {#pod-generation}

* Поле `metadata.generation` є унікальним. Воно автоматично встановлюється системою таким чином, що нові podʼи мають значення `metadata.generation`, рівне 1, і кожне оновлення змінних полів у специфікації podʼа збільшуватиме значення `metadata.generation` на 1.

{{< feature-state feature_gate_name="PodObservedGenerationTracking" >}}

* `observedGeneration` — це поле, яке фіксується в розділі `status` обʼєкта Pod. Kubelet встановить `status.observedGeneration` для відстеження стану podʼа до поточного статусу podʼа. `status.observedGeneration` podʼа відображатиме `metadata.generation` podʼа у момент повідомлення про статус podʼа.

{{< note >}}
Поле `status.observedGeneration` керується kubelet, і зовнішні контролери **не повинні** змінювати це поле.
{{< /note >}}

Різні поля статусу можуть бути повʼязані або з `metadata.generation` поточного циклу синхронізації, або з `metadata.generation` попереднього циклу синхронізації. Ключова відмінність полягає в тому, чи зміна в `spec` відображається безпосередньо в `status`, чи є непрямим результатом поточного процесу.

#### Прямі оновлення статусу {#direct-status-updates}

Для полів статусу, де виділена специфікація безпосередньо відображається, `observedGeneration` буде повʼязане з поточним `metadata.generation` (Generation N).

Ця поведінка застосовується до:

* **Resize Status**: Статус операції зміни розміру ресурсу.
* **Allocated Resources**: Ресурси, виділені Podʼу після зміни розміру.
* **Ephemeral Containers**: Коли додається новий ефемерний контейнер, і він знаходиться в стані `Waiting`.

#### Непрямі оновлення статусу {#indirect-status-updates}

Для полів статусу, які є непрямим результатом виконання специфікації, `observedGeneration` буде повʼязано з `metadata.generation` попереднього циклу синхронізації (покоління N-1).

Ця поведінка застосовується до:

* **Container Image**: `ContainerStatus.ImageID` показує образ з попереднього покоління, поки новий образ не буде завантажено, а контейнер не буде оновлено.
* **Actual Resources**: Під час зміни розміру, фактичні ресурси, що використовуються, все ще належать запиту попереднього покоління.
* **Container state**: Під час зміни розміру, з політикою перезапуску, що вимагає перезапуску, відображає запит попереднього покоління.
* **activeDeadlineSeconds** & **terminationGracePeriodSeconds** & **deletionTimestamp**: Вплив цих полів на статус Podʼа є результатом раніше отриманої специфікації.

## Спільні ресурси та комунікація {#resource-sharing-and-communication}

Podʼи дозволяють контейнерам спільно використовувати ресурси та спілкуватися один з одним.

### Збереження в Podʼах {#pod-storage}

Кожен Pod може вказати набір спільних {{< glossary_tooltip text="ресурсів зберігання" term_id="volume" >}}. Всі контейнери в Pod можуть отримати доступ до спільних томів, що дозволяє цим контейнерам спільно використовувати дані. Також томи дозволяють постійним даним в Pod вижити в разі перезапуску одного з контейнерів. Дивіться [Зберігання](/docs/concepts/storage/) для отримання додаткової інформації про те, як Kubernetes реалізує спільне зберігання та робить його доступним для Podʼів.

### Мережі та Pod {#pod-networking}

Кожен Pod отримує власну унікальну IP-адресу для кожного сімейства адрес. Кожен контейнер в Pod використовує спільний простір імен мережі, включаючи IP-адресу та мережеві порти. В межах Pod (і **тільки** там) контейнери, які належать до Pod, можуть спілкуватися один з одним, використовуючи `localhost`. Коли контейнери в Pod спілкуються з іншими обʼєктами _по за Podʼом_, вони повинні координуватись, як вони використовують спільні мережеві ресурси (такі як порти). В межах Pod контейнери спільно використовують IP-адресу та порти, і можуть знаходити один одного через `localhost`. Контейнери в різних Podʼах мають власні IP-адреси та не можуть спілкуватися за допомогою міжпроцесового звʼязку ОС без спеціальної конфігурації. Контейнери, які хочуть взаємодіяти з контейнером, що працює в іншому Pod, можуть використовувати IP-мережу для комунікації.

Контейнери в Pod бачать системне імʼя хоста таким самим, як і вказане `name` для Pod. Більше про це ви можете прочитати в розділі [мережі](/docs/concepts/cluster-administration/networking/).

## Налаштування безпеки Podʼів {#pod-security}

Щоб встановити обмеження безпеки для Podʼів і контейнерів, використовуйте поле `securityContext` у специфікації Podʼа. Це поле дає вам можливість детально контролювати, що може робити Pod або окремі контейнери. Докладнішу інформацію див. у розділі [Розширена конфігурація Podʼа](/docs/concepts/workloads/pods/advanced-pod-config/).

Для базової конфігурації безпеки слід дотримуватися базового стандарту безпеки Podʼів і запускати контейнери як не-root. Ви можете встановити прості контексти безпеки:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - name: sec-ctx-demo
    image: busybox
    command: ["sh", "-c", "sleep 1h"]
```

Для розширеної конфігурації контексту безпеки, включаючи capabilities, профілі seccomp та детальні параметри безпеки, див. розділ [концепції безпеки](/docs/concepts/security/).

* Щоб дізнатися про обмеження безпеки на рівні ядра, які ви можете використовувати, див. [Обмеження безпеки ядра Linux для Podʼів та контейнерів](/docs/concepts/security/linux-kernel-security-constraints).
* Для отримання додаткової інформації про контекст безпеки Podʼа див. [Налаштування контексту безпеки для Podʼа або контейнера](/docs/tasks/configure-pod-container/security-context/).

## Статичні Podʼи {#static-pods}

{{< feature-state for_k8s_version="v1.22" state="stable" >}}

_Static Pods_ керуються безпосередньо демоном kubelet на конкретному вузлі, без спостереження з боку {{< glossary_tooltip text="сервера API" term_id="kube-apiserver" >}}. У той час як більшість Podʼів керуються панеллю управління (наприклад, {{< glossary_tooltip text="Deployment" term_id="deployment" >}}), для статичних Podʼів kubelet безпосередньо наглядає за кожним статичним Pod (та перезапускає його, якщо він падає).

Статичні Podʼи завжди привʼязані до одного {{< glossary_tooltip term_id="kubelet" text="Kubeletʼу" >}} на конкретному вузлі. Основне використання статичних Podʼів — це запуск самостійної панелі управління: іншими словами, використання kubelet для нагляду за окремими [компонентами панелі управління](/docs/concepts/architecture/#control-plane-components).

Kublet автоматично намагається створити {{< glossary_tooltip text="mirror Pod" term_id="mirror-pod" >}} на сервері API Kubernetes для кожного статичного Pod. Це означає, що Pod, які працюють на вузлі, видно на сервері API, але ними не можна керувати звідти. Дивіться [Створення статичних Podʼів](/docs/tasks/configure-pod-container/static-pod) для отримання додаткової інформації.

{{< note >}}
Розділ `spec` статичного Pod не може посилатися на інші API-обʼєкти (наприклад, {{< glossary_tooltip text="ServiceAccount" term_id="service-account" >}}, {{< glossary_tooltip text="ConfigMap" term_id="configmap" >}}, {{< glossary_tooltip text="Secret" term_id="secret" >}} тощо).
{{< /note >}}

### Як Podʼи керують кількома контейнерами {#how-pods-manage-multiple-containers}

Podʼи спроєктовано для підтримки кількох співпрацюючих процесів (таких як контейнери), які утворюють єдиний обʼєкт служби. Контейнери в Pod автоматично спільно розміщуються та плануються на тому ж фізичному або віртуальному компʼютері в кластері. Контейнери можуть спільно використовувати ресурси та залежності, спілкуватися один з одним та координувати, коли та як вони завершують роботу.

Podʼи в Kubernetes можуть керувати одним або кількома контейнерами двома способами:

* **Podʼи, що керують одним контейнером**. Модель "один контейнер на Pod" є найпоширенішим використанням в Kubernetes. У цьому випадку Pod можна розглядати як обгортку навколо одного контейнера; Kubernetes керує Podʼами, а не контейнерами безпосередньо.
* **Podʼи, що керують кількома контейнерами, які мають працювати разом**. Pod може інкапсулювати застосунок, який складається з кількох розміщених разом контейнерів, які тісно повʼязані та мають спільні ресурси. Ці спільно розташовані контейнери утворюють єдину цілісну службу — наприклад, один контейнер обслуговує дані, збережені в спільному томі, для загального доступу, тоді як окремий {{< glossary_tooltip text="контейнер sidecar" term_id="sidecar-container" >}} оновлює ці файли. Pod обгортає ці контейнери, ресурси сховища та тимчасову мережеву ідентичність разом як єдину одиницю.

Наприклад, у вас може бути контейнер, який виконує функції вебсервера для файлів у спільному томі, та окремий ["sidecar" контейнер](/docs/concepts/workloads/pods/sidecar-containers/), який оновлює ці файли з віддаленого джерела, як показано на наступній діаграмі:

{{< figure src="/images/docs/pod.svg" alt="Діаграма створення Podʼа" class="diagram-medium" >}}

Деякі Podʼи мають {{< glossary_tooltip text="контейнери ініціалізації" term_id="init-container" >}} та {{< glossary_tooltip text="контейнери застосунку" term_id="app-container" >}}. Типово, контейнери ініціалізації запускаються та завершують роботу перед тим, як почнуть працювати контейнери застосунку.

У вас також може бути ["sidecar" контейнер](/docs/concepts/workloads/pods/sidecar-containers/), який виконує додаткові функції для контейнера застосунку, наприклад, реалізує service mesh.

{{< feature-state for_k8s_version="v1.29" state="beta" >}}

Типово увімкнена [функціональна можливість](/docs/reference/command-line-tools-reference/feature-gates/) `SidecarContainers` дозволяє вам вказати `restartPolicy: Always` для контейнерів ініціалізації. Встановлення політики перезапуску `Always` гарантує, що контейнери, там де ви встановили, будуть вважатися як _sidecar_ та працювати протягом усього життєвого циклу Pod. Контейнери, які явно визначені як sidecar контейнери, стартують до запуску основного застосунку Podʼа та працюють допоки Pod не завершить роботу.

## Перевірки контейнерів {#container-probes}

_Probe_ — це діагностика, яку періодично виконує kubelet на контейнері. Для виконання діагностики kubelet може використовувати різні дії:

* `ExecAction` (виконується за допомогою процесу виконання контейнера)
* `TCPSocketAction` (перевіряється безпосередньо the kubelet)
* `HTTPGetAction` (перевіряється безпосередньо kubelet)

Ви можете дізнатися більше про [перевірки](/docs/concepts/workloads/pods/pod-lifecycle/#container-probes) в документації про життєвий цикл Podʼів

## {{% heading "whatsnext" %}}

* Дізнайтесь про [життєвий цикл Podʼів](/docs/concepts/workloads/pods/pod-lifecycle/).
* Дізнайтесь про [PodDisruptionBudget](/docs/concepts/workloads/pods/disruptions/) та як ви можете використовувати його для керування доступністю застосунку під час збоїв.
* Pod є ресурсом найвищого рівня в Kubernetes REST API. Обʼєкт {{< api-reference page="workload-resources/pod-v1" >}} детально описує його.
* [The Distributed System Toolkit: Patterns for Composite Containers](/blog/2015/06/the-distributed-system-toolkit-patterns/) пояснює загальні макети для Pod з більш ніж одним контейнером.
* Дізнайтесь про [Топологію обмежень розподілу Podʼів](/docs/concepts/scheduling-eviction/topology-spread-constraints/)
* Прочитайте [Розширена конфігурація Podʼів](/docs/concepts/workloads/pods/advanced-pod-config/), щоб дізнатися про цю тему докладніше. На цій сторінці висвітлюються аспекти конфігурації Podʼів, що виходять за межі основних положень, зокрема:

  * PriorityClasses
  * RuntimeClasses
  * розширені способи конфігурації _планування_: спосіб, яким Kubernetes вирішує, на якому вузлі повинен працювати Pod.

Для розуміння контексту того, чому Kubernetes обгортає загальний API Pod іншими ресурсами (такими як {{< glossary_tooltip text="StatefulSets" term_id="statefulset" >}} або {{< glossary_tooltip text="Deployments" term_id="deployment" >}}), ви можете прочитати про попередні роботи, включаючи:

* [Aurora](https://aurora.apache.org/documentation/latest/reference/configuration/#job-schema)
* [Borg](https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/)
* [Marathon](https://github.com/d2iq-archive/marathon)
* [Omega](https://research.google/pubs/pub41684/)
* [Tupperware](https://engineering.fb.com/data-center-engineering/tupperware/).
