---
layout: blog
title: "Kubernetes 1.17ï¼šç¨³å®š"
date: 2019-12-09T13ï¼š00ï¼š00-08ï¼š00
slug: kubernetes-1-17-release-announcement
evergreen: true
---

<!-- ---
layout: blog
title: "Kubernetes 1.17: Stability"
date: 2019-12-09T13:00:00-08:00
slug: kubernetes-1-17-release-announcement
evergreen: true
--- -->
**ä½œè€…:** [Kubernetes 1.17å‘å¸ƒå›¢é˜Ÿ](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.17/release_team.md)

<!--
**Authors:** [Kubernetes 1.17 Release Team](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.17/release_team.md)
-->
æˆ‘ä»¬é«˜å…´çš„å®£å¸ƒKubernetes 1.17ç‰ˆæœ¬çš„äº¤ä»˜ï¼Œå®ƒæ˜¯æˆ‘ä»¬2019å¹´çš„ç¬¬å››ä¸ªä¹Ÿæ˜¯æœ€åä¸€ä¸ªå‘å¸ƒç‰ˆæœ¬ã€‚Kubernetes v1.17åŒ…å«22ä¸ªå¢å¼ºåŠŸèƒ½ï¼šæœ‰14ä¸ªå¢å¼ºå·²ç»é€æ­¥ç¨³å®š(stable)ï¼Œ4ä¸ªå¢å¼ºåŠŸèƒ½å·²ç»è¿›å…¥å…¬å¼€æµ‹è¯•ç‰ˆ(beta)ï¼Œ4ä¸ªå¢å¼ºåŠŸèƒ½åˆšåˆšè¿›å…¥å†…éƒ¨æµ‹è¯•ç‰ˆ(alpha)ã€‚
<!--
Weâ€™re pleased to announce the delivery of Kubernetes 1.17, our fourth and final release of 2019! Kubernetes v1.17 consists of 22 enhancements: 14 enhancements have graduated to stable, 4 enhancements are moving to beta, and 4 enhancements are entering alpha.
-->
## ä¸»è¦çš„ä¸»é¢˜
<!--
## Major Themes
-->
### äº‘æœåŠ¡æä¾›å•†æ ‡ç­¾åŸºæœ¬å¯ç”¨
<!--
### Cloud Provider Labels reach General Availability
-->
ä½œä¸ºå…¬å¼€æµ‹è¯•ç‰ˆç‰¹æ€§æ·»åŠ åˆ° v1.2 ï¼Œv1.17 ä¸­å¯ä»¥çœ‹åˆ°äº‘æä¾›å•†æ ‡ç­¾è¾¾åˆ°åŸºæœ¬å¯ç”¨ã€‚
<!--
Added as a beta feature way back in v1.2, v1.17 sees the general availability of cloud provider labels.
-->
### å·å¿«ç…§è¿›å…¥å…¬å¼€æµ‹è¯•ç‰ˆ
<!--
### Volume Snapshot Moves to Beta
-->
åœ¨ v1.17 ä¸­ï¼ŒKuberneteså·å¿«ç…§ç‰¹æ€§æ˜¯å…¬å¼€æµ‹è¯•ç‰ˆã€‚è¿™ä¸ªç‰¹æ€§æ˜¯åœ¨ v1.12 ä¸­ä»¥å†…éƒ¨æµ‹è¯•ç‰ˆå¼•å…¥çš„ï¼Œç¬¬äºŒä¸ªæœ‰é‡å¤§å˜åŒ–çš„å†…éƒ¨æµ‹è¯•ç‰ˆæ˜¯ v1.13 ã€‚
<!--
The Kubernetes Volume Snapshot feature is now beta in Kubernetes v1.17. It was introduced as alpha in Kubernetes v1.12, with a second alpha with breaking changes in Kubernetes v1.13.
-->
## å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»å…¬å¼€æµ‹è¯•ç‰ˆ
<!--
### CSI Migration Beta
 -->
åœ¨ v1.17 ä¸­ï¼ŒKubernetesæ ‘å†…å­˜å‚¨æ’ä»¶åˆ°å®¹å™¨å­˜å‚¨æ¥å£(CSI)çš„è¿ç§»åŸºç¡€æ¶æ„æ˜¯å…¬å¼€æµ‹è¯•ç‰ˆã€‚å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»æœ€åˆæ˜¯åœ¨Kubernetes v1.14 ä¸­ä»¥å†…éƒ¨æµ‹è¯•ç‰ˆå¼•å…¥çš„ã€‚
<!--
The Kubernetes in-tree storage plugin to Container Storage Interface (CSI) migration infrastructure is now beta in Kubernetes v1.17. CSI migration was introduced as alpha in Kubernetes v1.14.
-->
## äº‘æœåŠ¡æä¾›å•†æ ‡ç­¾åŸºæœ¬å¯ç”¨
<!--
## Cloud Provider Labels reach General Availability
-->
å½“èŠ‚ç‚¹å’Œå·è¢«åˆ›å»ºï¼Œä¼šåŸºäºåŸºç¡€äº‘æä¾›å•†çš„Kubernetesé›†ç¾¤æ‰“ä¸Šä¸€ç³»åˆ—æ ‡å‡†æ ‡ç­¾ã€‚èŠ‚ç‚¹ä¼šè·å¾—ä¸€ä¸ªå®ä¾‹ç±»å‹æ ‡ç­¾ã€‚èŠ‚ç‚¹å’Œå·éƒ½ä¼šå¾—åˆ°ä¸¤ä¸ªæè¿°èµ„æºåœ¨äº‘æä¾›å•†æ‹“æ‰‘çš„ä½ç½®æ ‡ç­¾,é€šå¸¸æ˜¯ä»¥åŒºåŸŸå’Œåœ°åŒºçš„æ–¹å¼ç»„ç»‡ã€‚
<!--
When nodes and volumes are created, a set of standard labels are applied based on the underlying cloud provider of the Kubernetes cluster. Nodes get a label for the instance type. Both nodes and volumes get two labels describing the location of the resource in the cloud provider topology, usually organized in zones and regions.
-->

Kubernetesç»„ä»¶ä½¿ç”¨æ ‡å‡†æ ‡ç­¾æ¥æ”¯æŒä¸€äº›ç‰¹æ€§ã€‚ä¾‹å¦‚ï¼Œè°ƒåº¦è€…ä¼šä¿è¯podså’Œå®ƒä»¬æ‰€å£°æ˜çš„å·æ”¾ç½®åœ¨ç›¸åŒçš„åŒºåŸŸï¼›å½“è°ƒåº¦éƒ¨ç½²çš„podsæ—¶ï¼Œè°ƒåº¦å™¨ä¼šä¼˜å…ˆå°†å®ƒä»¬åˆ†å¸ƒåœ¨ä¸åŒçš„åŒºåŸŸã€‚ä½ è¿˜å¯ä»¥åœ¨è‡ªå·±çš„podsæ ‡å‡†ä¸­åˆ©ç”¨æ ‡ç­¾æ¥é…ç½®ï¼Œå¦‚èŠ‚ç‚¹äº²å’Œæ€§ï¼Œä¹‹ç±»çš„äº‹ã€‚æ ‡å‡†æ ‡ç­¾ä½¿å¾—ä½ å†™çš„podè§„èŒƒåœ¨ä¸åŒçš„äº‘æä¾›å•†ä¹‹é—´æ˜¯å¯ç§»æ¤çš„ã€‚
<!--
Standard labels are used by Kubernetes components to support some features. For example, the scheduler would ensure that pods are placed on the same zone as the volumes they claim; and when scheduling pods belonging to a deployment, the scheduler would prioritize spreading them across zones. You can also use the labels in your pod specs to configure things as such node affinity. Standard labels allow you to write pod specs that are portable among different cloud providers.
-->

åœ¨è¿™ä¸ªç‰ˆæœ¬ä¸­ï¼Œæ ‡ç­¾å·²ç»è¾¾åˆ°åŸºæœ¬å¯ç”¨ã€‚Kubernetesç»„ä»¶éƒ½å·²ç»æ›´æ–°ï¼Œå¯ä»¥å¡«å……åŸºæœ¬å¯ç”¨å’Œå…¬å¼€æµ‹è¯•ç‰ˆæ ‡ç­¾ï¼Œå¹¶å¯¹ä¸¤è€…åšå‡ºååº”ã€‚ç„¶è€Œï¼Œå¦‚æœä½ çš„podè§„èŒƒæˆ–è‡ªå®šä¹‰çš„æ§åˆ¶å™¨æ­£åœ¨ä½¿ç”¨å…¬å¼€æµ‹è¯•ç‰ˆæ ‡ç­¾ï¼Œå¦‚èŠ‚ç‚¹äº²å’Œæ€§ï¼Œæˆ‘ä»¬å»ºè®®ä½ å¯ä»¥å°†å®ƒä»¬è¿ç§»åˆ°æ–°çš„åŸºæœ¬å¯ç”¨æ ‡ç­¾ä¸­ã€‚ä½ å¯ä»¥ä»å¦‚ä¸‹åœ°æ–¹æ‰¾åˆ°æ–°æ ‡ç­¾çš„æ–‡æ¡£ï¼š
<!--
The labels are reaching general availability in this release. Kubernetes components have been updated to populate the GA and beta labels and to react to both. However, if you are using the beta labels in your pod specs for features such as node affinity, or in your custom controllers, we recommend that you start migrating them to the new GA labels. You can find the documentation for the new labels here:
-->

- [å®ä¾‹ç±»å‹](/zh-cn/docs/reference/labels-annotations-taints/#nodekubernetesioinstance-type)
- [åœ°åŒº](/zh-cn/docs/reference/labels-annotations-taints/#topologykubernetesioregion)
- [åŒºåŸŸ](/zh-cn/docs/reference/labels-annotations-taints/#topologykubernetesiozone)

<!--
- [node.kubernetes.io/instance-type](/docs/reference/labels-annotations-taints/#nodekubernetesioinstance-type)
- [topology.kubernetes.io/region](/docs/reference/labels-annotations-taints/#topologykubernetesioregion)
- [topology.kubernetes.io/zone](/docs/reference/labels-annotations-taints/#topologykubernetesiozone)
-->
## å·å¿«ç…§è¿›å…¥å…¬å¼€æµ‹è¯•ç‰ˆ
<!--
## Volume Snapshot Moves to Beta
-->
åœ¨ v1.17 ä¸­ï¼ŒKuberneteså·å¿«ç…§æ˜¯æ˜¯å…¬å¼€æµ‹è¯•ç‰ˆã€‚æœ€åˆæ˜¯åœ¨ v1.12 ä¸­ä»¥å†…éƒ¨æµ‹è¯•ç‰ˆå¼•å…¥çš„ï¼Œç¬¬äºŒä¸ªæœ‰é‡å¤§å˜åŒ–çš„å†…éƒ¨æµ‹è¯•ç‰ˆæ˜¯ v1.13 ã€‚è¿™ç¯‡æ–‡ç« æ€»ç»“å®ƒåœ¨å…¬å¼€ç‰ˆæœ¬ä¸­çš„å˜åŒ–ã€‚
<!--
The Kubernetes Volume Snapshot feature is now beta in Kubernetes v1.17. It was introduced as alpha in Kubernetes v1.12, with a second alpha with breaking changes in Kubernetes v1.13.  This post summarizes the changes in the beta release.
-->
### å·å¿«ç…§æ˜¯ä»€ä¹ˆï¼Ÿ
<!--
### What is a Volume Snapshot?
-->
è®¸å¤šçš„å­˜å‚¨ç³»ç»Ÿ(å¦‚è°·æ­Œäº‘æŒä¹…åŒ–ç£ç›˜ï¼Œäºšé©¬é€Šå¼¹æ€§å—å­˜å‚¨å’Œè®¸å¤šçš„å†…éƒ¨å­˜å‚¨ç³»ç»Ÿ)æ”¯æŒä¸ºæŒä¹…å·åˆ›å»ºå¿«ç…§ã€‚å¿«ç…§ä»£è¡¨å·åœ¨ä¸€ä¸ªæ—¶é—´ç‚¹çš„å¤åˆ¶ã€‚å®ƒå¯ç”¨äºé…ç½®æ–°å·(ä½¿ç”¨å¿«ç…§æ•°æ®æå‰å¡«å……)æˆ–æ¢å¤å·åˆ°ä¸€ä¸ªä¹‹å‰çš„çŠ¶æ€(ç”¨å¿«ç…§è¡¨ç¤º)ã€‚
<!--
Many storage systems (like Google Cloud Persistent Disks, Amazon Elastic Block Storage, and many on-premise storage systems) provide the ability to create a â€œsnapshotâ€ of a persistent volume. A snapshot represents a point-in-time copy of a volume. A snapshot can be used either to provision a new volume (pre-populated with the snapshot data) or to restore an existing volume to a previous state (represented by the snapshot).
-->
### ä¸ºä»€ä¹ˆç»™KubernetesåŠ å…¥å·å¿«ç…§ï¼Ÿ
<!--
### Why add Volume Snapshots to Kubernetes?
-->
Kuberneteså·æ’ä»¶ç³»ç»Ÿå·²ç»æä¾›äº†åŠŸèƒ½å¼ºå¤§çš„æŠ½è±¡ç”¨äºè‡ªåŠ¨é…ç½®ã€é™„åŠ å’ŒæŒ‚è½½å—æ–‡ä»¶ç³»ç»Ÿã€‚
<!--
The Kubernetes volume plugin system already provides a powerful abstraction that automates the provisioning, attaching, and mounting of block and file storage.
-->

æ”¯æŒæ‰€æœ‰è¿™äº›ç‰¹æ€§æ˜¯Kubernetesè´Ÿè½½å¯ç§»æ¤çš„ç›®æ ‡ï¼šKubernetesæ—¨åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨å’Œåº•å±‚é›†ç¾¤ä¹‹é—´åˆ›å»ºä¸€ä¸ªæŠ½è±¡å±‚,ä½¿å¾—åº”ç”¨å¯ä»¥ä¸æ„ŸçŸ¥å…¶è¿è¡Œé›†ç¾¤çš„å…·ä½“ä¿¡æ¯å¹¶ä¸”éƒ¨ç½²ä¹Ÿä¸éœ€ç‰¹å®šé›†ç¾¤çš„çŸ¥è¯†ã€‚
<!--
Underpinning all these features is the Kubernetes goal of workload portability: Kubernetes aims to create an abstraction layer between distributed systems applications and underlying clusters so that applications can be agnostic to the specifics of the cluster they run on and application deployment requires no â€œcluster specificâ€ knowledge.
-->

Kuberneteså­˜å‚¨ç‰¹åˆ«å…´è¶£ç»„(SIG)å°†å¿«ç…§æ“ä½œç¡®å®šä¸ºå¯¹å¾ˆå¤šæœ‰çŠ¶æ€è´Ÿè½½çš„å…³é”®åŠŸèƒ½ã€‚å¦‚æ•°æ®åº“ç®¡ç†å‘˜å¸Œæœ›åœ¨æ“ä½œæ•°æ®åº“å‰ä¿å­˜æ•°æ®åº“å·å¿«ç…§ã€‚
<!--
The Kubernetes Storage SIG identified snapshot operations as critical functionality for many stateful workloads. For example, a database administrator may want to snapshot a database volume before starting a database operation.
-->

åœ¨Kubernetesæ¥å£ä¸­æä¾›ä¸€ç§æ ‡å‡†çš„æ–¹å¼è§¦å‘å¿«ç…§æ“ä½œï¼ŒKubernetesç”¨æˆ·å¯ä»¥å¤„ç†è¿™ç§ç”¨æˆ·åœºæ™¯ï¼Œè€Œä¸å¿…ä½¿ç”¨Kubernetes API(å¹¶æ‰‹åŠ¨æ‰§è¡Œå­˜å‚¨ç³»ç»Ÿçš„å…·ä½“æ“ä½œ)ã€‚
<!--
By providing a standard way to trigger snapshot operations in the Kubernetes API, Kubernetes users can now handle use cases like this without having to go around the Kubernetes API (and manually executing storage system specific operations).
-->

å–è€Œä»£ä¹‹çš„æ˜¯ï¼ŒKubernetesç”¨æˆ·ç°åœ¨è¢«æˆæƒä»¥ä¸é›†ç¾¤æ— å…³çš„æ–¹å¼å°†å¿«ç…§æ“ä½œæ”¾è¿›ä»–ä»¬çš„å·¥å…·å’Œç­–ç•¥ä¸­ï¼Œå¹¶ä¸”ç¡®ä¿¡å®ƒå°†å¯¹ä»»æ„çš„Kubernetesé›†ç¾¤æœ‰æ•ˆï¼Œè€Œä¸åº•å±‚å­˜å‚¨æ— å…³ã€‚
<!--
Instead, Kubernetes users are now empowered to incorporate snapshot operations in a cluster agnostic way into their tooling and policy with the comfort of knowing that it will work against arbitrary Kubernetes clusters regardless of the underlying storage.
-->

æ­¤å¤–ï¼ŒKubernetes å¿«ç…§åŸè¯­ä½œä¸ºåŸºç¡€æ„å»ºèƒ½åŠ›è§£é”äº†ä¸ºKuberneteså¼€å‘é«˜çº§ã€ä¼ä¸šçº§ã€å­˜å‚¨ç®¡ç†ç‰¹æ€§çš„èƒ½åŠ›:åŒ…æ‹¬åº”ç”¨æˆ–é›†ç¾¤çº§åˆ«çš„å¤‡ä»½æ–¹æ¡ˆã€‚
<!--
Additionally these Kubernetes snapshot primitives act as basic building blocks that unlock the ability to develop advanced, enterprise grade, storage administration features for Kubernetes: including application or cluster level backup solutions.
-->

ä½ å¯ä»¥é˜…è¯»æ›´å¤šå…³äº[å‘å¸ƒå®¹å™¨å­˜å‚¨æ¥å£å·å¿«ç…§å…¬å¼€æµ‹è¯•ç‰ˆ](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-cis-volume-snapshot-beta/)
<!--
You can read more in the blog entry about [releasing CSI volume snapshots to beta](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-cis-volume-snapshot-beta/).
-->
## å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»å…¬æµ‹ç‰ˆ
<!--
## CSI Migration Beta
-->
### ä¸ºä»€ä¹ˆæˆ‘ä»¬è¿ç§»å†…å»ºæ ‘æ’ä»¶åˆ°å®¹å™¨å­˜å‚¨æ¥å£ï¼Ÿ
<!--
### Why are we migrating in-tree plugins to CSI?
-->
åœ¨å®¹å™¨å­˜å‚¨æ¥å£ä¹‹å‰ï¼ŒKubernetesæä¾›åŠŸèƒ½å¼ºå¤§çš„å·æ’ä»¶ç³»ç»Ÿã€‚è¿™äº›å·æ’ä»¶æ˜¯æ ‘å†…çš„æ„å‘³ç€å®ƒä»¬çš„ä»£ç æ˜¯æ ¸å¿ƒKubernetesä»£ç çš„ä¸€éƒ¨åˆ†å¹¶é™„å¸¦åœ¨æ ¸å¿ƒKubernetesäºŒè¿›åˆ¶ä¸­ã€‚ç„¶è€Œï¼Œä¸ºKubernetesæ·»åŠ æ’ä»¶æ”¯æŒæ–°å·æ˜¯éå¸¸æœ‰æŒ‘æˆ˜çš„ã€‚å¸Œæœ›åœ¨Kubernetesä¸Šä¸ºè‡ªå·±å­˜å‚¨ç³»ç»Ÿæ·»åŠ æ”¯æŒ(æˆ–ä¿®å¤ç°æœ‰å·æ’ä»¶çš„bug)çš„ä¾›åº”å•†è¢«è¿«ä¸Kuberneteså‘è¡Œè¿›ç¨‹å¯¹é½ã€‚æ­¤å¤–ï¼Œç¬¬ä¸‰æ–¹å­˜å‚¨ä»£ç åœ¨æ ¸å¿ƒKubernetesäºŒè¿›åˆ¶ä¸­ä¼šé€ æˆå¯é æ€§å’Œå®‰å…¨é—®é¢˜ï¼Œå¹¶ä¸”è¿™äº›ä»£ç å¯¹äºKubernetesçš„ç»´æŠ¤è€…æ¥è¯´æ˜¯éš¾ä»¥(ä¸€äº›åœºæ™¯æ˜¯ä¸å¯èƒ½)æµ‹è¯•å’Œç»´æŠ¤çš„ã€‚åœ¨Kubernetesä¸Šé‡‡ç”¨å®¹å™¨å­˜å‚¨æ¥å£å¯ä»¥è§£å†³å¤§éƒ¨åˆ†é—®é¢˜ã€‚
<!--
Prior to CSI, Kubernetes provided a powerful volume plugin system. These volume plugins were â€œin-treeâ€ meaning their code was part of the core Kubernetes code and shipped with the core Kubernetes binaries. However, adding support for new volume plugins to Kubernetes was challenging. Vendors that wanted to add support for their storage system to Kubernetes (or even fix a bug in an existing volume plugin) were forced to align with the Kubernetes release process. In addition, third-party storage code caused reliability and security issues in core Kubernetes binaries and the code was often difficult (and in some cases impossible) for Kubernetes maintainers to test and maintain. Using the Container Storage Interface in Kubernetes resolves these major issues.
 -->

éšç€æ›´å¤šå®¹å™¨å­˜å‚¨æ¥å£é©±åŠ¨å˜æˆç”Ÿäº§ç¯å¢ƒå¯ç”¨ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„Kubernetesç”¨æˆ·ä»å®¹å™¨å­˜å‚¨æ¥å£æ¨¡å‹ä¸­è·ç›Šã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¸å¸Œæœ›å¼ºåˆ¶ç”¨æˆ·ä»¥ç ´åç°æœ‰åŸºæœ¬å¯ç”¨çš„å­˜å‚¨æ¥å£çš„æ–¹å¼å»æ”¹å˜è´Ÿè½½å’Œé…ç½®ã€‚é“è·¯å¾ˆæ˜ç¡®ï¼Œæˆ‘ä»¬å°†ä¸å¾—ä¸ç”¨CSIæ›¿æ¢æ ‘å†…æ’ä»¶æ¥å£ã€‚ä»€ä¹ˆæ˜¯å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»ï¼Ÿ
<!--
As more CSI Drivers were created and became production ready, we wanted all Kubernetes users to reap the benefits of the CSI model. However, we did not want to force users into making workload/configuration changes by breaking the existing generally available storage APIs. The way forward was clear - we would have to replace the backend of the â€œin-tree pluginâ€ APIs with CSI.
What is CSI migration?
-->

åœ¨å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»ä¸Šæ‰€åšçš„åŠªåŠ›ä½¿å¾—æ›¿æ¢ç°æœ‰çš„æ ‘å†…å­˜å‚¨æ’ä»¶ï¼Œå¦‚`kubernetes.io/gce-pd`æˆ–`kubernetes.io/aws-ebs`ï¼Œä¸ºç›¸åº”çš„å®¹å™¨å­˜å‚¨æ¥å£é©±åŠ¨æˆä¸ºå¯èƒ½ã€‚å¦‚æœå®¹å™¨å­˜å‚¨æ¥å£è¿ç§»æ­£å¸¸å·¥ä½œï¼ŒKubernetesç»ˆç«¯ç”¨æˆ·ä¸ä¼šæ³¨æ„åˆ°ä»»ä½•å·®åˆ«ã€‚è¿ç§»è¿‡åï¼ŒKubernetesç”¨æˆ·å¯ä»¥ç»§ç»­ä½¿ç”¨ç°æœ‰æ¥å£æ¥ä¾èµ–æ ‘å†…å­˜å‚¨æ’ä»¶çš„åŠŸèƒ½ã€‚
<!--
The CSI migration effort enables the replacement of existing in-tree storage plugins such as `kubernetes.io/gce-pd` or `kubernetes.io/aws-ebs` with a corresponding CSI driver. If CSI Migration is working properly, Kubernetes end users shouldnâ€™t notice a difference. After migration, Kubernetes users may continue to rely on all the functionality of in-tree storage plugins using the existing interface.
 -->

å½“Kubernetesé›†ç¾¤ç®¡ç†è€…æ›´æ–°é›†ç¾¤ä½¿å¾—CSIè¿ç§»å¯ç”¨ï¼Œç°æœ‰çš„æœ‰çŠ¶æ€éƒ¨ç½²å’Œå·¥ä½œè´Ÿè½½ç…§å¸¸å·¥ä½œï¼›ç„¶è€Œï¼Œåœ¨å¹•åKuberneteså°†å­˜å‚¨ç®¡ç†æ“ä½œäº¤ç»™äº†(ä»¥å‰æ˜¯äº¤ç»™æ ‘å†…é©±åŠ¨)CSIé©±åŠ¨ã€‚
<!--
When a Kubernetes cluster administrator updates a cluster to enable CSI migration, existing stateful deployments and workloads continue to function as they always have; however, behind the scenes Kubernetes hands control of all storage management operations (previously targeting in-tree drivers) to CSI drivers.
-->

Kubernetesç»„éå¸¸åŠªåŠ›åœ°ä¿è¯å­˜å‚¨æ¥å£çš„ç¨³å®šæ€§å’Œå¹³æ»‘å‡çº§ä½“éªŒçš„æ‰¿è¯ºã€‚è¿™éœ€è¦ç»†è‡´çš„è€ƒè™‘ç°æœ‰ç‰¹æ€§å’Œè¡Œä¸ºæ¥ç¡®ä¿åå‘å…¼å®¹å’Œæ¥å£ç¨³å®šæ€§ã€‚ä½ å¯ä»¥æƒ³åƒæˆåœ¨åŠ é€Ÿè¡Œé©¶çš„ç›´çº¿ä¸Šç»™èµ›è½¦æ¢è½®èƒã€‚
<!--
The Kubernetes team has worked hard to ensure the stability of storage APIs and for the promise of a smooth upgrade experience. This involves meticulous accounting of all existing features and behaviors to ensure backwards compatibility and API stability. You can think of it like changing the wheels on a racecar while itâ€™s speeding down the straightaway.
-->

ä½ å¯ä»¥åœ¨è¿™ç¯‡åšå®¢ä¸­é˜…è¯»æ›´å¤šå…³äº[å®¹å™¨å­˜å‚¨æ¥å£è¿ç§»æˆä¸ºå…¬å¼€æµ‹è¯•ç‰ˆ](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/).
<!--
You can read more in the blog entry about [CSI migration going to beta](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/).
-->
## å…¶å®ƒæ›´æ–°
<!--
## Other Updates
 -->
### ç¨³å®šğŸ’¯
<!--
### Graduated to Stable ğŸ’¯
-->
- [æŒ‰æ¡ä»¶æ±¡æŸ“èŠ‚ç‚¹](https://github.com/kubernetes/enhancements/issues/382)
- [å¯é…ç½®çš„Podè¿›ç¨‹å…±äº«å‘½åç©ºé—´](https://github.com/kubernetes/enhancements/issues/495)
- [é‡‡ç”¨kube-schedulerè°ƒåº¦DaemonSet Pods](https://github.com/kubernetes/enhancements/issues/548)
- [åŠ¨æ€å·æœ€å¤§å€¼](https://github.com/kubernetes/enhancements/issues/554)
- [Kuberneteså®¹å™¨å­˜å‚¨æ¥å£æ”¯æŒæ‹“æ‰‘](https://github.com/kubernetes/enhancements/issues/557)
- [åœ¨SubPathæŒ‚è½½æä¾›ç¯å¢ƒå˜é‡æ‰©å±•](https://github.com/kubernetes/enhancements/issues/559)
- [ä¸ºCustom Resourcesæä¾›é»˜è®¤å€¼](https://github.com/kubernetes/enhancements/issues/575)
- [ä»é¢‘ç¹çš„Kubletå¿ƒè·³åˆ°ç§Ÿçº¦æ¥å£](https://github.com/kubernetes/enhancements/issues/589)
- [æ‹†åˆ†Kubernetesæµ‹è¯•Tarball](https://github.com/kubernetes/enhancements/issues/714)
- [æ·»åŠ Watchä¹¦ç­¾æ”¯æŒ](https://github.com/kubernetes/enhancements/issues/956)
- [è¡Œä¸ºé©±åŠ¨ä¸€è‡´æ€§æµ‹è¯•](https://github.com/kubernetes/enhancements/issues/960)
- [æœåŠ¡è´Ÿè½½å‡è¡¡ç»ˆç»“ä¿æŠ¤](https://github.com/kubernetes/enhancements/issues/980)
- [é¿å…æ¯ä¸€ä¸ªWatcherç‹¬ç«‹åºåˆ—åŒ–ç›¸åŒçš„å¯¹è±¡](https://github.com/kubernetes/enhancements/issues/1152)

<!--
- [Taint Node by Condition](https://github.com/kubernetes/enhancements/issues/382)
- [Configurable Pod Process Namespace Sharing](https://github.com/kubernetes/enhancements/issues/495)
- [Schedule DaemonSet Pods by kube-scheduler](https://github.com/kubernetes/enhancements/issues/548)
- [Dynamic Maximum Volume Count](https://github.com/kubernetes/enhancements/issues/554)
- [Kubernetes CSI Topology Support](https://github.com/kubernetes/enhancements/issues/557)
- [Provide Environment Variables Expansion in SubPath Mount](https://github.com/kubernetes/enhancements/issues/559)
- [Defaulting of Custom Resources](https://github.com/kubernetes/enhancements/issues/575)
- [Move Frequent Kubelet Heartbeats To Lease Api](https://github.com/kubernetes/enhancements/issues/589)
- [Break Apart The Kubernetes Test Tarball](https://github.com/kubernetes/enhancements/issues/714)
- [Add Watch Bookmarks Support](https://github.com/kubernetes/enhancements/issues/956)
- [Behavior-Driven Conformance Testing](https://github.com/kubernetes/enhancements/issues/960)
- [Finalizer Protection For Service Loadbalancers](https://github.com/kubernetes/enhancements/issues/980)
- [Avoid Serializing The Same Object Independently For Every Watcher](https://github.com/kubernetes/enhancements/issues/1152)
-->
### ä¸»è¦å˜åŒ–
<!--
### Major Changes
-->
- [æ·»åŠ IPv4/IPv6åŒæ ˆæ”¯æŒ](https://github.com/kubernetes/enhancements/issues/563)

<!--
- [Add IPv4/IPv6 Dual Stack Support](https://github.com/kubernetes/enhancements/issues/563)
-->
### å…¶å®ƒæ˜¾è‘—ç‰¹æ€§
<!--
### Other Notable Features
-->
- [æ‹“æ‰‘æ„ŸçŸ¥è·¯ç”±æœåŠ¡(å†…éƒ¨æµ‹è¯•ç‰ˆ)](https://github.com/kubernetes/enhancements/issues/536)
- [ä¸ºWindowsæ·»åŠ RunAsUserName](https://github.com/kubernetes/enhancements/issues/1043)

<!--
- [Topology Aware Routing of Services (Alpha)](https://github.com/kubernetes/enhancements/issues/536)
- [RunAsUserName for Windows](https://github.com/kubernetes/enhancements/issues/1043)
-->
### å¯ç”¨æ€§
<!--
### Availability
-->
Kubernetes 1.17 å¯ä»¥[åœ¨GitHubä¸‹è½½](https://github.com/kubernetes/kubernetes/releases/tag/v1.17.0)ã€‚å¼€å§‹ä½¿ç”¨Kubernetesï¼Œçœ‹çœ‹è¿™äº›[äº¤äº’æ•™å­¦](https://kubernetes.io/docs/tutorials/)ã€‚ä½ å¯ä»¥éå¸¸å®¹æ˜“ä½¿ç”¨[kubeadm](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)å®‰è£…1.17ã€‚
<!--
Kubernetes 1.17 is available for [download on GitHub](https://github.com/kubernetes/kubernetes/releases/tag/v1.17.0). To get started with Kubernetes, check out these [interactive tutorials](https://kubernetes.io/docs/tutorials/). You can also easily install 1.17 using [kubeadm](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/).
 -->
### å‘å¸ƒå›¢é˜Ÿ
<!--
### Release Team
-->
æ­£æ˜¯å› ä¸ºæœ‰ä¸Šåƒäººå‚ä¸æŠ€æœ¯æˆ–éæŠ€æœ¯å†…å®¹çš„è´¡çŒ®æ‰ä½¿è¿™ä¸ªç‰ˆæœ¬æˆä¸ºå¯èƒ½ã€‚ç‰¹åˆ«æ„Ÿè°¢ç”±Guinevere Saengeré¢†å¯¼çš„[å‘å¸ƒå›¢é˜Ÿ](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.17/release_team.md)ã€‚å‘å¸ƒå›¢é˜Ÿçš„35åæˆå‘˜åœ¨å‘å¸ƒç‰ˆæœ¬çš„å¤šæ–¹é¢è¿›è¡Œäº†åè°ƒï¼Œä»æ–‡æ¡£åˆ°æµ‹è¯•ï¼Œæ ¡éªŒå’Œç‰¹æ€§çš„å®Œå–„ã€‚
<!--
This release is made possible through the efforts of hundreds of individuals who contributed both technical and non-technical content. Special thanks to the [release team](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.17/release_team.md) led by Guinevere Saenger. The 35 individuals on the release team coordinated many aspects of the release, from documentation to testing, validation, and feature completeness.
-->
éšç€Kubernetesç¤¾åŒºçš„æˆé•¿ï¼Œæˆ‘ä»¬çš„å‘å¸ƒæµç¨‹æ˜¯åœ¨å¼€æºè½¯ä»¶åä½œæ–¹é¢æƒŠäººçš„ç¤ºä¾‹ã€‚Kuberneteså¿«é€Ÿå¹¶æŒç»­è·å¾—æ–°ç”¨æˆ·ã€‚è¿™ä¸€æˆé•¿äº§ç”Ÿäº†è‰¯æ€§çš„åé¦ˆå¾ªç¯ï¼Œæ›´å¤šçš„è´¡çŒ®è€…è´¡çŒ®ä»£ç åˆ›é€ äº†æ›´åŠ æ´»è·ƒçš„ç”Ÿæ€ã€‚Kuberneteså·²ç»æœ‰è¶…è¿‡[39000ä½è´¡çŒ®è€…](https://k8s.devstats.cncf.io/d/24/overall-project-statistics?orgId=1)å’Œä¸€ä¸ªè¶…è¿‡66000äººçš„æ´»è·ƒç¤¾åŒºã€‚
<!--
As the Kubernetes community has grown, our release process represents an amazing demonstration of collaboration in open source software development. Kubernetes continues to gain new users at a rapid pace. This growth creates a positive feedback cycle where more contributors commit code creating a more vibrant ecosystem. Kubernetes has had over [39,000 individual contributors](https://k8s.devstats.cncf.io/d/24/overall-project-statistics?orgId=1) to date and an active community of more than 66,000 people.
-->
### ç½‘ç»œç ”è®¨ä¼š
<!--
### Webinar
-->
2020å¹´1æœˆ7å·ï¼ŒåŠ å…¥Kubernetes 1.17å‘å¸ƒå›¢é˜Ÿï¼Œå­¦ä¹ å…³äºè¿™æ¬¡å‘å¸ƒçš„ä¸»è¦ç‰¹æ€§ã€‚[è¿™é‡Œ](https://zoom.us/webinar/register/9315759188139/WN_kPOZA_6RTjeGdXTG7YFO3A)æ³¨å†Œã€‚
<!--
Join members of the Kubernetes 1.17 release team on Jan 7th, 2020 to learn about the major features in this release. Register [here](https://zoom.us/webinar/register/9315759188139/WN_kPOZA_6RTjeGdXTG7YFO3A).
-->
### å‚ä¸å…¶ä¸­
<!--
### Get Involved
-->
æœ€ç®€å•çš„å‚ä¸Kubernetesçš„æ–¹å¼æ˜¯åŠ å…¥å…¶ä¸­ä¸€ä¸ªä¸ä½ å…´è¶£ç›¸åŒçš„[ç‰¹åˆ«å…´è¶£ç»„](https://github.com/kubernetes/community/blob/master/sig-list.md)ï¼ˆSIGs)ã€‚æœ‰ä»€ä¹ˆæƒ³è¦å¹¿æ’­åˆ°Kubernetesç¤¾åŒºå—ï¼Ÿé€šè¿‡å¦‚ä¸‹çš„é¢‘é“ï¼Œåœ¨æ¯å‘¨çš„[ç¤¾åŒºä¼šè®®](https://github.com/kubernetes/community/tree/master/communication)åˆ†äº«ä½ çš„å£°éŸ³ã€‚æ„Ÿè°¢ä½ çš„è´¡çŒ®å’Œæ”¯æŒã€‚
<!--
The simplest way to get involved with Kubernetes is by joining one of the many [Special Interest Groups](https://github.com/kubernetes/community/blob/master/sig-list.md) (SIGs) that align with your interests. Have something youâ€™d like to broadcast to the Kubernetes community? Share your voice at our weekly [community meeting](https://github.com/kubernetes/community/tree/master/communication), and through the channels below. Thank you for your continued feedback and support.
-->

- åœ¨Twitterä¸Šå…³æ³¨æˆ‘ä»¬[@Kubernetesio](https://twitter.com/kubernetesio)è·å–æœ€æ–°çš„æ›´æ–°
- åœ¨[Discuss](https://discuss.kubernetes.io/)å‚ä¸ç¤¾åŒºçš„è®¨è®º
- åœ¨[Slack](http://slack.k8s.io/)åŠ å…¥ç¤¾åŒº
- åœ¨[Stack Overflow](http://stackoverflow.com/questions/tagged/kubernetes)å‘å¸ƒé—®é¢˜(æˆ–å›ç­”é—®é¢˜)
- åˆ†äº«ä½ çš„Kubernetes[æ•…äº‹](https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform)

<!--
- Follow us on Twitter [@Kubernetesio](https://twitter.com/kubernetesio) for latest updates
- Join the community discussion on [Discuss](https://discuss.kubernetes.io/)
- Join the community on [Slack](http://slack.k8s.io/)
- Post questions (or answer questions) on [Stack Overflow](http://stackoverflow.com/questions/tagged/kubernetes)
- Share your Kubernetes [story](https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform)
 -->
