---
layout: blog
title: 'Kubernetes v1.30 初探'
date: 2024-03-12
slug: kubernetes-1-30-upcoming-changes
---
<!--
layout: blog
title: 'A Peek at Kubernetes v1.30'
date: 2024-03-12
slug: kubernetes-1-30-upcoming-changes
-->

<!-- 
**Authors:** Amit Dsouza, Frederick Kautz, Kristin Martin, Abigail McCarthy, Natali Vlatko
-->
**作者:** Amit Dsouza, Frederick Kautz, Kristin Martin, Abigail McCarthy, Natali Vlatko

**譯者:** Paco Xu (DaoCloud)

<!--
## A quick look: exciting changes in Kubernetes v1.30

It's a new year and a new Kubernetes release. We're halfway through the release cycle and
have quite a few interesting and exciting enhancements coming in v1.30. From brand new features
in alpha, to established features graduating to stable, to long-awaited improvements, this release
has something for everyone to pay attention to!

To tide you over until the official release, here's a sneak peek of the enhancements we're most
excited about in this cycle!
-->

## 快速預覽：Kubernetes v1.30 中令人興奮的變化

新年新版本，v1.30 發佈週期已過半，我們將迎來一系列有趣且令人興奮的增強功能。
從全新的 alpha 特性，到已有的特性升級爲穩定版，再到期待已久的改進，這個版本對每個人都有值得關注的內容！

爲了讓你在正式發佈之前對其有所瞭解，下面給出我們在這個週期中最爲期待的增強功能的預覽！

<!--
## Major changes for Kubernetes v1.30
-->
## Kubernetes v1.30 的主要變化

<!--
### Structured parameters for dynamic resource allocation ([KEP-4381](https://kep.k8s.io/4381))
-->
### 動態資源分配（DRA）的結構化參數 ([KEP-4381](https://kep.k8s.io/4381))

<!--
[Dynamic resource allocation](/docs/concepts/scheduling-eviction/dynamic-resource-allocation/) was
added to Kubernetes as an alpha feature in v1.26. It defines an alternative to the traditional
device-plugin API for requesting access to third-party resources. By design, dynamic resource
allocation uses parameters for resources that are completely opaque to core Kubernetes. This
approach poses a problem for the Cluster Autoscaler (CA) or any higher-level controller that
needs to make decisions for a group of pods (e.g. a job scheduler). It cannot simulate the effect of
allocating or deallocating claims over time. Only the third-party DRA drivers have the information
available to do this.
-->
[動態資源分配（DRA）](/zh-cn/docs/concepts/scheduling-eviction/dynamic-resource-allocation/) 在 Kubernetes v1.26 中作爲 alpha 特性添加。
它定義了一種替代傳統設備插件 device plugin API 的方式，用於請求訪問第三方資源。
在設計上，動態資源分配（DRA）使用的資源參數對於核心 Kubernetes 完全不透明。
這種方法對於叢集自動縮放器（CA）或任何需要爲一組 Pod 做決策的高級控制器（例如作業調度器）都會帶來問題。
這一設計無法模擬在不同時間分配或釋放請求的效果。
只有第三方 DRA 驅動程序才擁有信息來做到這一點。

<!--
​​Structured Parameters for dynamic resource allocation is an extension to the original
implementation that addresses this problem by building a framework to support making these claim
parameters less opaque. Instead of handling the semantics of all claim parameters themselves,
drivers could manage resources and describe them using a specific "structured model" pre-defined by
Kubernetes. This would allow components aware of this "structured model" to make decisions about
these resources without outsourcing them to some third-party controller. For example, the scheduler
could allocate claims rapidly without back-and-forth communication with dynamic resource
allocation drivers. Work done for this release centers on defining the framework necessary to enable
different "structured models" and to implement the "named resources" model. This model allows
listing individual resource instances and, compared to the traditional device plugin API, adds the
ability to select those instances individually via attributes.
-->
動態資源分配（DRA）的結構化參數是對原始實現的擴展，它通過構建一個框架來支持增加請求參數的透明度來解決這個問題。
驅動程序不再需要自己處理所有請求參數的語義，而是可以使用 Kubernetes 預定義的特定“結構化模型”來管理和描述資源。
這一設計允許瞭解這個“結構化規範”的組件做出關於這些資源的決策，而不再將它們外包給某些第三方控制器。
例如，調度器可以在不與動態資源分配（DRA）驅動程序反覆通信的前提下快速完成分配請求。
這個版本的工作重點是定義一個框架來支持不同的“結構化模型”，並實現“命名資源”模型。
此模型允許列出各個資源實例，同時，與傳統的設備插件 API 相比，模型增加了通過屬性逐一選擇實例的能力。

<!--
### Node memory swap support ([KEP-2400](https://kep.k8s.io/2400))
-->
### 節點交換內存 SWAP 支持 ([KEP-2400](https://kep.k8s.io/2400))

<!--
In Kubernetes v1.30, memory swap support on Linux nodes gets a big change to how it works - with a
strong emphasis on improving system stability. In previous Kubernetes versions, the `NodeSwap`
feature gate was disabled by default, and when enabled, it used `UnlimitedSwap` behavior as the
default behavior. To achieve better stability, `UnlimitedSwap` behavior (which might compromise node
stability) will be removed in v1.30.
-->
在 Kubernetes v1.30 中，Linux 節點上的交換內存支持機制有了重大改進，其重點是提高系統的穩定性。
以前的 Kubernetes 版本默認情況下禁用了 `NodeSwap` 特性門控。當門控被啓用時，`UnlimitedSwap` 行爲被作爲默認行爲。
爲了提高穩定性，`UnlimitedSwap` 行爲（可能會影響節點的穩定性）將在 v1.30 中被移除。

<!--
The updated, still-beta support for swap on Linux nodes will be available by default. However, the
default behavior will be to run the node set to `NoSwap` (not `UnlimitedSwap`) mode. In `NoSwap`
mode, the kubelet supports running on a node where swap space is active, but Pods don't use any of
the page file. You'll still need to set `--fail-swap-on=false` for the kubelet to run on that node.
However, the big change is the other mode: `LimitedSwap`. In this mode, the kubelet actually uses
the page file on that node and allows Pods to have some of their virtual memory paged out.
Containers (and their parent pods)  do not have access to swap beyond their memory limit, but the
system can still use the swap space if available.
-->
更新後的 Linux 節點上的交換內存支持仍然是 beta 級別，並且默認情況下開啓。
然而，節點默認行爲是使用 `NoSwap`（而不是 `UnlimitedSwap`）模式。
在 `NoSwap` 模式下，kubelet 支持在啓用了磁盤交換空間的節點上運行，但 Pod 不會使用頁面文件（pagefile）。
你仍然需要爲 kubelet 設置 `--fail-swap-on=false` 才能讓 kubelet 在該節點上運行。
特性的另一個重大變化是針對另一種模式：`LimitedSwap`。
在 `LimitedSwap` 模式下，kubelet 會實際使用節點上的頁面文件，並允許 Pod 的一些虛擬內存被換頁出去。
容器（及其父 Pod）訪問交換內存空間不可超出其內存限制，但系統的確可以使用可用的交換空間。

<!--
Kubernetes' Node special interest group (SIG Node) will also update the documentation to help you
understand how to use the revised implementation, based on feedback from end users, contributors,
and the wider Kubernetes community.
-->
Kubernetes 的 SIG Node 小組還將根據最終使用者、貢獻者和更廣泛的 Kubernetes 社區的反饋更新文檔，
以幫助你瞭解如何使用經過修訂的實現。

<!--
Read the previous [blog post](/blog/2023/08/24/swap-linux-beta/) or the [node swap
documentation](/docs/concepts/architecture/nodes/#swap-memory) for more details on 
Linux node swap support in Kubernetes.
-->
閱讀之前的[博客文章](/zh-cn/blog/2023/08/24/swap-linux-beta/)或[交換內存管理文檔](/zh-cn/docs/concepts/architecture/nodes/#swap-memory)以獲取有關
Kubernetes 中 Linux 節點交換支持的更多詳細信息。

<!--
### Support user namespaces in pods ([KEP-127](https://kep.k8s.io/127))
-->
### 支持 Pod 運行在使用者命名空間 ([KEP-127](https://kep.k8s.io/127))

<!--
[User namespaces](/docs/concepts/workloads/pods/user-namespaces) is a Linux-only feature that better
isolates pods to prevent or mitigate several CVEs rated high/critical, including
[CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv),
published in January 2024. In Kubernetes 1.30, support for user namespaces is migrating to beta and
now supports pods with and without volumes, custom UID/GID ranges, and more!
-->
[使用者命名空間](/zh-cn/docs/concepts/workloads/pods/user-namespaces) 是一個僅在 Linux 上可用的特性，它更好地隔離 Pod，
以防止或減輕幾個高/嚴重級別的 CVE，包括 2024 年 1 月發佈的 [CVE-2024-21626](https://github.com/opencontainers/runc/security/advisories/GHSA-xr7r-f8xq-vfvv)。
在 Kubernetes 1.30 中，對使用者命名空間的支持正在遷移到 beta，並且現在支持帶有和不帶有卷的 Pod，自定義 UID/GID 範圍等等！

<!--
### Structured authorization configuration ([KEP-3221](https://kep.k8s.io/3221))
-->
### 結構化鑑權設定([KEP-3221](https://kep.k8s.io/3221))

<!--
Support for [structured authorization
configuration](/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file)
is moving to beta and will be enabled by default. This feature enables the creation of
authorization chains with multiple webhooks with well-defined parameters that validate requests in a
particular order and allows fine-grained control – such as explicit Deny on failures. The
configuration file approach even allows you to specify [CEL](/docs/reference/using-api/cel/) rules
to pre-filter requests before they are dispatched to webhooks, helping you to prevent unnecessary
invocations. The API server also automatically reloads the authorizer chain when the configuration
file is modified.
-->
對[結構化鑑權設定](/zh-cn/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file)的支持正在晉級到 Beta 版本，並將默認啓用。
這個特性支持創建具有明確參數定義的多個 Webhook 所構成的鑑權鏈；這些 Webhook 按特定順序驗證請求，
並允許進行細粒度的控制，例如在失敗時明確拒絕。
設定文件方法甚至允許你指定 [CEL](/zh-cn/docs/reference/using-api/cel/) 規則，以在將請求分派到 Webhook 之前對其進行預過濾，幫助你防止不必要的調用。
當設定文件被修改時，API 伺服器還會自動重新加載鑑權鏈。

<!--
You must specify the path to that authorization configuration using the `--authorization-config`
command line argument. If you want to keep using command line flags instead of a
configuration file, those will continue to work as-is. To gain access to new authorization webhook
capabilities like multiple webhooks, failure policy, and pre-filter rules, switch to putting options
in an `--authorization-config` file. From Kubernetes 1.30, the configuration file format is
beta-level, and only requires specifying `--authorization-config` since the feature gate is enabled by
default. An example configuration with all possible values is provided in the [Authorization
docs](/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file).
For more details, read the [Authorization
docs](/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file).
-->
你必須使用 `--authorization-config` 命令列參數指定鑑權設定的路徑。
如果你想繼續使用命令列標誌而不是設定文件，命令列方式沒有變化。
要訪問新的 Webhook 功能，例如多 Webhook 支持、失敗策略和預過濾規則，需要切換到將選項放在 `--authorization-config` 文件中。
從 Kubernetes 1.30 開始，設定文件格式約定是 beta 級別的，只需要指定 `--authorization-config`，因爲特性門控默認啓用。
[鑑權文檔](/zh-cn/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file)
中提供了一個包含所有可能值的示例設定。
有關更多詳細信息，請閱讀[鑑權文檔](/zh-cn/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file)。

<!--
### Container resource based pod autoscaling ([KEP-1610](https://kep.k8s.io/1610))
-->
### 基於容器資源指標的 Pod 自動擴縮容 ([KEP-1610](https://kep.k8s.io/1610))

<!--
Horizontal pod autoscaling based on `ContainerResource` metrics will graduate to stable in v1.30.
This new behavior for HorizontalPodAutoscaler allows you to configure automatic scaling based on the
resource usage for individual containers, rather than the aggregate resource use over a Pod. See our
[previous article](/blog/2023/05/02/hpa-container-resource-metric/) for further details, or read
[container resource metrics](/docs/tasks/run-application/horizontal-pod-autoscale/#container-resource-metrics).
-->
基於 `ContainerResource` 指標的 Pod 水平自動擴縮容將在 v1.30 中升級爲穩定版。
HorizontalPodAutoscaler 的這一新行爲允許你根據各個容器的資源使用情況而不是 Pod 的聚合資源使用情況來設定自動伸縮。
有關更多詳細信息，請參閱我們的[先前文章](/zh-cn/blog/2023/05/02/hpa-container-resource-metric/)，
或閱讀[容器資源指標](/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/#container-resource-metrics)。

<!--
### CEL for admission control ([KEP-3488](https://kep.k8s.io/3488))
-->
### 在准入控制中使用 CEL ([KEP-3488](https://kep.k8s.io/3488))

<!--
Integrating Common Expression Language (CEL) for admission control in Kubernetes introduces a more
dynamic and expressive way of evaluating admission requests. This feature allows complex,
fine-grained policies to be defined and enforced directly through the Kubernetes API, enhancing
security and governance capabilities without compromising performance or flexibility.
-->
Kubernetes 爲準入控制集成了 Common Expression Language (CEL) 。
這一集成引入了一種更動態、表達能力更強的方式來判定準入請求。
這個特性允許通過 Kubernetes API 直接定義和執行復雜的、細粒度的策略，同時增強了安全性和治理能力，而不會影響性能或靈活性。

<!--
CEL's addition to Kubernetes admission control empowers cluster administrators to craft intricate
rules that can evaluate the content of API requests against the desired state and policies of the
cluster without resorting to Webhook-based access controllers. This level of control is crucial for
maintaining the integrity, security, and efficiency of cluster operations, making Kubernetes
environments more robust and adaptable to various use cases and requirements. For more information
on using CEL for admission control, see the [API
documentation](/docs/reference/access-authn-authz/validating-admission-policy/) for
ValidatingAdmissionPolicy.
-->
將 CEL 引入到 Kubernetes 的准入控制後，叢集管理員就具有了制定複雜規則的能力，
這些規則可以根據叢集的期望狀態和策略來評估 API 請求的內容，而無需使用基於 Webhook 的訪問控制器。
這種控制水平對於維護叢集操作的完整性、安全性和效率至關重要，使 Kubernetes 環境更加健壯，更適應各種用例和需求。
有關使用 CEL 進行准入控制的更多信息，請參閱 [API 文檔](/zh-cn/docs/reference/access-authn-authz/validating-admission-policy/)中的 ValidatingAdmissionPolicy。

<!--
We hope you're as excited for this release as we are. Keep an eye out for the official release 
blog in a few weeks for more highlights!
-->
我們希望你和我們一樣對這個版本的發佈感到興奮。請在未來幾周內密切關注官方發佈博客，以瞭解其他亮點！
